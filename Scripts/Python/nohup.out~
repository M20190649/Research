FLOCKFINDER=SpatialJoin;TIME=Wed May 30 23:19:52 PDT 2018;RUN=1527747592;NODES=4;ESTART=;EEND=;ESTEP=;MU=4;DELTA=;SCRIPT=DeltaBenchmarker;EVENT=Start
WARNING:root:Setting 4 nodes...
acald013@dblab-rack15: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack11: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack14: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack12: no org.apache.spark.deploy.worker.Worker to stop
no org.apache.spark.deploy.master.Master to stop
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack15: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack15.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
WARNING:root:4 nodes has been set...
2018-05-30 23:20:07,651 -> Starting app...
2018-05-30 23:20:10,703 -> Starting session                                   |   3.05s |      0 
2018-05-30 23:20:10,718 -> Setting paramaters                                 |   0.02s |      0 
2018-05-30 23:20:13,866 -> Reading data                                       |   3.15s | 203106 points
2018-05-30 23:20:17,232 -> Extracting timestamps                              |   3.37s |     11 timestamps
2018-05-30 23:20:17,240 -> === SpatialJoin Start ===
2018-05-30 23:20:23,094 -> Reporting locations...                             |   5.59s |  18093 points
2018-05-30 23:20:23,108 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=0,dataset=berlin0-10
2018-05-30 23:20:31,796 -> A.Indexing points... [8.651s] [18093 results]
2018-05-30 23:20:39,429 -> B.Getting pairs... [7.633s] [5511 results]
2018-05-30 23:20:41,678 -> C.Computing centers... [2.249s] [11022 results]
2018-05-30 23:20:43,022 -> D.Indexing centers... [1.343s] [11022 results]
2018-05-30 23:20:49,054 -> E.Getting disks... [6.032s] [11022 results]
2018-05-30 23:20:49,466 -> F.Filtering less-than-mu disks... [0.412s] [1210 results]
2018-05-30 23:20:52,066 -> G.Prunning duplicate candidates... [2.600s] [599 results]
2018-05-30 23:20:52,588 -> H.Indexing candidates... [3.122s] [599 results]
2018-05-30 23:20:52,816 -> I.Getting expansions... [0.228s] [1657 results]
2018-05-30 23:20:53,442 -> J.Finding maximal disks... [0.626s] [206 results]
2018-05-30 23:20:55,236 -> K.Prunning duplicates and subsets... [1.794s] [205 results]
2018-05-30 23:20:55,237 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-30 23:20:55,237 ->   berlin0-10,   18093,  30.0,    28,  4,  32.09,    5511,     11022,          599,        205,  0
2018-05-30 23:20:55,304 -> Dropping indices...[0.067s]
2018-05-30 23:20:55,617 -> 1.Set of disks for t_i...                          |  32.52s |    205 disks
2018-05-30 23:20:56,013 -> 4.Found flocks...                                  |   0.40s |      0 flocks
2018-05-30 23:20:56,849 -> 5.Updating times...                                |   0.51s |    205 flocks
2018-05-30 23:20:57,699 -> 6.Filter phase...                                  |   0.85s |    205 flocks
2018-05-30 23:21:02,388 -> Reporting locations...                             |   4.69s |  18245 points
2018-05-30 23:21:02,388 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=1,dataset=berlin0-10
2018-05-30 23:21:06,959 -> A.Indexing points... [4.552s] [18245 results]
2018-05-30 23:21:12,216 -> B.Getting pairs... [5.257s] [5629 results]
2018-05-30 23:21:13,690 -> C.Computing centers... [1.474s] [11258 results]
2018-05-30 23:21:14,801 -> D.Indexing centers... [1.110s] [11258 results]
2018-05-30 23:21:19,801 -> E.Getting disks... [4.999s] [11258 results]
2018-05-30 23:21:20,068 -> F.Filtering less-than-mu disks... [0.267s] [1299 results]
2018-05-30 23:21:21,587 -> G.Prunning duplicate candidates... [1.519s] [640 results]
2018-05-30 23:21:21,936 -> H.Indexing candidates... [1.868s] [640 results]
2018-05-30 23:21:22,100 -> I.Getting expansions... [0.164s] [1703 results]
2018-05-30 23:21:22,266 -> J.Finding maximal disks... [0.165s] [220 results]
2018-05-30 23:21:23,518 -> K.Prunning duplicates and subsets... [1.252s] [216 results]
2018-05-30 23:21:23,518 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-30 23:21:23,518 ->   berlin0-10,   18245,  30.0,    28,  4,  21.11,    5629,     11258,          640,        216,  1
2018-05-30 23:21:23,607 -> Dropping indices...[0.088s]
2018-05-30 23:21:23,890 -> 1.Set of disks for t_i...                          |  21.50s |    216 disks
2018-05-30 23:21:27,356 -> 2.Distance Join phase...                           |   3.47s |    486 combinations
2018-05-30 23:21:30,455 -> 3.Getting candidates...                            |   3.10s |    196 candidates
2018-05-30 23:21:31,141 -> 4.Found flocks...                                  |   0.69s |    196 flocks
2018-05-30 23:21:33,585 -> 5.Updating times...                                |   1.50s |    196 flocks
2018-05-30 23:21:36,163 -> 6.Filter phase...                                  |   2.58s |    236 flocks
2018-05-30 23:21:41,015 -> Reporting locations...                             |   4.85s |  18394 points
2018-05-30 23:21:41,015 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=2,dataset=berlin0-10
2018-05-30 23:21:45,231 -> A.Indexing points... [4.202s] [18394 results]
2018-05-30 23:21:50,268 -> B.Getting pairs... [5.037s] [5701 results]
2018-05-30 23:21:51,665 -> C.Computing centers... [1.397s] [11402 results]
2018-05-30 23:21:52,747 -> D.Indexing centers... [1.082s] [11402 results]
2018-05-30 23:21:57,516 -> E.Getting disks... [4.769s] [11402 results]
2018-05-30 23:21:57,762 -> F.Filtering less-than-mu disks... [0.246s] [1336 results]
2018-05-30 23:21:59,316 -> G.Prunning duplicate candidates... [1.554s] [658 results]
2018-05-30 23:21:59,670 -> H.Indexing candidates... [1.908s] [658 results]
2018-05-30 23:21:59,855 -> I.Getting expansions... [0.185s] [1757 results]
2018-05-30 23:22:00,016 -> J.Finding maximal disks... [0.161s] [232 results]
2018-05-30 23:22:01,348 -> K.Prunning duplicates and subsets... [1.332s] [227 results]
2018-05-30 23:22:01,348 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-30 23:22:01,348 ->   berlin0-10,   18394,  30.0,    28,  4,  20.32,    5701,     11402,          658,        227,  2
2018-05-30 23:22:01,468 -> Dropping indices...[0.120s]
2018-05-30 23:22:01,698 -> 1.Set of disks for t_i...                          |  20.68s |    227 disks
2018-05-30 23:22:08,664 -> 2.Distance Join phase...                           |   6.97s |    648 combinations
2018-05-30 23:22:12,971 -> 3.Getting candidates...                            |   4.31s |    218 candidates
2018-05-30 23:22:13,660 -> 4.Found flocks...                                  |   0.69s |    218 flocks
2018-05-30 23:22:16,230 -> 5.Updating times...                                |   1.17s |    218 flocks
2018-05-30 23:22:18,047 -> 6.Filter phase...                                  |   1.82s |    248 flocks
2018-05-30 23:22:22,808 -> Reporting locations...                             |   4.76s |  18548 points
2018-05-30 23:22:22,809 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=3,dataset=berlin0-10
2018-05-30 23:22:30,222 -> A.Indexing points... [7.394s] [18548 results]
2018-05-30 23:22:41,098 -> B.Getting pairs... [10.876s] [5768 results]
2018-05-30 23:22:42,526 -> C.Computing centers... [1.428s] [11536 results]
2018-05-30 23:22:43,518 -> D.Indexing centers... [0.991s] [11536 results]
2018-05-30 23:22:50,666 -> E.Getting disks... [7.148s] [11536 results]
2018-05-30 23:22:50,905 -> F.Filtering less-than-mu disks... [0.239s] [1349 results]
2018-05-30 23:22:53,181 -> G.Prunning duplicate candidates... [2.276s] [675 results]
2018-05-30 23:22:53,490 -> H.Indexing candidates... [2.585s] [675 results]
2018-05-30 23:22:53,679 -> I.Getting expansions... [0.188s] [1875 results]
2018-05-30 23:22:53,841 -> J.Finding maximal disks... [0.162s] [230 results]
2018-05-30 23:22:55,690 -> K.Prunning duplicates and subsets... [1.849s] [225 results]
2018-05-30 23:22:55,690 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-30 23:22:55,690 ->   berlin0-10,   18548,  30.0,    28,  4,  32.86,    5768,     11536,          675,        225,  3
2018-05-30 23:22:55,912 -> Dropping indices...[0.222s]
2018-05-30 23:22:56,183 -> 1.Set of disks for t_i...                          |  33.37s |    225 disks
2018-05-30 23:23:02,601 -> 2.Distance Join phase...                           |   6.42s |    671 combinations
2018-05-30 23:23:06,599 -> 3.Getting candidates...                            |   4.00s |    220 candidates
2018-05-30 23:23:07,497 -> 4.Found flocks...                                  |   0.90s |    220 flocks
2018-05-30 23:23:10,770 -> 5.Updating times...                                |   1.29s |    220 flocks
2018-05-30 23:23:12,971 -> 6.Filter phase...                                  |   2.20s |    250 flocks
2018-05-30 23:23:17,728 -> Reporting locations...                             |   4.76s |  18548 points
2018-05-30 23:23:17,728 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=4,dataset=berlin0-10
2018-05-30 23:23:25,118 -> A.Indexing points... [7.371s] [18548 results]
2018-05-30 23:23:35,558 -> B.Getting pairs... [10.440s] [5775 results]
2018-05-30 23:23:36,849 -> C.Computing centers... [1.291s] [11550 results]
2018-05-30 23:23:37,896 -> D.Indexing centers... [1.047s] [11550 results]
2018-05-30 23:23:45,030 -> E.Getting disks... [7.112s] [11550 results]
2018-05-30 23:23:45,332 -> F.Filtering less-than-mu disks... [0.302s] [1369 results]
2018-05-30 23:23:47,597 -> G.Prunning duplicate candidates... [2.265s] [694 results]
2018-05-30 23:23:47,972 -> H.Indexing candidates... [2.640s] [694 results]
2018-05-30 23:23:48,200 -> I.Getting expansions... [0.228s] [1914 results]
2018-05-30 23:23:48,361 -> J.Finding maximal disks... [0.161s] [245 results]
2018-05-30 23:23:50,380 -> K.Prunning duplicates and subsets... [2.019s] [238 results]
2018-05-30 23:23:50,380 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-30 23:23:50,380 ->   berlin0-10,   18548,  30.0,    28,  4,  32.63,    5775,     11550,          694,        238,  4
2018-05-30 23:23:50,626 -> Dropping indices...[0.246s]
2018-05-30 23:23:50,890 -> 1.Set of disks for t_i...                          |  33.16s |    238 disks
2018-05-30 23:23:58,078 -> 2.Distance Join phase...                           |   7.19s |    701 combinations
2018-05-30 23:24:02,515 -> 3.Getting candidates...                            |   4.44s |    224 candidates
2018-05-30 23:24:03,536 -> 4.Found flocks...                                  |   1.02s |    224 flocks
2018-05-30 23:24:07,671 -> 5.Updating times...                                |   1.38s |    224 flocks
2018-05-30 23:24:10,024 -> 6.Filter phase...                                  |   2.35s |    249 flocks
2018-05-30 23:24:14,800 -> Reporting locations...                             |   4.78s |  18548 points
2018-05-30 23:24:14,800 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=5,dataset=berlin0-10
2018-05-30 23:24:22,262 -> A.Indexing points... [7.444s] [18548 results]
2018-05-30 23:24:32,518 -> B.Getting pairs... [10.256s] [5765 results]
2018-05-30 23:24:34,008 -> C.Computing centers... [1.490s] [11530 results]
2018-05-30 23:24:34,977 -> D.Indexing centers... [0.969s] [11530 results]
2018-05-30 23:24:42,037 -> E.Getting disks... [7.059s] [11530 results]
2018-05-30 23:24:42,279 -> F.Filtering less-than-mu disks... [0.241s] [1362 results]
2018-05-30 23:24:44,929 -> G.Prunning duplicate candidates... [2.650s] [686 results]
2018-05-30 23:24:45,239 -> H.Indexing candidates... [2.960s] [686 results]
2018-05-30 23:24:45,435 -> I.Getting expansions... [0.195s] [1917 results]
2018-05-30 23:24:45,595 -> J.Finding maximal disks... [0.160s] [237 results]
2018-05-30 23:24:47,464 -> K.Prunning duplicates and subsets... [1.869s] [234 results]
2018-05-30 23:24:47,464 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-30 23:24:47,465 ->   berlin0-10,   18548,  30.0,    28,  4,  32.65,    5765,     11530,          686,        234,  5
2018-05-30 23:24:47,810 -> Dropping indices...[0.345s]
2018-05-30 23:24:48,047 -> 1.Set of disks for t_i...                          |  33.25s |    234 disks
2018-05-30 23:24:55,914 -> 2.Distance Join phase...                           |   7.87s |    630 combinations
2018-05-30 23:25:00,927 -> 3.Getting candidates...                            |   5.01s |    230 candidates
2018-05-30 23:25:02,076 -> 4.Found flocks...                                  |   1.15s |    230 flocks
2018-05-30 23:25:06,790 -> 5.Updating times...                                |   1.49s |    230 flocks
2018-05-30 23:25:09,248 -> 6.Filter phase...                                  |   2.46s |    259 flocks
2018-05-30 23:25:14,001 -> Reporting locations...                             |   4.75s |  18546 points
2018-05-30 23:25:14,001 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=6,dataset=berlin0-10
2018-05-30 23:25:21,755 -> A.Indexing points... [7.735s] [18546 results]
2018-05-30 23:25:32,241 -> B.Getting pairs... [10.486s] [5758 results]
2018-05-30 23:25:33,728 -> C.Computing centers... [1.487s] [11516 results]
2018-05-30 23:25:34,705 -> D.Indexing centers... [0.977s] [11516 results]
2018-05-30 23:25:41,901 -> E.Getting disks... [7.196s] [11516 results]
2018-05-30 23:25:42,218 -> F.Filtering less-than-mu disks... [0.317s] [1346 results]
2018-05-30 23:25:44,490 -> G.Prunning duplicate candidates... [2.272s] [681 results]
2018-05-30 23:25:44,829 -> H.Indexing candidates... [2.611s] [681 results]
2018-05-30 23:25:45,031 -> I.Getting expansions... [0.202s] [1951 results]
2018-05-30 23:25:45,177 -> J.Finding maximal disks... [0.146s] [225 results]
2018-05-30 23:25:47,081 -> K.Prunning duplicates and subsets... [1.904s] [222 results]
2018-05-30 23:25:47,081 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-30 23:25:47,081 ->   berlin0-10,   18546,  30.0,    28,  4,  33.06,    5758,     11516,          681,        222,  6
2018-05-30 23:25:47,438 -> Dropping indices...[0.357s]
2018-05-30 23:25:47,702 -> 1.Set of disks for t_i...                          |  33.70s |    222 disks
2018-05-30 23:25:56,582 -> 2.Distance Join phase...                           |   8.88s |    619 combinations
2018-05-30 23:26:01,289 -> 3.Getting candidates...                            |   4.71s |    224 candidates
2018-05-30 23:26:02,640 -> 4.Found flocks...                                  |   1.35s |    224 flocks
2018-05-30 23:26:09,207 -> 5.Updating times...                                |   2.74s |    224 flocks
2018-05-30 23:26:11,607 -> 6.Filter phase...                                  |   2.40s |    247 flocks
2018-05-30 23:26:16,377 -> Reporting locations...                             |   4.77s |  18546 points
2018-05-30 23:26:16,377 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=7,dataset=berlin0-10
2018-05-30 23:26:24,072 -> A.Indexing points... [7.680s] [18546 results]
2018-05-30 23:26:34,839 -> B.Getting pairs... [10.767s] [5788 results]
2018-05-30 23:26:36,303 -> C.Computing centers... [1.464s] [11576 results]
2018-05-30 23:26:37,364 -> D.Indexing centers... [1.061s] [11576 results]
2018-05-30 23:26:44,374 -> E.Getting disks... [7.010s] [11576 results]
2018-05-30 23:26:44,601 -> F.Filtering less-than-mu disks... [0.227s] [1361 results]
2018-05-30 23:26:46,626 -> G.Prunning duplicate candidates... [2.025s] [688 results]
2018-05-30 23:26:46,931 -> H.Indexing candidates... [2.330s] [688 results]
2018-05-30 23:26:47,168 -> I.Getting expansions... [0.237s] [1882 results]
2018-05-30 23:26:47,312 -> J.Finding maximal disks... [0.144s] [233 results]
2018-05-30 23:26:49,139 -> K.Prunning duplicates and subsets... [1.827s] [231 results]
2018-05-30 23:26:49,139 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-30 23:26:49,139 ->   berlin0-10,   18546,  30.0,    28,  4,  32.75,    5788,     11576,          688,        231,  7
2018-05-30 23:26:49,602 -> Dropping indices...[0.463s]
2018-05-30 23:26:49,891 -> 1.Set of disks for t_i...                          |  33.51s |    231 disks
2018-05-30 23:26:58,730 -> 2.Distance Join phase...                           |   8.84s |    597 combinations
2018-05-30 23:27:03,729 -> 3.Getting candidates...                            |   5.00s |    213 candidates
2018-05-30 23:27:04,985 -> 4.Found flocks...                                  |   1.26s |    213 flocks
2018-05-30 23:27:11,752 -> 5.Updating times...                                |   1.72s |    213 flocks
2018-05-30 23:27:14,161 -> 6.Filter phase...                                  |   2.41s |    244 flocks
2018-05-30 23:27:18,853 -> Reporting locations...                             |   4.69s |  18546 points
2018-05-30 23:27:18,853 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=8,dataset=berlin0-10
2018-05-30 23:27:24,025 -> A.Indexing points... [5.155s] [18546 results]
2018-05-30 23:27:30,333 -> B.Getting pairs... [6.308s] [5791 results]
2018-05-30 23:27:31,679 -> C.Computing centers... [1.346s] [11582 results]
2018-05-30 23:27:32,750 -> D.Indexing centers... [1.071s] [11582 results]
2018-05-30 23:27:38,065 -> E.Getting disks... [5.315s] [11582 results]
2018-05-30 23:27:38,314 -> F.Filtering less-than-mu disks... [0.248s] [1316 results]
2018-05-30 23:27:40,013 -> G.Prunning duplicate candidates... [1.699s] [670 results]
2018-05-30 23:27:40,372 -> H.Indexing candidates... [2.058s] [670 results]
2018-05-30 23:27:40,539 -> I.Getting expansions... [0.167s] [1792 results]
2018-05-30 23:27:40,687 -> J.Finding maximal disks... [0.148s] [220 results]
2018-05-30 23:27:42,047 -> K.Prunning duplicates and subsets... [1.360s] [219 results]
2018-05-30 23:27:42,047 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-30 23:27:42,047 ->   berlin0-10,   18546,  30.0,    28,  4,  23.18,    5791,     11582,          670,        219,  8
2018-05-30 23:27:42,637 -> Dropping indices...[0.590s]
2018-05-30 23:27:43,009 -> 1.Set of disks for t_i...                          |  24.16s |    219 disks
2018-05-30 23:27:52,023 -> 2.Distance Join phase...                           |   9.01s |    520 combinations
2018-05-30 23:27:57,196 -> 3.Getting candidates...                            |   5.17s |    211 candidates
2018-05-30 23:27:58,690 -> 4.Found flocks...                                  |   1.49s |    211 flocks
2018-05-30 23:28:06,019 -> 5.Updating times...                                |   1.90s |    211 flocks
2018-05-30 23:28:08,816 -> 6.Filter phase...                                  |   2.80s |    232 flocks
2018-05-30 23:28:13,464 -> Reporting locations...                             |   4.65s |  18546 points
2018-05-30 23:28:13,465 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=9,dataset=berlin0-10
2018-05-30 23:28:20,170 -> A.Indexing points... [6.670s] [18546 results]
2018-05-30 23:28:29,401 -> B.Getting pairs... [9.231s] [5802 results]
2018-05-30 23:28:30,907 -> C.Computing centers... [1.506s] [11604 results]
2018-05-30 23:28:31,910 -> D.Indexing centers... [1.003s] [11604 results]
2018-05-30 23:28:38,384 -> E.Getting disks... [6.474s] [11604 results]
2018-05-30 23:28:38,598 -> F.Filtering less-than-mu disks... [0.214s] [1306 results]
2018-05-30 23:28:40,370 -> G.Prunning duplicate candidates... [1.772s] [675 results]
2018-05-30 23:28:40,751 -> H.Indexing candidates... [2.153s] [675 results]
2018-05-30 23:28:40,914 -> I.Getting expansions... [0.163s] [1813 results]
2018-05-30 23:28:41,058 -> J.Finding maximal disks... [0.144s] [212 results]
2018-05-30 23:28:42,871 -> K.Prunning duplicates and subsets... [1.812s] [210 results]
2018-05-30 23:28:42,871 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-30 23:28:42,871 ->   berlin0-10,   18546,  30.0,    28,  4,  29.37,    5802,     11604,          675,        210,  9
2018-05-30 23:28:43,557 -> Dropping indices...[0.686s]
2018-05-30 23:28:43,875 -> 1.Set of disks for t_i...                          |  30.41s |    210 disks
2018-05-30 23:28:54,740 -> 2.Distance Join phase...                           |  10.87s |    474 combinations
2018-05-30 23:29:00,379 -> 3.Getting candidates...                            |   5.64s |    206 candidates
2018-05-30 23:29:02,032 -> 4.Found flocks...                                  |   1.65s |    206 flocks
2018-05-30 23:29:10,941 -> 5.Updating times...                                |   2.22s |    206 flocks
2018-05-30 23:29:14,317 -> 6.Filter phase...                                  |   3.38s |    226 flocks
2018-05-30 23:29:18,956 -> Reporting locations...                             |   4.64s |  18546 points
2018-05-30 23:29:18,957 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=10,dataset=berlin0-10
2018-05-30 23:29:25,874 -> A.Indexing points... [6.882s] [18546 results]
2018-05-30 23:29:34,896 -> B.Getting pairs... [9.022s] [5797 results]
2018-05-30 23:29:36,221 -> C.Computing centers... [1.325s] [11594 results]
2018-05-30 23:29:37,263 -> D.Indexing centers... [1.041s] [11594 results]
2018-05-30 23:29:43,977 -> E.Getting disks... [6.714s] [11594 results]
2018-05-30 23:29:44,207 -> F.Filtering less-than-mu disks... [0.230s] [1312 results]
2018-05-30 23:29:45,978 -> G.Prunning duplicate candidates... [1.771s] [675 results]
2018-05-30 23:29:46,409 -> H.Indexing candidates... [2.202s] [675 results]
2018-05-30 23:29:46,628 -> I.Getting expansions... [0.219s] [1804 results]
2018-05-30 23:29:46,777 -> J.Finding maximal disks... [0.149s] [212 results]
2018-05-30 23:29:48,416 -> K.Prunning duplicates and subsets... [1.638s] [211 results]
2018-05-30 23:29:48,416 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-30 23:29:48,417 ->   berlin0-10,   18546,  30.0,    28,  4,  29.42,    5797,     11594,          675,        211, 10
2018-05-30 23:29:49,098 -> Dropping indices...[0.681s]
2018-05-30 23:29:49,410 -> 1.Set of disks for t_i...                          |  30.45s |    211 disks
2018-05-30 23:30:00,527 -> 2.Distance Join phase...                           |  11.12s |    457 combinations
2018-05-30 23:30:06,769 -> 3.Getting candidates...                            |   6.24s |    197 candidates
2018-05-30 23:30:08,332 -> 4.Found flocks...                                  |   1.56s |    197 flocks
2018-05-30 23:30:17,622 -> 5.Updating times...                                |   2.03s |    197 flocks
2018-05-30 23:30:20,274 -> 6.Filter phase...                                  |   2.65s |    221 flocks
2018-05-30 23:30:20,274 -> 

PFLOCK_SJ	30.0	4	2	2139

2018-05-30 23:30:26,402 -> Running SpatialJoin...                             | 609.16s |   2139 flocks
2018-05-30 23:30:26,402 -> method=SpatialJoin,cores=28,epsilon=30.0,mu=4,delta=2,time=609.162,master=spark://169.235.27.134:7077
2018-05-30 23:30:26,402 -> Closing app...
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack15: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
FLOCKFINDER=SpatialJoin;TIME=Wed May 30 23:30:28 PDT 2018;RUN=1527747592;NODES=4;ESTART=;EEND=;ESTEP=;MU=4;DELTA=;SCRIPT=DeltaBenchmarker;EVENT=End
FLOCKFINDER=MergeLast;TIME=Wed May 30 23:30:28 PDT 2018;RUN=1527748228;NODES=4;ESTART=;EEND=;ESTEP=;MU=4;DELTA=;SCRIPT=DeltaBenchmarker;EVENT=Start
WARNING:root:Setting 4 nodes...
acald013@dblab-rack12: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack14: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack11: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack15: no org.apache.spark.deploy.worker.Worker to stop
no org.apache.spark.deploy.master.Master to stop
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack15: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack15.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
WARNING:root:4 nodes has been set...
2018-05-30 23:30:36,072 -> Starting app...
2018-05-30 23:30:39,040 -> Starting session                                   |   2.97s |      0 
2018-05-30 23:30:39,056 -> Setting paramaters                                 |   0.02s |      0 
2018-05-30 23:30:42,298 -> Reading data                                       |   3.24s | 203106 points
2018-05-30 23:30:45,623 -> Extracting timestamps                              |   3.33s |     11 timestamps
2018-05-30 23:30:45,631 -> === MergeLast Start ===
2018-05-30 23:30:50,999 -> Reporting locations at t=0...                      |   5.16s |  18093 points
2018-05-30 23:30:51,020 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=0,dataset=berlin0-10
2018-05-30 23:30:59,307 -> A.Indexing points... [8.237s] [18093 results]
2018-05-30 23:31:06,843 -> B.Getting pairs... [7.536s] [5511 results]
2018-05-30 23:31:09,136 -> C.Computing centers... [2.293s] [11022 results]
2018-05-30 23:31:10,917 -> D.Indexing centers... [1.781s] [11022 results]
2018-05-30 23:31:17,551 -> E.Getting disks... [6.634s] [11022 results]
2018-05-30 23:31:18,040 -> F.Filtering less-than-mu disks... [0.489s] [1210 results]
2018-05-30 23:31:20,862 -> G.Prunning duplicate candidates... [2.822s] [599 results]
2018-05-30 23:31:21,381 -> H.Indexing candidates... [3.341s] [599 results]
2018-05-30 23:31:21,651 -> I.Getting expansions... [0.270s] [1657 results]
2018-05-30 23:31:22,188 -> J.Finding maximal disks... [0.537s] [206 results]
2018-05-30 23:31:24,535 -> K.Prunning duplicates and subsets... [2.347s] [205 results]
2018-05-30 23:31:24,535 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-30 23:31:24,535 ->   berlin0-10,   18093,  30.0,    28,  4,  33.47,    5511,     11022,          599,        205,  0
2018-05-30 23:31:24,614 -> Dropping indices...[0.079s]
2018-05-30 23:31:24,943 -> 1.Set of disks for t_i...                          |  33.94s |    205 disks
2018-05-30 23:31:29,504 -> Reporting locations at t=1...                      |   4.56s |  18245 points
2018-05-30 23:31:29,505 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=1,dataset=berlin0-10
2018-05-30 23:31:34,327 -> A.Indexing points... [4.799s] [18245 results]
2018-05-30 23:31:39,547 -> B.Getting pairs... [5.220s] [5629 results]
2018-05-30 23:31:40,934 -> C.Computing centers... [1.387s] [11258 results]
2018-05-30 23:31:41,944 -> D.Indexing centers... [1.010s] [11258 results]
2018-05-30 23:31:46,571 -> E.Getting disks... [4.627s] [11258 results]
2018-05-30 23:31:46,831 -> F.Filtering less-than-mu disks... [0.260s] [1299 results]
2018-05-30 23:31:48,664 -> G.Prunning duplicate candidates... [1.832s] [640 results]
2018-05-30 23:31:49,001 -> H.Indexing candidates... [2.169s] [640 results]
2018-05-30 23:31:49,168 -> I.Getting expansions... [0.167s] [1703 results]
2018-05-30 23:31:49,641 -> J.Finding maximal disks... [0.473s] [220 results]
2018-05-30 23:31:51,029 -> K.Prunning duplicates and subsets... [1.388s] [216 results]
2018-05-30 23:31:51,029 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-30 23:31:51,029 ->   berlin0-10,   18245,  30.0,    28,  4,  21.50,    5629,     11258,          640,        216,  1
2018-05-30 23:31:51,103 -> Dropping indices...[0.074s]
2018-05-30 23:31:51,361 -> 2.Set of disks for t_i+delta...                    |  21.86s |    205 disks
2018-05-30 23:31:59,780 -> 3.Joining timestams                                |   8.42s |    319 candidates
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 3 in stage 1467.0 failed 4 times, most recent failure: Lost task 3.3 in stage 1467.0 (TID 66191, 169.235.27.134, executor 1): java.util.NoSuchElementException: head of empty list
	at scala.collection.immutable.Nil$.head(List.scala:420)
	at scala.collection.immutable.Nil$.head(List.scala:417)
	at scala.collection.generic.TraversableForwarder$class.head(TraversableForwarder.scala:56)
	at scala.collection.mutable.ListBuffer.head(ListBuffer.scala:45)
	at FlockFinderMergeLast$.computeMaximalDisks(FlockFinderMergeLast.scala:277)
	at FlockFinderMergeLast$$anonfun$runMergeLast$1$$anonfun$13.apply(FlockFinderMergeLast.scala:221)
	at FlockFinderMergeLast$$anonfun$runMergeLast$1$$anonfun$13.apply(FlockFinderMergeLast.scala:219)
	at org.apache.spark.sql.execution.MapElementsExec$$anonfun$8$$anonfun$apply$1.apply(objects.scala:237)
	at org.apache.spark.sql.execution.MapElementsExec$$anonfun$8$$anonfun$apply$1.apply(objects.scala:237)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.columnar.InMemoryRelation$$anonfun$1$$anon$1.hasNext(InMemoryRelation.scala:138)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:215)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:957)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:948)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:888)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:948)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:694)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:334)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1958)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:935)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:934)
	at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:275)
	at org.apache.spark.sql.Dataset$$anonfun$org$apache$spark$sql$Dataset$$execute$1$1.apply(Dataset.scala:2371)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:57)
	at org.apache.spark.sql.Dataset.withNewExecutionId(Dataset.scala:2765)
	at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$execute$1(Dataset.scala:2370)
	at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collect(Dataset.scala:2377)
	at org.apache.spark.sql.Dataset$$anonfun$count$1.apply(Dataset.scala:2405)
	at org.apache.spark.sql.Dataset$$anonfun$count$1.apply(Dataset.scala:2404)
	at org.apache.spark.sql.Dataset.withCallback(Dataset.scala:2778)
	at org.apache.spark.sql.Dataset.count(Dataset.scala:2404)
	at FlockFinderMergeLast$$anonfun$runMergeLast$1.apply(FlockFinderMergeLast.scala:228)
	at FlockFinderMergeLast$$anonfun$runMergeLast$1.apply(FlockFinderMergeLast.scala:121)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at FlockFinderMergeLast$.runMergeLast(FlockFinderMergeLast.scala:121)
	at FlockFinderMergeLast$$anonfun$run$1$$anonfun$apply$mcVI$sp$1$$anonfun$apply$mcVI$sp$2.apply$mcVD$sp(FlockFinderMergeLast.scala:91)
	at FlockFinderMergeLast$$anonfun$run$1$$anonfun$apply$mcVI$sp$1$$anonfun$apply$mcVI$sp$2.apply(FlockFinderMergeLast.scala:86)
	at FlockFinderMergeLast$$anonfun$run$1$$anonfun$apply$mcVI$sp$1$$anonfun$apply$mcVI$sp$2.apply(FlockFinderMergeLast.scala:86)
	at scala.collection.immutable.NumericRange.foreach(NumericRange.scala:73)
	at FlockFinderMergeLast$$anonfun$run$1$$anonfun$apply$mcVI$sp$1.apply$mcVI$sp(FlockFinderMergeLast.scala:86)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at FlockFinderMergeLast$$anonfun$run$1.apply$mcVI$sp(FlockFinderMergeLast.scala:86)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at FlockFinderMergeLast$.run(FlockFinderMergeLast.scala:86)
	at FlockFinderMergeLast$.main(FlockFinderMergeLast.scala:585)
	at FlockFinderMergeLast.main(FlockFinderMergeLast.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: java.util.NoSuchElementException: head of empty list
	at scala.collection.immutable.Nil$.head(List.scala:420)
	at scala.collection.immutable.Nil$.head(List.scala:417)
	at scala.collection.generic.TraversableForwarder$class.head(TraversableForwarder.scala:56)
	at scala.collection.mutable.ListBuffer.head(ListBuffer.scala:45)
	at FlockFinderMergeLast$.computeMaximalDisks(FlockFinderMergeLast.scala:277)
	at FlockFinderMergeLast$$anonfun$runMergeLast$1$$anonfun$13.apply(FlockFinderMergeLast.scala:221)
	at FlockFinderMergeLast$$anonfun$runMergeLast$1$$anonfun$13.apply(FlockFinderMergeLast.scala:219)
	at org.apache.spark.sql.execution.MapElementsExec$$anonfun$8$$anonfun$apply$1.apply(objects.scala:237)
	at org.apache.spark.sql.execution.MapElementsExec$$anonfun$8$$anonfun$apply$1.apply(objects.scala:237)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.columnar.InMemoryRelation$$anonfun$1$$anon$1.hasNext(InMemoryRelation.scala:138)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:215)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:957)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:948)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:888)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:948)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:694)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:334)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
acald013@dblab-rack15: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
FLOCKFINDER=MergeLast;TIME=Wed May 30 23:32:10 PDT 2018;RUN=1527748228;NODES=4;ESTART=;EEND=;ESTEP=;MU=4;DELTA=;SCRIPT=DeltaBenchmarker;EVENT=End
FLOCKFINDER=SpatialJoin;TIME=Wed May 30 23:32:10 PDT 2018;RUN=1527748330;NODES=4;ESTART=;EEND=;ESTEP=;MU=4;DELTA=;SCRIPT=DeltaBenchmarker;EVENT=Start
WARNING:root:Setting 4 nodes...
acald013@dblab-rack12: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack15: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack14: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack11: no org.apache.spark.deploy.worker.Worker to stop
no org.apache.spark.deploy.master.Master to stop
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack15: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack15.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
WARNING:root:4 nodes has been set...
2018-05-30 23:32:17,358 -> Starting app...
2018-05-30 23:32:20,328 -> Starting session                                   |   2.97s |      0 
2018-05-30 23:32:20,343 -> Setting paramaters                                 |   0.01s |      0 
2018-05-30 23:32:23,544 -> Reading data                                       |   3.20s | 203106 points
2018-05-30 23:32:26,714 -> Extracting timestamps                              |   3.17s |     11 timestamps
2018-05-30 23:32:26,722 -> === SpatialJoin Start ===
2018-05-30 23:32:32,299 -> Reporting locations...                             |   5.34s |  18093 points
2018-05-30 23:32:32,306 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=0,dataset=berlin0-10
2018-05-30 23:32:40,911 -> A.Indexing points... [8.572s] [18093 results]
2018-05-30 23:32:48,312 -> B.Getting pairs... [7.401s] [5511 results]
2018-05-30 23:32:50,448 -> C.Computing centers... [2.135s] [11022 results]
2018-05-30 23:32:51,815 -> D.Indexing centers... [1.366s] [11022 results]
2018-05-30 23:32:57,176 -> E.Getting disks... [5.361s] [11022 results]
2018-05-30 23:32:57,560 -> F.Filtering less-than-mu disks... [0.384s] [1210 results]
2018-05-30 23:33:00,136 -> G.Prunning duplicate candidates... [2.576s] [599 results]
2018-05-30 23:33:00,594 -> H.Indexing candidates... [3.034s] [599 results]
2018-05-30 23:33:00,843 -> I.Getting expansions... [0.249s] [1657 results]
2018-05-30 23:33:01,441 -> J.Finding maximal disks... [0.598s] [206 results]
2018-05-30 23:33:03,357 -> K.Prunning duplicates and subsets... [1.916s] [205 results]
2018-05-30 23:33:03,358 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-30 23:33:03,358 ->   berlin0-10,   18093,  30.0,    28,  4,  31.02,    5511,     11022,          599,        205,  0
2018-05-30 23:33:03,430 -> Dropping indices...[0.072s]
2018-05-30 23:33:03,734 -> 1.Set of disks for t_i...                          |  31.44s |    205 disks
2018-05-30 23:33:04,130 -> 4.Found flocks...                                  |   0.40s |      0 flocks
2018-05-30 23:33:04,835 -> 5.Updating times...                                |   0.45s |    205 flocks
2018-05-30 23:33:05,756 -> 6.Filter phase...                                  |   0.92s |    205 flocks
2018-05-30 23:33:10,800 -> Reporting locations...                             |   5.04s |  18245 points
2018-05-30 23:33:10,800 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=1,dataset=berlin0-10
2018-05-30 23:33:14,967 -> A.Indexing points... [4.151s] [18245 results]
2018-05-30 23:33:19,894 -> B.Getting pairs... [4.927s] [5629 results]
2018-05-30 23:33:21,370 -> C.Computing centers... [1.476s] [11258 results]
2018-05-30 23:33:22,380 -> D.Indexing centers... [1.010s] [11258 results]
2018-05-30 23:33:27,121 -> E.Getting disks... [4.741s] [11258 results]
2018-05-30 23:33:27,343 -> F.Filtering less-than-mu disks... [0.222s] [1299 results]
2018-05-30 23:33:28,777 -> G.Prunning duplicate candidates... [1.434s] [640 results]
2018-05-30 23:33:29,146 -> H.Indexing candidates... [1.803s] [640 results]
2018-05-30 23:33:29,291 -> I.Getting expansions... [0.145s] [1703 results]
2018-05-30 23:33:29,442 -> J.Finding maximal disks... [0.150s] [220 results]
2018-05-30 23:33:30,543 -> K.Prunning duplicates and subsets... [1.101s] [216 results]
2018-05-30 23:33:30,543 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-30 23:33:30,543 ->   berlin0-10,   18245,  30.0,    28,  4,  19.73,    5629,     11258,          640,        216,  1
2018-05-30 23:33:30,630 -> Dropping indices...[0.087s]
2018-05-30 23:33:31,001 -> 1.Set of disks for t_i...                          |  20.20s |    216 disks
2018-05-30 23:33:34,507 -> 2.Distance Join phase...                           |   3.51s |    645 combinations
2018-05-30 23:33:37,598 -> 3.Getting candidates...                            |   3.09s |    196 candidates
2018-05-30 23:33:38,404 -> 4.Found flocks...                                  |   0.81s |      0 flocks
2018-05-30 23:33:40,897 -> 5.Updating times...                                |   1.47s |    196 flocks
2018-05-30 23:33:43,604 -> 6.Filter phase...                                  |   2.71s |    236 flocks
2018-05-30 23:33:48,628 -> Reporting locations...                             |   5.02s |  18394 points
2018-05-30 23:33:48,628 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=2,dataset=berlin0-10
2018-05-30 23:33:52,619 -> A.Indexing points... [3.977s] [18394 results]
2018-05-30 23:33:57,226 -> B.Getting pairs... [4.607s] [5701 results]
2018-05-30 23:33:58,476 -> C.Computing centers... [1.250s] [11402 results]
2018-05-30 23:33:59,401 -> D.Indexing centers... [0.925s] [11402 results]
2018-05-30 23:34:03,905 -> E.Getting disks... [4.503s] [11402 results]
2018-05-30 23:34:04,138 -> F.Filtering less-than-mu disks... [0.233s] [1336 results]
2018-05-30 23:34:05,475 -> G.Prunning duplicate candidates... [1.337s] [658 results]
2018-05-30 23:34:05,792 -> H.Indexing candidates... [1.654s] [658 results]
2018-05-30 23:34:05,951 -> I.Getting expansions... [0.159s] [1757 results]
2018-05-30 23:34:06,098 -> J.Finding maximal disks... [0.147s] [232 results]
2018-05-30 23:34:07,311 -> K.Prunning duplicates and subsets... [1.213s] [227 results]
2018-05-30 23:34:07,312 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-30 23:34:07,312 ->   berlin0-10,   18394,  30.0,    28,  4,  18.67,    5701,     11402,          658,        227,  2
2018-05-30 23:34:07,463 -> Dropping indices...[0.151s]
2018-05-30 23:34:07,754 -> 1.Set of disks for t_i...                          |  19.13s |    227 disks
2018-05-30 23:34:14,995 -> 2.Distance Join phase...                           |   7.24s |    902 combinations
2018-05-30 23:34:19,845 -> 3.Getting candidates...                            |   4.85s |    239 candidates
2018-05-30 23:34:20,546 -> 4.Found flocks...                                  |   0.70s |    199 flocks
2018-05-30 23:34:23,234 -> 5.Updating times...                                |   1.17s |    239 flocks
2018-05-30 23:34:25,253 -> 6.Filter phase...                                  |   2.02s |    268 flocks
2018-05-30 23:34:30,210 -> Reporting locations...                             |   4.96s |  18548 points
2018-05-30 23:34:30,210 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=3,dataset=berlin0-10
2018-05-30 23:34:37,686 -> A.Indexing points... [7.458s] [18548 results]
2018-05-30 23:34:48,377 -> B.Getting pairs... [10.691s] [5768 results]
2018-05-30 23:34:49,765 -> C.Computing centers... [1.388s] [11536 results]
2018-05-30 23:34:50,643 -> D.Indexing centers... [0.878s] [11536 results]
2018-05-30 23:34:57,670 -> E.Getting disks... [7.026s] [11536 results]
2018-05-30 23:34:57,886 -> F.Filtering less-than-mu disks... [0.215s] [1349 results]
2018-05-30 23:35:00,326 -> G.Prunning duplicate candidates... [2.440s] [675 results]
2018-05-30 23:35:00,636 -> H.Indexing candidates... [2.750s] [675 results]
2018-05-30 23:35:00,788 -> I.Getting expansions... [0.152s] [1875 results]
2018-05-30 23:35:00,933 -> J.Finding maximal disks... [0.145s] [230 results]
2018-05-30 23:35:02,779 -> K.Prunning duplicates and subsets... [1.846s] [225 results]
2018-05-30 23:35:02,779 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-30 23:35:02,779 ->   berlin0-10,   18548,  30.0,    28,  4,  32.55,    5768,     11536,          675,        225,  3
2018-05-30 23:35:02,991 -> Dropping indices...[0.212s]
2018-05-30 23:35:03,558 -> 1.Set of disks for t_i...                          |  33.35s |    225 disks
2018-05-30 23:35:10,680 -> 2.Distance Join phase...                           |   7.12s |   1012 combinations
2018-05-30 23:35:14,995 -> 3.Getting candidates...                            |   4.31s |    242 candidates
2018-05-30 23:35:16,430 -> 4.Found flocks...                                  |   1.44s |    210 flocks
2018-05-30 23:35:20,107 -> 5.Updating times...                                |   1.57s |    242 flocks
2018-05-30 23:35:22,429 -> 6.Filter phase...                                  |   2.32s |    269 flocks
2018-05-30 23:35:27,410 -> Reporting locations...                             |   4.98s |  18548 points
2018-05-30 23:35:27,410 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=4,dataset=berlin0-10
2018-05-30 23:35:34,856 -> A.Indexing points... [7.428s] [18548 results]
2018-05-30 23:35:45,399 -> B.Getting pairs... [10.543s] [5775 results]
2018-05-30 23:35:46,722 -> C.Computing centers... [1.323s] [11550 results]
2018-05-30 23:35:47,804 -> D.Indexing centers... [1.082s] [11550 results]
2018-05-30 23:35:54,777 -> E.Getting disks... [6.973s] [11550 results]
2018-05-30 23:35:54,996 -> F.Filtering less-than-mu disks... [0.219s] [1369 results]
2018-05-30 23:35:57,038 -> G.Prunning duplicate candidates... [2.042s] [694 results]
2018-05-30 23:35:57,332 -> H.Indexing candidates... [2.336s] [694 results]
2018-05-30 23:35:57,489 -> I.Getting expansions... [0.157s] [1914 results]
2018-05-30 23:35:57,627 -> J.Finding maximal disks... [0.138s] [245 results]
2018-05-30 23:35:59,515 -> K.Prunning duplicates and subsets... [1.888s] [238 results]
2018-05-30 23:35:59,515 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-30 23:35:59,515 ->   berlin0-10,   18548,  30.0,    28,  4,  32.09,    5775,     11550,          694,        238,  4
2018-05-30 23:35:59,793 -> Dropping indices...[0.278s]
2018-05-30 23:36:00,034 -> 1.Set of disks for t_i...                          |  32.62s |    238 disks
2018-05-30 23:36:07,787 -> 2.Distance Join phase...                           |   7.75s |   1066 combinations
2018-05-30 23:36:12,405 -> 3.Getting candidates...                            |   4.62s |    250 candidates
2018-05-30 23:36:13,355 -> 4.Found flocks...                                  |   0.95s |    220 flocks
2018-05-30 23:36:17,555 -> 5.Updating times...                                |   1.40s |    250 flocks
2018-05-30 23:36:19,909 -> 6.Filter phase...                                  |   2.35s |    274 flocks
2018-05-30 23:36:24,884 -> Reporting locations...                             |   4.98s |  18548 points
2018-05-30 23:36:24,884 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=5,dataset=berlin0-10
2018-05-30 23:36:32,368 -> A.Indexing points... [7.470s] [18548 results]
2018-05-30 23:36:43,025 -> B.Getting pairs... [10.657s] [5765 results]
2018-05-30 23:36:44,294 -> C.Computing centers... [1.269s] [11530 results]
2018-05-30 23:36:45,185 -> D.Indexing centers... [0.891s] [11530 results]
2018-05-30 23:36:52,437 -> E.Getting disks... [7.252s] [11530 results]
2018-05-30 23:36:52,662 -> F.Filtering less-than-mu disks... [0.225s] [1362 results]
2018-05-30 23:36:54,934 -> G.Prunning duplicate candidates... [2.271s] [686 results]
2018-05-30 23:36:55,246 -> H.Indexing candidates... [2.583s] [686 results]
2018-05-30 23:36:55,396 -> I.Getting expansions... [0.150s] [1917 results]
2018-05-30 23:36:55,536 -> J.Finding maximal disks... [0.140s] [237 results]
2018-05-30 23:36:57,355 -> K.Prunning duplicates and subsets... [1.819s] [234 results]
2018-05-30 23:36:57,355 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-30 23:36:57,355 ->   berlin0-10,   18548,  30.0,    28,  4,  32.46,    5765,     11530,          686,        234,  5
2018-05-30 23:36:57,695 -> Dropping indices...[0.340s]
2018-05-30 23:36:57,988 -> 1.Set of disks for t_i...                          |  33.10s |    234 disks
2018-05-30 23:37:06,084 -> 2.Distance Join phase...                           |   8.10s |   1035 combinations
2018-05-30 23:37:11,153 -> 3.Getting candidates...                            |   5.07s |    240 candidates
2018-05-30 23:37:12,249 -> 4.Found flocks...                                  |   1.10s |    213 flocks
2018-05-30 23:37:17,365 -> 5.Updating times...                                |   1.62s |    240 flocks
2018-05-30 23:37:19,874 -> 6.Filter phase...                                  |   2.51s |    267 flocks
2018-05-30 23:37:24,808 -> Reporting locations...                             |   4.93s |  18546 points
2018-05-30 23:37:24,809 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=6,dataset=berlin0-10
2018-05-30 23:37:32,512 -> A.Indexing points... [7.688s] [18546 results]
2018-05-30 23:37:43,242 -> B.Getting pairs... [10.730s] [5758 results]
2018-05-30 23:37:44,554 -> C.Computing centers... [1.312s] [11516 results]
2018-05-30 23:37:45,429 -> D.Indexing centers... [0.875s] [11516 results]
2018-05-30 23:37:52,358 -> E.Getting disks... [6.929s] [11516 results]
2018-05-30 23:37:52,570 -> F.Filtering less-than-mu disks... [0.212s] [1346 results]
2018-05-30 23:37:54,649 -> G.Prunning duplicate candidates... [2.079s] [681 results]
2018-05-30 23:37:54,938 -> H.Indexing candidates... [2.368s] [681 results]
2018-05-30 23:37:55,112 -> I.Getting expansions... [0.174s] [1951 results]
2018-05-30 23:37:55,254 -> J.Finding maximal disks... [0.142s] [225 results]
2018-05-30 23:37:57,020 -> K.Prunning duplicates and subsets... [1.766s] [222 results]
2018-05-30 23:37:57,020 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-30 23:37:57,020 ->   berlin0-10,   18546,  30.0,    28,  4,  32.20,    5758,     11516,          681,        222,  6
2018-05-30 23:37:57,528 -> Dropping indices...[0.508s]
2018-05-30 23:37:57,796 -> 1.Set of disks for t_i...                          |  32.99s |    222 disks
2018-05-30 23:38:06,661 -> 2.Distance Join phase...                           |   8.87s |    894 combinations
2018-05-30 23:38:11,703 -> 3.Getting candidates...                            |   5.04s |    252 candidates
2018-05-30 23:38:12,848 -> 4.Found flocks...                                  |   1.15s |    218 flocks
2018-05-30 23:38:18,561 -> 5.Updating times...                                |   1.61s |    252 flocks
2018-05-30 23:38:21,083 -> 6.Filter phase...                                  |   2.52s |    272 flocks
2018-05-30 23:38:26,017 -> Reporting locations...                             |   4.93s |  18546 points
2018-05-30 23:38:26,018 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=7,dataset=berlin0-10
2018-05-30 23:38:33,510 -> A.Indexing points... [7.475s] [18546 results]
2018-05-30 23:38:44,302 -> B.Getting pairs... [10.792s] [5788 results]
2018-05-30 23:38:45,554 -> C.Computing centers... [1.252s] [11576 results]
2018-05-30 23:38:46,538 -> D.Indexing centers... [0.984s] [11576 results]
2018-05-30 23:38:53,500 -> E.Getting disks... [6.962s] [11576 results]
2018-05-30 23:38:53,714 -> F.Filtering less-than-mu disks... [0.214s] [1361 results]
2018-05-30 23:38:57,212 -> G.Prunning duplicate candidates... [3.498s] [688 results]
2018-05-30 23:38:57,514 -> H.Indexing candidates... [3.800s] [688 results]
2018-05-30 23:38:57,672 -> I.Getting expansions... [0.158s] [1882 results]
2018-05-30 23:38:57,805 -> J.Finding maximal disks... [0.133s] [233 results]
2018-05-30 23:38:59,703 -> K.Prunning duplicates and subsets... [1.898s] [231 results]
2018-05-30 23:38:59,703 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-30 23:38:59,703 ->   berlin0-10,   18546,  30.0,    28,  4,  33.67,    5788,     11576,          688,        231,  7
2018-05-30 23:39:00,251 -> Dropping indices...[0.548s]
2018-05-30 23:39:00,494 -> 1.Set of disks for t_i...                          |  34.48s |    231 disks
2018-05-30 23:39:08,984 -> 2.Distance Join phase...                           |   8.49s |    934 combinations
2018-05-30 23:39:14,082 -> 3.Getting candidates...                            |   5.10s |    239 candidates
2018-05-30 23:39:15,432 -> 4.Found flocks...                                  |   1.35s |    216 flocks
2018-05-30 23:39:21,960 -> 5.Updating times...                                |   1.74s |    239 flocks
2018-05-30 23:39:24,632 -> 6.Filter phase...                                  |   2.67s |    270 flocks
2018-05-30 23:39:29,538 -> Reporting locations...                             |   4.91s |  18546 points
2018-05-30 23:39:29,538 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=8,dataset=berlin0-10
2018-05-30 23:39:34,527 -> A.Indexing points... [4.973s] [18546 results]
2018-05-30 23:39:41,195 -> B.Getting pairs... [6.667s] [5791 results]
2018-05-30 23:39:42,453 -> C.Computing centers... [1.258s] [11582 results]
2018-05-30 23:39:43,386 -> D.Indexing centers... [0.933s] [11582 results]
2018-05-30 23:39:48,879 -> E.Getting disks... [5.493s] [11582 results]
2018-05-30 23:39:49,137 -> F.Filtering less-than-mu disks... [0.257s] [1316 results]
2018-05-30 23:39:51,172 -> G.Prunning duplicate candidates... [2.035s] [670 results]
2018-05-30 23:39:51,520 -> H.Indexing candidates... [2.383s] [670 results]
2018-05-30 23:39:51,713 -> I.Getting expansions... [0.193s] [1792 results]
2018-05-30 23:39:51,851 -> J.Finding maximal disks... [0.138s] [220 results]
2018-05-30 23:39:53,168 -> K.Prunning duplicates and subsets... [1.316s] [219 results]
2018-05-30 23:39:53,168 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-30 23:39:53,168 ->   berlin0-10,   18546,  30.0,    28,  4,  23.61,    5791,     11582,          670,        219,  8
2018-05-30 23:39:53,897 -> Dropping indices...[0.729s]
2018-05-30 23:39:54,153 -> 1.Set of disks for t_i...                          |  24.62s |    219 disks
2018-05-30 23:40:03,711 -> 2.Distance Join phase...                           |   9.56s |    811 combinations
2018-05-30 23:40:09,119 -> 3.Getting candidates...                            |   5.41s |    226 candidates
2018-05-30 23:40:10,482 -> 4.Found flocks...                                  |   1.36s |    197 flocks
2018-05-30 23:40:18,084 -> 5.Updating times...                                |   1.85s |    226 flocks
2018-05-30 23:40:20,665 -> 6.Filter phase...                                  |   2.58s |    247 flocks
2018-05-30 23:40:25,501 -> Reporting locations...                             |   4.84s |  18546 points
2018-05-30 23:40:25,501 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=9,dataset=berlin0-10
2018-05-30 23:40:33,028 -> A.Indexing points... [7.494s] [18546 results]
2018-05-30 23:40:43,336 -> B.Getting pairs... [10.308s] [5802 results]
2018-05-30 23:40:44,582 -> C.Computing centers... [1.246s] [11604 results]
2018-05-30 23:40:45,525 -> D.Indexing centers... [0.943s] [11604 results]
2018-05-30 23:40:53,573 -> E.Getting disks... [8.048s] [11604 results]
2018-05-30 23:40:53,810 -> F.Filtering less-than-mu disks... [0.236s] [1306 results]
2018-05-30 23:40:56,013 -> G.Prunning duplicate candidates... [2.203s] [675 results]
2018-05-30 23:40:56,368 -> H.Indexing candidates... [2.558s] [675 results]
2018-05-30 23:40:56,582 -> I.Getting expansions... [0.213s] [1813 results]
2018-05-30 23:40:56,740 -> J.Finding maximal disks... [0.158s] [212 results]
2018-05-30 23:40:58,778 -> K.Prunning duplicates and subsets... [2.038s] [210 results]
2018-05-30 23:40:58,778 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-30 23:40:58,778 ->   berlin0-10,   18546,  30.0,    28,  4,  33.24,    5802,     11604,          675,        210,  9
2018-05-30 23:40:59,484 -> Dropping indices...[0.706s]
2018-05-30 23:40:59,750 -> 1.Set of disks for t_i...                          |  34.25s |    210 disks
2018-05-30 23:41:09,442 -> 2.Distance Join phase...                           |   9.69s |    637 combinations
2018-05-30 23:41:15,290 -> 3.Getting candidates...                            |   5.85s |    219 candidates
2018-05-30 23:41:16,962 -> 4.Found flocks...                                  |   1.67s |    199 flocks
2018-05-30 23:41:26,114 -> 5.Updating times...                                |   2.39s |    219 flocks
2018-05-30 23:41:29,741 -> 6.Filter phase...                                  |   3.63s |    239 flocks
2018-05-30 23:41:34,584 -> Reporting locations...                             |   4.84s |  18546 points
2018-05-30 23:41:34,584 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=10,dataset=berlin0-10
2018-05-30 23:41:41,783 -> A.Indexing points... [7.165s] [18546 results]
2018-05-30 23:41:51,802 -> B.Getting pairs... [10.019s] [5797 results]
2018-05-30 23:41:53,160 -> C.Computing centers... [1.358s] [11594 results]
2018-05-30 23:41:54,036 -> D.Indexing centers... [0.876s] [11594 results]
2018-05-30 23:42:01,077 -> E.Getting disks... [7.040s] [11594 results]
2018-05-30 23:42:01,293 -> F.Filtering less-than-mu disks... [0.216s] [1312 results]
2018-05-30 23:42:03,374 -> G.Prunning duplicate candidates... [2.081s] [675 results]
2018-05-30 23:42:03,696 -> H.Indexing candidates... [2.403s] [675 results]
2018-05-30 23:42:03,847 -> I.Getting expansions... [0.151s] [1804 results]
2018-05-30 23:42:03,974 -> J.Finding maximal disks... [0.127s] [212 results]
2018-05-30 23:42:05,964 -> K.Prunning duplicates and subsets... [1.990s] [211 results]
2018-05-30 23:42:05,964 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-30 23:42:05,964 ->   berlin0-10,   18546,  30.0,    28,  4,  31.35,    5797,     11594,          675,        211, 10
2018-05-30 23:42:06,745 -> Dropping indices...[0.781s]
2018-05-30 23:42:07,009 -> 1.Set of disks for t_i...                          |  32.43s |    211 disks
2018-05-30 23:42:18,747 -> 2.Distance Join phase...                           |  11.74s |    598 combinations
2018-05-30 23:42:25,110 -> 3.Getting candidates...                            |   6.36s |    213 candidates
2018-05-30 23:42:26,677 -> 4.Found flocks...                                  |   1.57s |    196 flocks
2018-05-30 23:42:36,147 -> 5.Updating times...                                |   2.00s |    213 flocks
2018-05-30 23:42:38,950 -> 6.Filter phase...                                  |   2.80s |    237 flocks
2018-05-30 23:42:38,950 -> 

PFLOCK_SJ	30.0	4	3	1868

2018-05-30 23:42:45,388 -> Running SpatialJoin...                             | 618.67s |   1868 flocks
2018-05-30 23:42:45,388 -> method=SpatialJoin,cores=28,epsilon=30.0,mu=4,delta=3,time=618.666,master=spark://169.235.27.134:7077
2018-05-30 23:42:45,389 -> Closing app...
acald013@dblab-rack15: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
FLOCKFINDER=SpatialJoin;TIME=Wed May 30 23:42:56 PDT 2018;RUN=1527748330;NODES=4;ESTART=;EEND=;ESTEP=;MU=4;DELTA=;SCRIPT=DeltaBenchmarker;EVENT=End
FLOCKFINDER=MergeLast;TIME=Wed May 30 23:42:56 PDT 2018;RUN=1527748976;NODES=4;ESTART=;EEND=;ESTEP=;MU=4;DELTA=;SCRIPT=DeltaBenchmarker;EVENT=Start
WARNING:root:Setting 4 nodes...
acald013@dblab-rack12: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack15: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack14: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack11: no org.apache.spark.deploy.worker.Worker to stop
no org.apache.spark.deploy.master.Master to stop
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack15: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack15.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
WARNING:root:4 nodes has been set...
2018-05-30 23:43:04,115 -> Starting app...
2018-05-30 23:43:06,969 -> Starting session                                   |   2.85s |      0 
2018-05-30 23:43:06,982 -> Setting paramaters                                 |   0.01s |      0 
2018-05-30 23:43:10,254 -> Reading data                                       |   3.27s | 203106 points
2018-05-30 23:43:13,677 -> Extracting timestamps                              |   3.42s |     11 timestamps
2018-05-30 23:43:13,684 -> === MergeLast Start ===
2018-05-30 23:43:19,470 -> Reporting locations at t=0...                      |   5.63s |  18093 points
2018-05-30 23:43:19,480 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=0,dataset=berlin0-10
2018-05-30 23:43:27,730 -> A.Indexing points... [8.216s] [18093 results]
2018-05-30 23:43:34,910 -> B.Getting pairs... [7.180s] [5511 results]
2018-05-30 23:43:36,974 -> C.Computing centers... [2.064s] [11022 results]
2018-05-30 23:43:38,228 -> D.Indexing centers... [1.254s] [11022 results]
2018-05-30 23:43:44,156 -> E.Getting disks... [5.928s] [11022 results]
2018-05-30 23:43:44,541 -> F.Filtering less-than-mu disks... [0.385s] [1210 results]
2018-05-30 23:43:47,269 -> G.Prunning duplicate candidates... [2.728s] [599 results]
2018-05-30 23:43:47,778 -> H.Indexing candidates... [3.237s] [599 results]
2018-05-30 23:43:47,974 -> I.Getting expansions... [0.196s] [1657 results]
2018-05-30 23:43:48,592 -> J.Finding maximal disks... [0.618s] [206 results]
2018-05-30 23:43:50,360 -> K.Prunning duplicates and subsets... [1.768s] [205 results]
2018-05-30 23:43:50,360 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-30 23:43:50,360 ->   berlin0-10,   18093,  30.0,    28,  4,  30.85,    5511,     11022,          599,        205,  0
2018-05-30 23:43:50,438 -> Dropping indices...[0.078s]
2018-05-30 23:43:50,775 -> 1.Set of disks for t_i...                          |  31.31s |    205 disks
2018-05-30 23:43:55,755 -> Reporting locations at t=2...                      |   4.98s |  18394 points
2018-05-30 23:43:55,756 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=2,dataset=berlin0-10
2018-05-30 23:44:00,334 -> A.Indexing points... [4.556s] [18394 results]
2018-05-30 23:44:05,500 -> B.Getting pairs... [5.166s] [5701 results]
2018-05-30 23:44:06,904 -> C.Computing centers... [1.404s] [11402 results]
2018-05-30 23:44:07,878 -> D.Indexing centers... [0.974s] [11402 results]
2018-05-30 23:44:12,420 -> E.Getting disks... [4.542s] [11402 results]
2018-05-30 23:44:12,651 -> F.Filtering less-than-mu disks... [0.231s] [1336 results]
2018-05-30 23:44:14,179 -> G.Prunning duplicate candidates... [1.528s] [658 results]
2018-05-30 23:44:14,500 -> H.Indexing candidates... [1.849s] [658 results]
2018-05-30 23:44:14,652 -> I.Getting expansions... [0.152s] [1757 results]
2018-05-30 23:44:14,802 -> J.Finding maximal disks... [0.150s] [232 results]
2018-05-30 23:44:15,924 -> K.Prunning duplicates and subsets... [1.121s] [227 results]
2018-05-30 23:44:15,924 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-30 23:44:15,924 ->   berlin0-10,   18394,  30.0,    28,  4,  20.15,    5701,     11402,          658,        227,  2
2018-05-30 23:44:16,004 -> Dropping indices...[0.080s]
2018-05-30 23:44:16,262 -> 2.Set of disks for t_i+delta...                    |  20.51s |    205 disks
2018-05-30 23:44:24,810 -> 3.Joining timestams                                |   8.55s |    332 candidates
2018-05-30 23:44:36,485 -> Checking internal timestamps                       |  11.68s |    199 flocks
2018-05-30 23:44:41,809 -> Reporting locations at t=1...                      |   4.91s |  18245 points
2018-05-30 23:44:41,809 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=1,dataset=berlin0-10
2018-05-30 23:44:46,164 -> A.Indexing points... [4.338s] [18245 results]
2018-05-30 23:44:50,946 -> B.Getting pairs... [4.782s] [5629 results]
2018-05-30 23:44:52,279 -> C.Computing centers... [1.333s] [11258 results]
2018-05-30 23:44:53,237 -> D.Indexing centers... [0.958s] [11258 results]
2018-05-30 23:44:57,764 -> E.Getting disks... [4.527s] [11258 results]
2018-05-30 23:44:57,974 -> F.Filtering less-than-mu disks... [0.210s] [1299 results]
2018-05-30 23:44:59,297 -> G.Prunning duplicate candidates... [1.323s] [640 results]
2018-05-30 23:44:59,623 -> H.Indexing candidates... [1.649s] [640 results]
2018-05-30 23:44:59,771 -> I.Getting expansions... [0.148s] [1703 results]
2018-05-30 23:44:59,919 -> J.Finding maximal disks... [0.148s] [220 results]
2018-05-30 23:45:01,069 -> K.Prunning duplicates and subsets... [1.150s] [216 results]
2018-05-30 23:45:01,069 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-30 23:45:01,069 ->   berlin0-10,   18245,  30.0,    28,  4,  19.24,    5629,     11258,          640,        216,  1
2018-05-30 23:45:01,158 -> Dropping indices...[0.089s]
2018-05-30 23:45:01,387 -> 1.Set of disks for t_i...                          |  19.58s |    216 disks
2018-05-30 23:45:06,318 -> Reporting locations at t=3...                      |   4.93s |  18548 points
2018-05-30 23:45:06,319 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=3,dataset=berlin0-10
2018-05-30 23:45:14,451 -> A.Indexing points... [8.111s] [18548 results]
2018-05-30 23:45:26,235 -> B.Getting pairs... [11.784s] [5768 results]
2018-05-30 23:45:27,621 -> C.Computing centers... [1.386s] [11536 results]
2018-05-30 23:45:28,566 -> D.Indexing centers... [0.945s] [11536 results]
2018-05-30 23:45:35,987 -> E.Getting disks... [7.421s] [11536 results]
2018-05-30 23:45:36,237 -> F.Filtering less-than-mu disks... [0.250s] [1349 results]
2018-05-30 23:45:38,743 -> G.Prunning duplicate candidates... [2.506s] [675 results]
2018-05-30 23:45:39,053 -> H.Indexing candidates... [2.816s] [675 results]
2018-05-30 23:45:39,206 -> I.Getting expansions... [0.153s] [1875 results]
2018-05-30 23:45:39,355 -> J.Finding maximal disks... [0.149s] [230 results]
2018-05-30 23:45:41,558 -> K.Prunning duplicates and subsets... [2.203s] [225 results]
2018-05-30 23:45:41,558 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-30 23:45:41,558 ->   berlin0-10,   18548,  30.0,    28,  4,  35.22,    5768,     11536,          675,        225,  3
2018-05-30 23:45:41,696 -> Dropping indices...[0.138s]
2018-05-30 23:45:41,916 -> 2.Set of disks for t_i+delta...                    |  35.60s |    216 disks
2018-05-30 23:45:48,957 -> 3.Joining timestams                                |   7.04s |    333 candidates
2018-05-30 23:45:58,402 -> Checking internal timestamps                       |   9.44s |    210 flocks
2018-05-30 23:46:04,004 -> Reporting locations at t=2...                      |   4.89s |  18394 points
2018-05-30 23:46:04,196 -> 1.Set of disks for t_i...                          |   0.19s |    227 disks
2018-05-30 23:46:09,134 -> Reporting locations at t=4...                      |   4.94s |  18548 points
2018-05-30 23:46:09,135 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=4,dataset=berlin0-10
2018-05-30 23:46:17,339 -> A.Indexing points... [8.183s] [18548 results]
2018-05-30 23:46:28,691 -> B.Getting pairs... [11.352s] [5775 results]
2018-05-30 23:46:29,991 -> C.Computing centers... [1.300s] [11550 results]
2018-05-30 23:46:30,951 -> D.Indexing centers... [0.960s] [11550 results]
2018-05-30 23:46:38,216 -> E.Getting disks... [7.265s] [11550 results]
2018-05-30 23:46:38,428 -> F.Filtering less-than-mu disks... [0.212s] [1369 results]
2018-05-30 23:46:40,767 -> G.Prunning duplicate candidates... [2.339s] [694 results]
2018-05-30 23:46:41,087 -> H.Indexing candidates... [2.659s] [694 results]
2018-05-30 23:46:41,246 -> I.Getting expansions... [0.159s] [1914 results]
2018-05-30 23:46:41,393 -> J.Finding maximal disks... [0.147s] [245 results]
2018-05-30 23:46:43,576 -> K.Prunning duplicates and subsets... [2.183s] [238 results]
2018-05-30 23:46:43,576 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-30 23:46:43,576 ->   berlin0-10,   18548,  30.0,    28,  4,  34.42,    5775,     11550,          694,        238,  4
2018-05-30 23:46:43,727 -> Dropping indices...[0.151s]
2018-05-30 23:46:43,961 -> 2.Set of disks for t_i+delta...                    |  34.83s |    227 disks
2018-05-30 23:46:51,224 -> 3.Joining timestams                                |   7.26s |    360 candidates
2018-05-30 23:47:01,152 -> Checking internal timestamps                       |   9.93s |    220 flocks
2018-05-30 23:47:06,919 -> Reporting locations at t=3...                      |   4.96s |  18548 points
2018-05-30 23:47:07,113 -> 1.Set of disks for t_i...                          |   0.19s |    225 disks
2018-05-30 23:47:12,042 -> Reporting locations at t=5...                      |   4.93s |  18548 points
2018-05-30 23:47:12,043 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=5,dataset=berlin0-10
2018-05-30 23:47:19,881 -> A.Indexing points... [7.818s] [18548 results]
2018-05-30 23:47:31,475 -> B.Getting pairs... [11.594s] [5765 results]
2018-05-30 23:47:32,701 -> C.Computing centers... [1.226s] [11530 results]
2018-05-30 23:47:33,749 -> D.Indexing centers... [1.048s] [11530 results]
2018-05-30 23:47:41,078 -> E.Getting disks... [7.329s] [11530 results]
2018-05-30 23:47:41,352 -> F.Filtering less-than-mu disks... [0.274s] [1362 results]
2018-05-30 23:47:43,569 -> G.Prunning duplicate candidates... [2.217s] [686 results]
2018-05-30 23:47:43,889 -> H.Indexing candidates... [2.537s] [686 results]
2018-05-30 23:47:44,043 -> I.Getting expansions... [0.154s] [1917 results]
2018-05-30 23:47:44,186 -> J.Finding maximal disks... [0.143s] [237 results]
2018-05-30 23:47:46,210 -> K.Prunning duplicates and subsets... [2.024s] [234 results]
2018-05-30 23:47:46,211 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-30 23:47:46,211 ->   berlin0-10,   18548,  30.0,    28,  4,  34.15,    5765,     11530,          686,        234,  5
2018-05-30 23:47:46,422 -> Dropping indices...[0.211s]
2018-05-30 23:47:46,653 -> 2.Set of disks for t_i+delta...                    |  34.61s |    225 disks
2018-05-30 23:47:53,801 -> 3.Joining timestams                                |   7.15s |    327 candidates
2018-05-30 23:48:03,095 -> Checking internal timestamps                       |   9.29s |    213 flocks
2018-05-30 23:48:09,054 -> Reporting locations at t=4...                      |   4.93s |  18548 points
2018-05-30 23:48:09,299 -> 1.Set of disks for t_i...                          |   0.25s |    238 disks
2018-05-30 23:48:14,195 -> Reporting locations at t=6...                      |   4.90s |  18546 points
2018-05-30 23:48:14,196 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=6,dataset=berlin0-10
2018-05-30 23:48:22,091 -> A.Indexing points... [7.882s] [18546 results]
2018-05-30 23:48:34,226 -> B.Getting pairs... [12.135s] [5758 results]
2018-05-30 23:48:35,544 -> C.Computing centers... [1.318s] [11516 results]
2018-05-30 23:48:36,437 -> D.Indexing centers... [0.893s] [11516 results]
2018-05-30 23:48:43,659 -> E.Getting disks... [7.221s] [11516 results]
2018-05-30 23:48:43,864 -> F.Filtering less-than-mu disks... [0.205s] [1346 results]
2018-05-30 23:48:46,116 -> G.Prunning duplicate candidates... [2.252s] [681 results]
2018-05-30 23:48:46,429 -> H.Indexing candidates... [2.565s] [681 results]
2018-05-30 23:48:46,591 -> I.Getting expansions... [0.162s] [1951 results]
2018-05-30 23:48:46,733 -> J.Finding maximal disks... [0.142s] [225 results]
2018-05-30 23:48:48,904 -> K.Prunning duplicates and subsets... [2.171s] [222 results]
2018-05-30 23:48:48,904 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-30 23:48:48,905 ->   berlin0-10,   18546,  30.0,    28,  4,  34.70,    5758,     11516,          681,        222,  6
2018-05-30 23:48:49,148 -> Dropping indices...[0.243s]
2018-05-30 23:48:49,413 -> 2.Set of disks for t_i+delta...                    |  35.22s |    238 disks
2018-05-30 23:48:56,498 -> 3.Joining timestams                                |   7.09s |    324 candidates
2018-05-30 23:49:05,980 -> Checking internal timestamps                       |   9.48s |    218 flocks
2018-05-30 23:49:12,107 -> Reporting locations at t=5...                      |   4.91s |  18548 points
2018-05-30 23:49:12,299 -> 1.Set of disks for t_i...                          |   0.19s |    234 disks
2018-05-30 23:49:17,161 -> Reporting locations at t=7...                      |   4.86s |  18546 points
2018-05-30 23:49:17,161 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=7,dataset=berlin0-10
2018-05-30 23:49:25,185 -> A.Indexing points... [8.006s] [18546 results]
2018-05-30 23:49:36,648 -> B.Getting pairs... [11.462s] [5788 results]
2018-05-30 23:49:37,895 -> C.Computing centers... [1.247s] [11576 results]
2018-05-30 23:49:38,852 -> D.Indexing centers... [0.956s] [11576 results]
2018-05-30 23:49:46,428 -> E.Getting disks... [7.576s] [11576 results]
2018-05-30 23:49:46,660 -> F.Filtering less-than-mu disks... [0.232s] [1361 results]
2018-05-30 23:49:49,312 -> G.Prunning duplicate candidates... [2.652s] [688 results]
2018-05-30 23:49:49,680 -> H.Indexing candidates... [3.020s] [688 results]
2018-05-30 23:49:49,847 -> I.Getting expansions... [0.167s] [1882 results]
2018-05-30 23:49:49,985 -> J.Finding maximal disks... [0.138s] [233 results]
2018-05-30 23:49:52,049 -> K.Prunning duplicates and subsets... [2.064s] [231 results]
2018-05-30 23:49:52,049 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-30 23:49:52,049 ->   berlin0-10,   18546,  30.0,    28,  4,  34.87,    5788,     11576,          688,        231,  7
2018-05-30 23:49:52,309 -> Dropping indices...[0.260s]
2018-05-30 23:49:52,544 -> 2.Set of disks for t_i+delta...                    |  35.38s |    234 disks
2018-05-30 23:49:59,803 -> 3.Joining timestams                                |   7.26s |    320 candidates
2018-05-30 23:50:09,532 -> Checking internal timestamps                       |   9.73s |    216 flocks
2018-05-30 23:50:15,898 -> Reporting locations at t=6...                      |   5.04s |  18546 points
2018-05-30 23:50:16,100 -> 1.Set of disks for t_i...                          |   0.20s |    222 disks
2018-05-30 23:50:21,028 -> Reporting locations at t=8...                      |   4.93s |  18546 points
2018-05-30 23:50:21,031 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=8,dataset=berlin0-10
2018-05-30 23:50:26,293 -> A.Indexing points... [5.242s] [18546 results]
2018-05-30 23:50:32,993 -> B.Getting pairs... [6.700s] [5791 results]
2018-05-30 23:50:34,258 -> C.Computing centers... [1.265s] [11582 results]
2018-05-30 23:50:35,195 -> D.Indexing centers... [0.937s] [11582 results]
2018-05-30 23:50:40,560 -> E.Getting disks... [5.365s] [11582 results]
2018-05-30 23:50:40,774 -> F.Filtering less-than-mu disks... [0.214s] [1316 results]
2018-05-30 23:50:42,430 -> G.Prunning duplicate candidates... [1.656s] [670 results]
2018-05-30 23:50:42,739 -> H.Indexing candidates... [1.965s] [670 results]
2018-05-30 23:50:42,893 -> I.Getting expansions... [0.154s] [1792 results]
2018-05-30 23:50:43,026 -> J.Finding maximal disks... [0.133s] [220 results]
2018-05-30 23:50:44,415 -> K.Prunning duplicates and subsets... [1.389s] [219 results]
2018-05-30 23:50:44,415 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-30 23:50:44,415 ->   berlin0-10,   18546,  30.0,    28,  4,  23.36,    5791,     11582,          670,        219,  8
2018-05-30 23:50:44,702 -> Dropping indices...[0.287s]
2018-05-30 23:50:44,978 -> 2.Set of disks for t_i+delta...                    |  23.95s |    222 disks
2018-05-30 23:50:51,774 -> 3.Joining timestams                                |   6.80s |    283 candidates
2018-05-30 23:51:01,222 -> Checking internal timestamps                       |   9.45s |    197 flocks
2018-05-30 23:51:07,735 -> Reporting locations at t=7...                      |   4.92s |  18546 points
2018-05-30 23:51:07,977 -> 1.Set of disks for t_i...                          |   0.24s |    231 disks
2018-05-30 23:51:12,780 -> Reporting locations at t=9...                      |   4.80s |  18546 points
2018-05-30 23:51:12,780 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=9,dataset=berlin0-10
2018-05-30 23:51:20,112 -> A.Indexing points... [7.292s] [18546 results]
2018-05-30 23:51:30,267 -> B.Getting pairs... [10.155s] [5802 results]
2018-05-30 23:51:31,518 -> C.Computing centers... [1.251s] [11604 results]
2018-05-30 23:51:32,525 -> D.Indexing centers... [1.007s] [11604 results]
2018-05-30 23:51:39,245 -> E.Getting disks... [6.719s] [11604 results]
2018-05-30 23:51:39,465 -> F.Filtering less-than-mu disks... [0.220s] [1306 results]
2018-05-30 23:51:41,758 -> G.Prunning duplicate candidates... [2.293s] [675 results]
2018-05-30 23:51:42,066 -> H.Indexing candidates... [2.601s] [675 results]
2018-05-30 23:51:42,221 -> I.Getting expansions... [0.150s] [1813 results]
2018-05-30 23:51:42,348 -> J.Finding maximal disks... [0.127s] [212 results]
2018-05-30 23:51:44,459 -> K.Prunning duplicates and subsets... [2.111s] [210 results]
2018-05-30 23:51:44,459 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-30 23:51:44,459 ->   berlin0-10,   18546,  30.0,    28,  4,  31.64,    5802,     11604,          675,        210,  9
2018-05-30 23:51:44,806 -> Dropping indices...[0.347s]
2018-05-30 23:51:45,076 -> 2.Set of disks for t_i+delta...                    |  32.30s |    231 disks
2018-05-30 23:51:53,152 -> 3.Joining timestams                                |   8.08s |    277 candidates
2018-05-30 23:52:02,490 -> Checking internal timestamps                       |   9.34s |    199 flocks
2018-05-30 23:52:09,103 -> Reporting locations at t=8...                      |   4.88s |  18546 points
2018-05-30 23:52:09,298 -> 1.Set of disks for t_i...                          |   0.20s |    219 disks
2018-05-30 23:52:14,076 -> Reporting locations at t=10...                     |   4.78s |  18546 points
2018-05-30 23:52:14,076 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=10,dataset=berlin0-10
2018-05-30 23:52:21,487 -> A.Indexing points... [7.371s] [18546 results]
2018-05-30 23:52:31,538 -> B.Getting pairs... [10.051s] [5797 results]
2018-05-30 23:52:32,936 -> C.Computing centers... [1.398s] [11594 results]
2018-05-30 23:52:33,860 -> D.Indexing centers... [0.924s] [11594 results]
2018-05-30 23:52:41,344 -> E.Getting disks... [7.484s] [11594 results]
2018-05-30 23:52:41,664 -> F.Filtering less-than-mu disks... [0.320s] [1312 results]
2018-05-30 23:52:43,668 -> G.Prunning duplicate candidates... [2.004s] [675 results]
2018-05-30 23:52:43,979 -> H.Indexing candidates... [2.315s] [675 results]
2018-05-30 23:52:44,156 -> I.Getting expansions... [0.176s] [1804 results]
2018-05-30 23:52:44,293 -> J.Finding maximal disks... [0.137s] [212 results]
2018-05-30 23:52:46,135 -> K.Prunning duplicates and subsets... [1.842s] [211 results]
2018-05-30 23:52:46,135 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-30 23:52:46,135 ->   berlin0-10,   18546,  30.0,    28,  4,  32.02,    5797,     11594,          675,        211, 10
2018-05-30 23:52:46,473 -> Dropping indices...[0.338s]
2018-05-30 23:52:46,729 -> 2.Set of disks for t_i+delta...                    |  32.65s |    219 disks
2018-05-30 23:52:53,533 -> 3.Joining timestams                                |   6.80s |    277 candidates
2018-05-30 23:53:02,733 -> Checking internal timestamps                       |   9.20s |    196 flocks
2018-05-30 23:53:04,657 -> 

PFLOCK_ML	30.0	4	3	1868

2018-05-30 23:53:06,465 -> Running MergeLast...                               | 592.78s |   1868 flocks
2018-05-30 23:53:06,466 -> method=MergeLast,cores=28,epsilon=30.0,mu=4,delta=3,time=592.782,master=spark://169.235.27.134:7077
2018-05-30 23:53:06,466 -> Closing app...
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack15: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
FLOCKFINDER=MergeLast;TIME=Wed May 30 23:53:08 PDT 2018;RUN=1527748976;NODES=4;ESTART=;EEND=;ESTEP=;MU=4;DELTA=;SCRIPT=DeltaBenchmarker;EVENT=End
FLOCKFINDER=SpatialJoin;TIME=Wed May 30 23:53:08 PDT 2018;RUN=1527749588;NODES=4;ESTART=;EEND=;ESTEP=;MU=4;DELTA=;SCRIPT=DeltaBenchmarker;EVENT=Start
WARNING:root:Setting 4 nodes...
acald013@dblab-rack12: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack15: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack14: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack11: no org.apache.spark.deploy.worker.Worker to stop
no org.apache.spark.deploy.master.Master to stop
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack15: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack15.out
WARNING:root:4 nodes has been set...
2018-05-30 23:53:15,702 -> Starting app...
2018-05-30 23:53:18,826 -> Starting session                                   |   3.13s |      0 
2018-05-30 23:53:18,841 -> Setting paramaters                                 |   0.01s |      0 
2018-05-30 23:53:21,927 -> Reading data                                       |   3.09s | 203106 points
2018-05-30 23:53:25,116 -> Extracting timestamps                              |   3.19s |     11 timestamps
2018-05-30 23:53:25,122 -> === SpatialJoin Start ===
2018-05-30 23:53:30,720 -> Reporting locations...                             |   5.34s |  18093 points
2018-05-30 23:53:30,737 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=0,dataset=berlin0-10
2018-05-30 23:53:39,654 -> A.Indexing points... [8.867s] [18093 results]
2018-05-30 23:53:47,591 -> B.Getting pairs... [7.937s] [5511 results]
2018-05-30 23:53:49,761 -> C.Computing centers... [2.170s] [11022 results]
2018-05-30 23:53:51,220 -> D.Indexing centers... [1.457s] [11022 results]
2018-05-30 23:53:56,946 -> E.Getting disks... [5.726s] [11022 results]
2018-05-30 23:53:57,296 -> F.Filtering less-than-mu disks... [0.350s] [1210 results]
2018-05-30 23:53:59,614 -> G.Prunning duplicate candidates... [2.317s] [599 results]
2018-05-30 23:54:00,076 -> H.Indexing candidates... [2.779s] [599 results]
2018-05-30 23:54:00,268 -> I.Getting expansions... [0.192s] [1657 results]
2018-05-30 23:54:00,918 -> J.Finding maximal disks... [0.650s] [206 results]
2018-05-30 23:54:02,831 -> K.Prunning duplicates and subsets... [1.913s] [205 results]
2018-05-30 23:54:02,831 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-30 23:54:02,831 ->   berlin0-10,   18093,  30.0,    28,  4,  32.04,    5511,     11022,          599,        205,  0
2018-05-30 23:54:02,923 -> Dropping indices...[0.092s]
2018-05-30 23:54:03,311 -> 1.Set of disks for t_i...                          |  32.59s |    205 disks
2018-05-30 23:54:03,705 -> 4.Found flocks...                                  |   0.39s |      0 flocks
2018-05-30 23:54:04,481 -> 5.Updating times...                                |   0.44s |    205 flocks
2018-05-30 23:54:05,333 -> 6.Filter phase...                                  |   0.85s |    205 flocks
2018-05-30 23:54:10,152 -> Reporting locations...                             |   4.82s |  18245 points
2018-05-30 23:54:10,152 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=1,dataset=berlin0-10
2018-05-30 23:54:15,046 -> A.Indexing points... [4.838s] [18245 results]
2018-05-30 23:54:20,144 -> B.Getting pairs... [5.098s] [5629 results]
2018-05-30 23:54:21,610 -> C.Computing centers... [1.466s] [11258 results]
2018-05-30 23:54:22,671 -> D.Indexing centers... [1.061s] [11258 results]
2018-05-30 23:54:27,981 -> E.Getting disks... [5.310s] [11258 results]
2018-05-30 23:54:28,244 -> F.Filtering less-than-mu disks... [0.262s] [1299 results]
2018-05-30 23:54:29,942 -> G.Prunning duplicate candidates... [1.698s] [640 results]
2018-05-30 23:54:30,277 -> H.Indexing candidates... [2.033s] [640 results]
2018-05-30 23:54:30,473 -> I.Getting expansions... [0.196s] [1703 results]
2018-05-30 23:54:30,627 -> J.Finding maximal disks... [0.154s] [220 results]
2018-05-30 23:54:32,076 -> K.Prunning duplicates and subsets... [1.449s] [216 results]
2018-05-30 23:54:32,076 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-30 23:54:32,076 ->   berlin0-10,   18245,  30.0,    28,  4,  21.87,    5629,     11258,          640,        216,  1
2018-05-30 23:54:32,165 -> Dropping indices...[0.089s]
2018-05-30 23:54:32,433 -> 1.Set of disks for t_i...                          |  22.28s |    216 disks
2018-05-30 23:54:35,779 -> 2.Distance Join phase...                           |   3.35s |    486 combinations
2018-05-30 23:54:38,889 -> 3.Getting candidates...                            |   3.11s |    196 candidates
2018-05-30 23:54:39,605 -> 4.Found flocks...                                  |   0.72s |    196 flocks
2018-05-30 23:54:41,931 -> 5.Updating times...                                |   1.43s |    196 flocks
2018-05-30 23:54:44,694 -> 6.Filter phase...                                  |   2.76s |    236 flocks
2018-05-30 23:54:49,538 -> Reporting locations...                             |   4.84s |  18394 points
2018-05-30 23:54:49,539 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=2,dataset=berlin0-10
2018-05-30 23:54:53,922 -> A.Indexing points... [4.364s] [18394 results]
2018-05-30 23:54:58,741 -> B.Getting pairs... [4.819s] [5701 results]
2018-05-30 23:55:00,098 -> C.Computing centers... [1.357s] [11402 results]
2018-05-30 23:55:01,017 -> D.Indexing centers... [0.919s] [11402 results]
2018-05-30 23:55:05,308 -> E.Getting disks... [4.291s] [11402 results]
2018-05-30 23:55:05,529 -> F.Filtering less-than-mu disks... [0.221s] [1336 results]
2018-05-30 23:55:07,161 -> G.Prunning duplicate candidates... [1.632s] [658 results]
2018-05-30 23:55:07,483 -> H.Indexing candidates... [1.954s] [658 results]
2018-05-30 23:55:07,638 -> I.Getting expansions... [0.155s] [1757 results]
2018-05-30 23:55:07,783 -> J.Finding maximal disks... [0.144s] [232 results]
2018-05-30 23:55:09,212 -> K.Prunning duplicates and subsets... [1.429s] [227 results]
2018-05-30 23:55:09,212 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-30 23:55:09,213 ->   berlin0-10,   18394,  30.0,    28,  4,  19.65,    5701,     11402,          658,        227,  2
2018-05-30 23:55:09,370 -> Dropping indices...[0.157s]
2018-05-30 23:55:09,667 -> 1.Set of disks for t_i...                          |  20.13s |    227 disks
2018-05-30 23:55:16,375 -> 2.Distance Join phase...                           |   6.71s |    648 combinations
2018-05-30 23:55:20,662 -> 3.Getting candidates...                            |   4.29s |    218 candidates
2018-05-30 23:55:21,322 -> 4.Found flocks...                                  |   0.66s |    218 flocks
2018-05-30 23:55:23,728 -> 5.Updating times...                                |   1.11s |    218 flocks
2018-05-30 23:55:25,513 -> 6.Filter phase...                                  |   1.79s |    248 flocks
2018-05-30 23:55:30,345 -> Reporting locations...                             |   4.83s |  18548 points
2018-05-30 23:55:30,345 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=3,dataset=berlin0-10
2018-05-30 23:55:37,370 -> A.Indexing points... [7.005s] [18548 results]
2018-05-30 23:55:46,872 -> B.Getting pairs... [9.502s] [5768 results]
2018-05-30 23:55:48,148 -> C.Computing centers... [1.276s] [11536 results]
2018-05-30 23:55:49,591 -> D.Indexing centers... [1.443s] [11536 results]
2018-05-30 23:55:56,084 -> E.Getting disks... [6.493s] [11536 results]
2018-05-30 23:55:56,295 -> F.Filtering less-than-mu disks... [0.211s] [1349 results]
2018-05-30 23:55:58,254 -> G.Prunning duplicate candidates... [1.959s] [675 results]
2018-05-30 23:55:58,573 -> H.Indexing candidates... [2.278s] [675 results]
2018-05-30 23:55:58,713 -> I.Getting expansions... [0.140s] [1875 results]
2018-05-30 23:55:58,856 -> J.Finding maximal disks... [0.143s] [230 results]
2018-05-30 23:56:00,264 -> K.Prunning duplicates and subsets... [1.407s] [225 results]
2018-05-30 23:56:00,264 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-30 23:56:00,264 ->   berlin0-10,   18548,  30.0,    28,  4,  29.90,    5768,     11536,          675,        225,  3
2018-05-30 23:56:00,477 -> Dropping indices...[0.213s]
2018-05-30 23:56:00,723 -> 1.Set of disks for t_i...                          |  30.38s |    225 disks
2018-05-30 23:56:06,984 -> 2.Distance Join phase...                           |   6.26s |    671 combinations
2018-05-30 23:56:11,011 -> 3.Getting candidates...                            |   4.03s |    220 candidates
2018-05-30 23:56:11,828 -> 4.Found flocks...                                  |   0.82s |    220 flocks
2018-05-30 23:56:15,069 -> 5.Updating times...                                |   1.35s |    220 flocks
2018-05-30 23:56:17,063 -> 6.Filter phase...                                  |   1.99s |    250 flocks
2018-05-30 23:56:21,871 -> Reporting locations...                             |   4.81s |  18548 points
2018-05-30 23:56:21,871 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=4,dataset=berlin0-10
2018-05-30 23:56:28,734 -> A.Indexing points... [6.844s] [18548 results]
2018-05-30 23:56:38,163 -> B.Getting pairs... [9.429s] [5775 results]
2018-05-30 23:56:39,511 -> C.Computing centers... [1.348s] [11550 results]
2018-05-30 23:56:40,516 -> D.Indexing centers... [1.005s] [11550 results]
2018-05-30 23:56:47,157 -> E.Getting disks... [6.641s] [11550 results]
2018-05-30 23:56:47,377 -> F.Filtering less-than-mu disks... [0.220s] [1369 results]
2018-05-30 23:56:49,408 -> G.Prunning duplicate candidates... [2.031s] [694 results]
2018-05-30 23:56:49,716 -> H.Indexing candidates... [2.339s] [694 results]
2018-05-30 23:56:49,875 -> I.Getting expansions... [0.159s] [1914 results]
2018-05-30 23:56:50,030 -> J.Finding maximal disks... [0.154s] [245 results]
2018-05-30 23:56:52,247 -> K.Prunning duplicates and subsets... [2.217s] [238 results]
2018-05-30 23:56:52,247 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-30 23:56:52,247 ->   berlin0-10,   18548,  30.0,    28,  4,  30.36,    5775,     11550,          694,        238,  4
2018-05-30 23:56:52,479 -> Dropping indices...[0.232s]
2018-05-30 23:56:52,715 -> 1.Set of disks for t_i...                          |  30.84s |    238 disks
2018-05-30 23:56:59,795 -> 2.Distance Join phase...                           |   7.08s |    701 combinations
2018-05-30 23:57:04,255 -> 3.Getting candidates...                            |   4.46s |    224 candidates
2018-05-30 23:57:05,311 -> 4.Found flocks...                                  |   1.06s |    224 flocks
2018-05-30 23:57:09,190 -> 5.Updating times...                                |   1.38s |    224 flocks
2018-05-30 23:57:11,513 -> 6.Filter phase...                                  |   2.32s |    249 flocks
2018-05-30 23:57:16,266 -> Reporting locations...                             |   4.75s |  18548 points
2018-05-30 23:57:16,266 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=5,dataset=berlin0-10
2018-05-30 23:57:23,054 -> A.Indexing points... [6.768s] [18548 results]
2018-05-30 23:57:32,667 -> B.Getting pairs... [9.613s] [5765 results]
2018-05-30 23:57:33,956 -> C.Computing centers... [1.289s] [11530 results]
2018-05-30 23:57:34,929 -> D.Indexing centers... [0.973s] [11530 results]
2018-05-30 23:57:41,578 -> E.Getting disks... [6.649s] [11530 results]
2018-05-30 23:57:41,781 -> F.Filtering less-than-mu disks... [0.203s] [1362 results]
2018-05-30 23:57:43,754 -> G.Prunning duplicate candidates... [1.973s] [686 results]
2018-05-30 23:57:44,058 -> H.Indexing candidates... [2.277s] [686 results]
2018-05-30 23:57:44,214 -> I.Getting expansions... [0.156s] [1917 results]
2018-05-30 23:57:44,349 -> J.Finding maximal disks... [0.134s] [237 results]
2018-05-30 23:57:46,277 -> K.Prunning duplicates and subsets... [1.928s] [234 results]
2018-05-30 23:57:46,277 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-30 23:57:46,277 ->   berlin0-10,   18548,  30.0,    28,  4,  29.99,    5765,     11530,          686,        234,  5
2018-05-30 23:57:46,562 -> Dropping indices...[0.284s]
2018-05-30 23:57:46,801 -> 1.Set of disks for t_i...                          |  30.54s |    234 disks
2018-05-30 23:57:54,468 -> 2.Distance Join phase...                           |   7.67s |    630 combinations
2018-05-30 23:57:59,193 -> 3.Getting candidates...                            |   4.73s |    230 candidates
2018-05-30 23:58:00,195 -> 4.Found flocks...                                  |   1.00s |    230 flocks
2018-05-30 23:58:04,951 -> 5.Updating times...                                |   1.48s |    230 flocks
2018-05-30 23:58:07,176 -> 6.Filter phase...                                  |   2.23s |    259 flocks
2018-05-30 23:58:11,965 -> Reporting locations...                             |   4.79s |  18546 points
2018-05-30 23:58:11,965 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=6,dataset=berlin0-10
2018-05-30 23:58:18,949 -> A.Indexing points... [6.965s] [18546 results]
2018-05-30 23:58:28,502 -> B.Getting pairs... [9.553s] [5758 results]
2018-05-30 23:58:29,758 -> C.Computing centers... [1.256s] [11516 results]
2018-05-30 23:58:30,675 -> D.Indexing centers... [0.917s] [11516 results]
2018-05-30 23:58:37,342 -> E.Getting disks... [6.666s] [11516 results]
2018-05-30 23:58:37,561 -> F.Filtering less-than-mu disks... [0.219s] [1346 results]
2018-05-30 23:58:40,448 -> G.Prunning duplicate candidates... [2.887s] [681 results]
2018-05-30 23:58:40,756 -> H.Indexing candidates... [3.195s] [681 results]
2018-05-30 23:58:40,923 -> I.Getting expansions... [0.167s] [1951 results]
2018-05-30 23:58:41,060 -> J.Finding maximal disks... [0.137s] [225 results]
2018-05-30 23:58:42,906 -> K.Prunning duplicates and subsets... [1.846s] [222 results]
2018-05-30 23:58:42,906 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-30 23:58:42,907 ->   berlin0-10,   18546,  30.0,    28,  4,  30.92,    5758,     11516,          681,        222,  6
2018-05-30 23:58:43,368 -> Dropping indices...[0.461s]
2018-05-30 23:58:43,637 -> 1.Set of disks for t_i...                          |  31.67s |    222 disks
2018-05-30 23:58:51,825 -> 2.Distance Join phase...                           |   8.19s |    619 combinations
2018-05-30 23:58:56,596 -> 3.Getting candidates...                            |   4.77s |    224 candidates
2018-05-30 23:58:57,725 -> 4.Found flocks...                                  |   1.13s |    224 flocks
2018-05-30 23:59:04,365 -> 5.Updating times...                                |   1.55s |    224 flocks
2018-05-30 23:59:06,660 -> 6.Filter phase...                                  |   2.30s |    247 flocks
2018-05-30 23:59:11,492 -> Reporting locations...                             |   4.83s |  18546 points
2018-05-30 23:59:11,492 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=7,dataset=berlin0-10
2018-05-30 23:59:18,436 -> A.Indexing points... [6.925s] [18546 results]
2018-05-30 23:59:28,085 -> B.Getting pairs... [9.648s] [5788 results]
2018-05-30 23:59:29,386 -> C.Computing centers... [1.301s] [11576 results]
2018-05-30 23:59:30,328 -> D.Indexing centers... [0.941s] [11576 results]
2018-05-30 23:59:36,925 -> E.Getting disks... [6.597s] [11576 results]
2018-05-30 23:59:37,164 -> F.Filtering less-than-mu disks... [0.239s] [1361 results]
2018-05-30 23:59:39,196 -> G.Prunning duplicate candidates... [2.032s] [688 results]
2018-05-30 23:59:39,499 -> H.Indexing candidates... [2.335s] [688 results]
2018-05-30 23:59:39,649 -> I.Getting expansions... [0.150s] [1882 results]
2018-05-30 23:59:39,776 -> J.Finding maximal disks... [0.127s] [233 results]
2018-05-30 23:59:41,563 -> K.Prunning duplicates and subsets... [1.786s] [231 results]
2018-05-30 23:59:41,563 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-30 23:59:41,563 ->   berlin0-10,   18546,  30.0,    28,  4,  30.05,    5788,     11576,          688,        231,  7
2018-05-30 23:59:42,024 -> Dropping indices...[0.461s]
2018-05-30 23:59:42,276 -> 1.Set of disks for t_i...                          |  30.78s |    231 disks
2018-05-30 23:59:50,612 -> 2.Distance Join phase...                           |   8.34s |    597 combinations
2018-05-30 23:59:55,329 -> 3.Getting candidates...                            |   4.72s |    213 candidates
2018-05-30 23:59:56,525 -> 4.Found flocks...                                  |   1.20s |    213 flocks
2018-05-31 00:00:02,644 -> 5.Updating times...                                |   1.65s |    213 flocks
2018-05-31 00:00:05,122 -> 6.Filter phase...                                  |   2.48s |    244 flocks
2018-05-31 00:00:09,850 -> Reporting locations...                             |   4.73s |  18546 points
2018-05-31 00:00:09,850 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=8,dataset=berlin0-10
2018-05-31 00:00:14,056 -> A.Indexing points... [4.188s] [18546 results]
2018-05-31 00:00:19,669 -> B.Getting pairs... [5.613s] [5791 results]
2018-05-31 00:00:20,936 -> C.Computing centers... [1.267s] [11582 results]
2018-05-31 00:00:21,954 -> D.Indexing centers... [1.018s] [11582 results]
2018-05-31 00:00:27,324 -> E.Getting disks... [5.369s] [11582 results]
2018-05-31 00:00:27,628 -> F.Filtering less-than-mu disks... [0.304s] [1316 results]
2018-05-31 00:00:29,458 -> G.Prunning duplicate candidates... [1.830s] [670 results]
2018-05-31 00:00:29,811 -> H.Indexing candidates... [2.183s] [670 results]
2018-05-31 00:00:30,019 -> I.Getting expansions... [0.208s] [1792 results]
2018-05-31 00:00:30,161 -> J.Finding maximal disks... [0.141s] [220 results]
2018-05-31 00:00:31,821 -> K.Prunning duplicates and subsets... [1.660s] [219 results]
2018-05-31 00:00:31,822 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:00:31,822 ->   berlin0-10,   18546,  30.0,    28,  4,  21.95,    5791,     11582,          670,        219,  8
2018-05-31 00:00:32,380 -> Dropping indices...[0.558s]
2018-05-31 00:00:32,630 -> 1.Set of disks for t_i...                          |  22.78s |    219 disks
2018-05-31 00:00:41,567 -> 2.Distance Join phase...                           |   8.94s |    520 combinations
2018-05-31 00:00:46,589 -> 3.Getting candidates...                            |   5.02s |    211 candidates
2018-05-31 00:00:47,931 -> 4.Found flocks...                                  |   1.34s |    211 flocks
2018-05-31 00:00:54,832 -> 5.Updating times...                                |   1.82s |    211 flocks
2018-05-31 00:00:59,121 -> 6.Filter phase...                                  |   4.29s |    232 flocks
2018-05-31 00:01:03,809 -> Reporting locations...                             |   4.69s |  18546 points
2018-05-31 00:01:03,810 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=9,dataset=berlin0-10
2018-05-31 00:01:10,848 -> A.Indexing points... [7.003s] [18546 results]
2018-05-31 00:01:21,014 -> B.Getting pairs... [10.166s] [5802 results]
2018-05-31 00:01:22,326 -> C.Computing centers... [1.312s] [11604 results]
2018-05-31 00:01:23,360 -> D.Indexing centers... [1.034s] [11604 results]
2018-05-31 00:01:29,938 -> E.Getting disks... [6.578s] [11604 results]
2018-05-31 00:01:30,139 -> F.Filtering less-than-mu disks... [0.201s] [1306 results]
2018-05-31 00:01:32,215 -> G.Prunning duplicate candidates... [2.076s] [675 results]
2018-05-31 00:01:32,527 -> H.Indexing candidates... [2.388s] [675 results]
2018-05-31 00:01:32,700 -> I.Getting expansions... [0.173s] [1813 results]
2018-05-31 00:01:32,832 -> J.Finding maximal disks... [0.132s] [212 results]
2018-05-31 00:01:34,573 -> K.Prunning duplicates and subsets... [1.741s] [210 results]
2018-05-31 00:01:34,573 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:01:34,573 ->   berlin0-10,   18546,  30.0,    28,  4,  30.73,    5802,     11604,          675,        210,  9
2018-05-31 00:01:35,188 -> Dropping indices...[0.614s]
2018-05-31 00:01:35,497 -> 1.Set of disks for t_i...                          |  31.69s |    210 disks
2018-05-31 00:01:44,842 -> 2.Distance Join phase...                           |   9.34s |    474 combinations
2018-05-31 00:01:50,290 -> 3.Getting candidates...                            |   5.45s |    206 candidates
2018-05-31 00:01:51,912 -> 4.Found flocks...                                  |   1.62s |    206 flocks
2018-05-31 00:02:00,301 -> 5.Updating times...                                |   2.15s |    206 flocks
2018-05-31 00:02:03,658 -> 6.Filter phase...                                  |   3.36s |    226 flocks
2018-05-31 00:02:08,404 -> Reporting locations...                             |   4.75s |  18546 points
2018-05-31 00:02:08,404 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=10,dataset=berlin0-10
2018-05-31 00:02:15,322 -> A.Indexing points... [6.883s] [18546 results]
2018-05-31 00:02:25,380 -> B.Getting pairs... [10.058s] [5797 results]
2018-05-31 00:02:26,646 -> C.Computing centers... [1.266s] [11594 results]
2018-05-31 00:02:27,664 -> D.Indexing centers... [1.018s] [11594 results]
2018-05-31 00:02:34,336 -> E.Getting disks... [6.672s] [11594 results]
2018-05-31 00:02:34,591 -> F.Filtering less-than-mu disks... [0.255s] [1312 results]
2018-05-31 00:02:36,842 -> G.Prunning duplicate candidates... [2.251s] [675 results]
2018-05-31 00:02:37,162 -> H.Indexing candidates... [2.571s] [675 results]
2018-05-31 00:02:37,360 -> I.Getting expansions... [0.198s] [1804 results]
2018-05-31 00:02:37,497 -> J.Finding maximal disks... [0.137s] [212 results]
2018-05-31 00:02:39,226 -> K.Prunning duplicates and subsets... [1.729s] [211 results]
2018-05-31 00:02:39,226 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:02:39,226 ->   berlin0-10,   18546,  30.0,    28,  4,  30.79,    5797,     11594,          675,        211, 10
2018-05-31 00:02:39,861 -> Dropping indices...[0.635s]
2018-05-31 00:02:40,123 -> 1.Set of disks for t_i...                          |  31.72s |    211 disks
2018-05-31 00:02:51,044 -> 2.Distance Join phase...                           |  10.92s |    457 combinations
2018-05-31 00:02:56,872 -> 3.Getting candidates...                            |   5.83s |    197 candidates
2018-05-31 00:02:58,339 -> 4.Found flocks...                                  |   1.47s |    197 flocks
2018-05-31 00:03:06,798 -> 5.Updating times...                                |   1.82s |    197 flocks
2018-05-31 00:03:09,313 -> 6.Filter phase...                                  |   2.52s |    221 flocks
2018-05-31 00:03:09,313 -> 

PFLOCK_SJ	30.0	4	2	2139

2018-05-31 00:03:15,035 -> Running SpatialJoin...                             | 589.91s |   2139 flocks
2018-05-31 00:03:15,035 -> method=SpatialJoin,cores=28,epsilon=30.0,mu=4,delta=2,time=589.913,master=spark://169.235.27.134:7077
2018-05-31 00:03:15,035 -> Closing app...
acald013@dblab-rack15: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
FLOCKFINDER=SpatialJoin;TIME=Thu May 31 00:03:21 PDT 2018;RUN=1527749588;NODES=4;ESTART=;EEND=;ESTEP=;MU=4;DELTA=;SCRIPT=DeltaBenchmarker;EVENT=End
FLOCKFINDER=MergeLast;TIME=Thu May 31 00:03:21 PDT 2018;RUN=1527750201;NODES=4;ESTART=;EEND=;ESTEP=;MU=4;DELTA=;SCRIPT=DeltaBenchmarker;EVENT=Start
WARNING:root:Setting 4 nodes...
acald013@dblab-rack15: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack12: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack14: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack11: no org.apache.spark.deploy.worker.Worker to stop
no org.apache.spark.deploy.master.Master to stop
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack15: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack15.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
WARNING:root:4 nodes has been set...
2018-05-31 00:03:28,391 -> Starting app...
2018-05-31 00:03:31,167 -> Starting session                                   |   2.78s |      0 
2018-05-31 00:03:31,182 -> Setting paramaters                                 |   0.01s |      0 
2018-05-31 00:03:34,295 -> Reading data                                       |   3.11s | 203106 points
2018-05-31 00:03:37,665 -> Extracting timestamps                              |   3.37s |     11 timestamps
2018-05-31 00:03:37,673 -> === MergeLast Start ===
2018-05-31 00:03:43,096 -> Reporting locations at t=0...                      |   5.27s |  18093 points
2018-05-31 00:03:43,108 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=0,dataset=berlin0-10
2018-05-31 00:03:51,240 -> A.Indexing points... [8.066s] [18093 results]
2018-05-31 00:03:58,335 -> B.Getting pairs... [7.095s] [5511 results]
2018-05-31 00:04:00,289 -> C.Computing centers... [1.954s] [11022 results]
2018-05-31 00:04:01,804 -> D.Indexing centers... [1.515s] [11022 results]
2018-05-31 00:04:07,564 -> E.Getting disks... [5.760s] [11022 results]
2018-05-31 00:04:07,985 -> F.Filtering less-than-mu disks... [0.421s] [1210 results]
2018-05-31 00:04:10,835 -> G.Prunning duplicate candidates... [2.850s] [599 results]
2018-05-31 00:04:11,278 -> H.Indexing candidates... [3.293s] [599 results]
2018-05-31 00:04:11,484 -> I.Getting expansions... [0.206s] [1657 results]
2018-05-31 00:04:12,100 -> J.Finding maximal disks... [0.616s] [206 results]
2018-05-31 00:04:13,911 -> K.Prunning duplicates and subsets... [1.811s] [205 results]
2018-05-31 00:04:13,911 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:04:13,911 ->   berlin0-10,   18093,  30.0,    28,  4,  30.74,    5511,     11022,          599,        205,  0
2018-05-31 00:04:13,995 -> Dropping indices...[0.083s]
2018-05-31 00:04:14,351 -> 1.Set of disks for t_i...                          |  31.26s |    205 disks
2018-05-31 00:04:19,623 -> Reporting locations at t=1...                      |   5.27s |  18245 points
2018-05-31 00:04:19,624 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=1,dataset=berlin0-10
2018-05-31 00:04:24,563 -> A.Indexing points... [4.901s] [18245 results]
2018-05-31 00:04:30,051 -> B.Getting pairs... [5.488s] [5629 results]
2018-05-31 00:04:31,408 -> C.Computing centers... [1.357s] [11258 results]
2018-05-31 00:04:32,452 -> D.Indexing centers... [1.043s] [11258 results]
2018-05-31 00:04:37,204 -> E.Getting disks... [4.752s] [11258 results]
2018-05-31 00:04:37,493 -> F.Filtering less-than-mu disks... [0.289s] [1299 results]
2018-05-31 00:04:38,949 -> G.Prunning duplicate candidates... [1.456s] [640 results]
2018-05-31 00:04:39,306 -> H.Indexing candidates... [1.813s] [640 results]
2018-05-31 00:04:39,463 -> I.Getting expansions... [0.157s] [1703 results]
2018-05-31 00:04:39,794 -> J.Finding maximal disks... [0.331s] [220 results]
2018-05-31 00:04:41,181 -> K.Prunning duplicates and subsets... [1.387s] [216 results]
2018-05-31 00:04:41,181 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:04:41,182 ->   berlin0-10,   18245,  30.0,    28,  4,  21.52,    5629,     11258,          640,        216,  1
2018-05-31 00:04:41,253 -> Dropping indices...[0.071s]
2018-05-31 00:04:41,522 -> 2.Set of disks for t_i+delta...                    |  21.90s |    205 disks
2018-05-31 00:04:50,197 -> 3.Joining timestams                                |   8.68s |    319 candidates
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 23 in stage 1467.0 failed 4 times, most recent failure: Lost task 23.3 in stage 1467.0 (TID 66187, 169.235.27.134, executor 2): java.util.NoSuchElementException: head of empty list
	at scala.collection.immutable.Nil$.head(List.scala:420)
	at scala.collection.immutable.Nil$.head(List.scala:417)
	at scala.collection.generic.TraversableForwarder$class.head(TraversableForwarder.scala:56)
	at scala.collection.mutable.ListBuffer.head(ListBuffer.scala:45)
	at FlockFinderMergeLast$.computeMaximalDisks(FlockFinderMergeLast.scala:277)
	at FlockFinderMergeLast$$anonfun$runMergeLast$1$$anonfun$13.apply(FlockFinderMergeLast.scala:221)
	at FlockFinderMergeLast$$anonfun$runMergeLast$1$$anonfun$13.apply(FlockFinderMergeLast.scala:219)
	at org.apache.spark.sql.execution.MapElementsExec$$anonfun$8$$anonfun$apply$1.apply(objects.scala:237)
	at org.apache.spark.sql.execution.MapElementsExec$$anonfun$8$$anonfun$apply$1.apply(objects.scala:237)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.columnar.InMemoryRelation$$anonfun$1$$anon$1.hasNext(InMemoryRelation.scala:138)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:215)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:957)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:948)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:888)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:948)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:694)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:334)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1958)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:935)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:934)
	at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:275)
	at org.apache.spark.sql.Dataset$$anonfun$org$apache$spark$sql$Dataset$$execute$1$1.apply(Dataset.scala:2371)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:57)
	at org.apache.spark.sql.Dataset.withNewExecutionId(Dataset.scala:2765)
	at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$execute$1(Dataset.scala:2370)
	at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collect(Dataset.scala:2377)
	at org.apache.spark.sql.Dataset$$anonfun$count$1.apply(Dataset.scala:2405)
	at org.apache.spark.sql.Dataset$$anonfun$count$1.apply(Dataset.scala:2404)
	at org.apache.spark.sql.Dataset.withCallback(Dataset.scala:2778)
	at org.apache.spark.sql.Dataset.count(Dataset.scala:2404)
	at FlockFinderMergeLast$$anonfun$runMergeLast$1.apply(FlockFinderMergeLast.scala:228)
	at FlockFinderMergeLast$$anonfun$runMergeLast$1.apply(FlockFinderMergeLast.scala:121)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at FlockFinderMergeLast$.runMergeLast(FlockFinderMergeLast.scala:121)
	at FlockFinderMergeLast$$anonfun$run$1$$anonfun$apply$mcVI$sp$1$$anonfun$apply$mcVI$sp$2.apply$mcVD$sp(FlockFinderMergeLast.scala:91)
	at FlockFinderMergeLast$$anonfun$run$1$$anonfun$apply$mcVI$sp$1$$anonfun$apply$mcVI$sp$2.apply(FlockFinderMergeLast.scala:86)
	at FlockFinderMergeLast$$anonfun$run$1$$anonfun$apply$mcVI$sp$1$$anonfun$apply$mcVI$sp$2.apply(FlockFinderMergeLast.scala:86)
	at scala.collection.immutable.NumericRange.foreach(NumericRange.scala:73)
	at FlockFinderMergeLast$$anonfun$run$1$$anonfun$apply$mcVI$sp$1.apply$mcVI$sp(FlockFinderMergeLast.scala:86)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at FlockFinderMergeLast$$anonfun$run$1.apply$mcVI$sp(FlockFinderMergeLast.scala:86)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at FlockFinderMergeLast$.run(FlockFinderMergeLast.scala:86)
	at FlockFinderMergeLast$.main(FlockFinderMergeLast.scala:585)
	at FlockFinderMergeLast.main(FlockFinderMergeLast.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: java.util.NoSuchElementException: head of empty list
	at scala.collection.immutable.Nil$.head(List.scala:420)
	at scala.collection.immutable.Nil$.head(List.scala:417)
	at scala.collection.generic.TraversableForwarder$class.head(TraversableForwarder.scala:56)
	at scala.collection.mutable.ListBuffer.head(ListBuffer.scala:45)
	at FlockFinderMergeLast$.computeMaximalDisks(FlockFinderMergeLast.scala:277)
	at FlockFinderMergeLast$$anonfun$runMergeLast$1$$anonfun$13.apply(FlockFinderMergeLast.scala:221)
	at FlockFinderMergeLast$$anonfun$runMergeLast$1$$anonfun$13.apply(FlockFinderMergeLast.scala:219)
	at org.apache.spark.sql.execution.MapElementsExec$$anonfun$8$$anonfun$apply$1.apply(objects.scala:237)
	at org.apache.spark.sql.execution.MapElementsExec$$anonfun$8$$anonfun$apply$1.apply(objects.scala:237)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.columnar.InMemoryRelation$$anonfun$1$$anon$1.hasNext(InMemoryRelation.scala:138)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:215)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:957)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:948)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:888)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:948)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:694)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:334)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack15: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
FLOCKFINDER=MergeLast;TIME=Thu May 31 00:05:00 PDT 2018;RUN=1527750201;NODES=4;ESTART=;EEND=;ESTEP=;MU=4;DELTA=;SCRIPT=DeltaBenchmarker;EVENT=End
FLOCKFINDER=SpatialJoin;TIME=Thu May 31 00:05:00 PDT 2018;RUN=1527750300;NODES=4;ESTART=;EEND=;ESTEP=;MU=4;DELTA=;SCRIPT=DeltaBenchmarker;EVENT=Start
WARNING:root:Setting 4 nodes...
acald013@dblab-rack12: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack15: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack14: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack11: no org.apache.spark.deploy.worker.Worker to stop
no org.apache.spark.deploy.master.Master to stop
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack15: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack15.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
WARNING:root:4 nodes has been set...
2018-05-31 00:05:08,006 -> Starting app...
2018-05-31 00:05:10,838 -> Starting session                                   |   2.83s |      0 
2018-05-31 00:05:10,852 -> Setting paramaters                                 |   0.01s |      0 
2018-05-31 00:05:13,989 -> Reading data                                       |   3.14s | 203106 points
2018-05-31 00:05:17,232 -> Extracting timestamps                              |   3.24s |     11 timestamps
2018-05-31 00:05:17,241 -> === SpatialJoin Start ===
2018-05-31 00:05:22,915 -> Reporting locations...                             |   5.43s |  18093 points
2018-05-31 00:05:22,930 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=0,dataset=berlin0-10
2018-05-31 00:05:31,179 -> A.Indexing points... [8.201s] [18093 results]
2018-05-31 00:05:38,469 -> B.Getting pairs... [7.289s] [5511 results]
2018-05-31 00:05:40,509 -> C.Computing centers... [2.039s] [11022 results]
2018-05-31 00:05:41,935 -> D.Indexing centers... [1.426s] [11022 results]
2018-05-31 00:05:47,851 -> E.Getting disks... [5.916s] [11022 results]
2018-05-31 00:05:48,217 -> F.Filtering less-than-mu disks... [0.366s] [1210 results]
2018-05-31 00:05:50,609 -> G.Prunning duplicate candidates... [2.392s] [599 results]
2018-05-31 00:05:51,089 -> H.Indexing candidates... [2.872s] [599 results]
2018-05-31 00:05:51,287 -> I.Getting expansions... [0.198s] [1657 results]
2018-05-31 00:05:51,941 -> J.Finding maximal disks... [0.654s] [206 results]
2018-05-31 00:05:53,753 -> K.Prunning duplicates and subsets... [1.812s] [205 results]
2018-05-31 00:05:53,753 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:05:53,753 ->   berlin0-10,   18093,  30.0,    28,  4,  30.78,    5511,     11022,          599,        205,  0
2018-05-31 00:05:53,825 -> Dropping indices...[0.072s]
2018-05-31 00:05:54,164 -> 1.Set of disks for t_i...                          |  31.25s |    205 disks
2018-05-31 00:05:54,538 -> 4.Found flocks...                                  |   0.37s |      0 flocks
2018-05-31 00:05:55,360 -> 5.Updating times...                                |   0.53s |    205 flocks
2018-05-31 00:05:56,282 -> 6.Filter phase...                                  |   0.92s |    205 flocks
2018-05-31 00:06:00,874 -> Reporting locations...                             |   4.59s |  18245 points
2018-05-31 00:06:00,874 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=1,dataset=berlin0-10
2018-05-31 00:06:05,348 -> A.Indexing points... [4.452s] [18245 results]
2018-05-31 00:06:10,578 -> B.Getting pairs... [5.230s] [5629 results]
2018-05-31 00:06:12,013 -> C.Computing centers... [1.435s] [11258 results]
2018-05-31 00:06:13,210 -> D.Indexing centers... [1.197s] [11258 results]
2018-05-31 00:06:19,206 -> E.Getting disks... [5.996s] [11258 results]
2018-05-31 00:06:19,863 -> F.Filtering less-than-mu disks... [0.657s] [1299 results]
2018-05-31 00:06:23,131 -> G.Prunning duplicate candidates... [3.268s] [640 results]
2018-05-31 00:06:23,540 -> H.Indexing candidates... [3.677s] [640 results]
2018-05-31 00:06:23,819 -> I.Getting expansions... [0.279s] [1703 results]
2018-05-31 00:06:24,216 -> J.Finding maximal disks... [0.397s] [220 results]
2018-05-31 00:06:26,551 -> K.Prunning duplicates and subsets... [2.335s] [216 results]
2018-05-31 00:06:26,551 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:06:26,552 ->   berlin0-10,   18245,  30.0,    28,  4,  25.66,    5629,     11258,          640,        216,  1
2018-05-31 00:06:26,640 -> Dropping indices...[0.088s]
2018-05-31 00:06:27,009 -> 1.Set of disks for t_i...                          |  26.14s |    216 disks
2018-05-31 00:06:31,047 -> 2.Distance Join phase...                           |   4.04s |    645 combinations
2018-05-31 00:06:34,488 -> 3.Getting candidates...                            |   3.44s |    196 candidates
2018-05-31 00:06:35,246 -> 4.Found flocks...                                  |   0.76s |      0 flocks
2018-05-31 00:06:37,812 -> 5.Updating times...                                |   1.59s |    196 flocks
2018-05-31 00:06:40,629 -> 6.Filter phase...                                  |   2.82s |    236 flocks
2018-05-31 00:06:45,131 -> Reporting locations...                             |   4.50s |  18394 points
2018-05-31 00:06:45,132 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=2,dataset=berlin0-10
2018-05-31 00:06:49,519 -> A.Indexing points... [4.366s] [18394 results]
2018-05-31 00:06:54,041 -> B.Getting pairs... [4.522s] [5701 results]
2018-05-31 00:06:55,324 -> C.Computing centers... [1.283s] [11402 results]
2018-05-31 00:06:56,208 -> D.Indexing centers... [0.884s] [11402 results]
2018-05-31 00:07:00,537 -> E.Getting disks... [4.329s] [11402 results]
2018-05-31 00:07:00,778 -> F.Filtering less-than-mu disks... [0.240s] [1336 results]
2018-05-31 00:07:02,233 -> G.Prunning duplicate candidates... [1.455s] [658 results]
2018-05-31 00:07:02,564 -> H.Indexing candidates... [1.786s] [658 results]
2018-05-31 00:07:02,711 -> I.Getting expansions... [0.147s] [1757 results]
2018-05-31 00:07:02,858 -> J.Finding maximal disks... [0.147s] [232 results]
2018-05-31 00:07:04,094 -> K.Prunning duplicates and subsets... [1.236s] [227 results]
2018-05-31 00:07:04,094 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:07:04,095 ->   berlin0-10,   18394,  30.0,    28,  4,  18.94,    5701,     11402,          658,        227,  2
2018-05-31 00:07:04,258 -> Dropping indices...[0.163s]
2018-05-31 00:07:04,587 -> 1.Set of disks for t_i...                          |  19.46s |    227 disks
2018-05-31 00:07:12,258 -> 2.Distance Join phase...                           |   7.67s |    902 combinations
2018-05-31 00:07:17,132 -> 3.Getting candidates...                            |   4.87s |    239 candidates
2018-05-31 00:07:17,882 -> 4.Found flocks...                                  |   0.75s |    199 flocks
2018-05-31 00:07:20,444 -> 5.Updating times...                                |   1.08s |    239 flocks
2018-05-31 00:07:22,427 -> 6.Filter phase...                                  |   1.98s |    268 flocks
2018-05-31 00:07:26,833 -> Reporting locations...                             |   4.41s |  18548 points
2018-05-31 00:07:26,834 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=3,dataset=berlin0-10
2018-05-31 00:07:33,699 -> A.Indexing points... [6.848s] [18548 results]
2018-05-31 00:07:43,247 -> B.Getting pairs... [9.548s] [5768 results]
2018-05-31 00:07:44,613 -> C.Computing centers... [1.366s] [11536 results]
2018-05-31 00:07:45,487 -> D.Indexing centers... [0.874s] [11536 results]
2018-05-31 00:07:52,129 -> E.Getting disks... [6.642s] [11536 results]
2018-05-31 00:07:52,370 -> F.Filtering less-than-mu disks... [0.241s] [1349 results]
2018-05-31 00:07:54,339 -> G.Prunning duplicate candidates... [1.969s] [675 results]
2018-05-31 00:07:54,677 -> H.Indexing candidates... [2.307s] [675 results]
2018-05-31 00:07:54,845 -> I.Getting expansions... [0.168s] [1875 results]
2018-05-31 00:07:55,008 -> J.Finding maximal disks... [0.163s] [230 results]
2018-05-31 00:07:57,328 -> K.Prunning duplicates and subsets... [2.320s] [225 results]
2018-05-31 00:07:57,328 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:07:57,328 ->   berlin0-10,   18548,  30.0,    28,  4,  30.48,    5768,     11536,          675,        225,  3
2018-05-31 00:07:57,542 -> Dropping indices...[0.214s]
2018-05-31 00:07:57,916 -> 1.Set of disks for t_i...                          |  31.08s |    225 disks
2018-05-31 00:08:04,631 -> 2.Distance Join phase...                           |   6.71s |   1012 combinations
2018-05-31 00:08:09,020 -> 3.Getting candidates...                            |   4.39s |    242 candidates
2018-05-31 00:08:09,938 -> 4.Found flocks...                                  |   0.92s |    210 flocks
2018-05-31 00:08:13,353 -> 5.Updating times...                                |   1.34s |    242 flocks
2018-05-31 00:08:15,654 -> 6.Filter phase...                                  |   2.30s |    269 flocks
2018-05-31 00:08:20,128 -> Reporting locations...                             |   4.47s |  18548 points
2018-05-31 00:08:20,128 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=4,dataset=berlin0-10
2018-05-31 00:08:27,082 -> A.Indexing points... [6.936s] [18548 results]
2018-05-31 00:08:36,646 -> B.Getting pairs... [9.563s] [5775 results]
2018-05-31 00:08:38,013 -> C.Computing centers... [1.367s] [11550 results]
2018-05-31 00:08:38,965 -> D.Indexing centers... [0.952s] [11550 results]
2018-05-31 00:08:45,537 -> E.Getting disks... [6.572s] [11550 results]
2018-05-31 00:08:45,765 -> F.Filtering less-than-mu disks... [0.228s] [1369 results]
2018-05-31 00:08:47,705 -> G.Prunning duplicate candidates... [1.940s] [694 results]
2018-05-31 00:08:48,038 -> H.Indexing candidates... [2.273s] [694 results]
2018-05-31 00:08:48,189 -> I.Getting expansions... [0.151s] [1914 results]
2018-05-31 00:08:48,339 -> J.Finding maximal disks... [0.150s] [245 results]
2018-05-31 00:08:50,071 -> K.Prunning duplicates and subsets... [1.732s] [238 results]
2018-05-31 00:08:50,071 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:08:50,071 ->   berlin0-10,   18548,  30.0,    28,  4,  29.93,    5775,     11550,          694,        238,  4
2018-05-31 00:08:50,348 -> Dropping indices...[0.277s]
2018-05-31 00:08:50,581 -> 1.Set of disks for t_i...                          |  30.45s |    238 disks
2018-05-31 00:08:58,358 -> 2.Distance Join phase...                           |   7.78s |   1066 combinations
2018-05-31 00:09:03,217 -> 3.Getting candidates...                            |   4.86s |    250 candidates
2018-05-31 00:09:04,235 -> 4.Found flocks...                                  |   1.02s |    220 flocks
2018-05-31 00:09:08,479 -> 5.Updating times...                                |   1.51s |    250 flocks
2018-05-31 00:09:10,964 -> 6.Filter phase...                                  |   2.49s |    274 flocks
2018-05-31 00:09:15,406 -> Reporting locations...                             |   4.44s |  18548 points
2018-05-31 00:09:15,406 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=5,dataset=berlin0-10
2018-05-31 00:09:22,234 -> A.Indexing points... [6.810s] [18548 results]
2018-05-31 00:09:31,779 -> B.Getting pairs... [9.545s] [5765 results]
2018-05-31 00:09:33,076 -> C.Computing centers... [1.297s] [11530 results]
2018-05-31 00:09:34,073 -> D.Indexing centers... [0.997s] [11530 results]
2018-05-31 00:09:40,504 -> E.Getting disks... [6.431s] [11530 results]
2018-05-31 00:09:40,717 -> F.Filtering less-than-mu disks... [0.213s] [1362 results]
2018-05-31 00:09:42,835 -> G.Prunning duplicate candidates... [2.118s] [686 results]
2018-05-31 00:09:43,144 -> H.Indexing candidates... [2.427s] [686 results]
2018-05-31 00:09:43,297 -> I.Getting expansions... [0.153s] [1917 results]
2018-05-31 00:09:43,436 -> J.Finding maximal disks... [0.139s] [237 results]
2018-05-31 00:09:45,252 -> K.Prunning duplicates and subsets... [1.816s] [234 results]
2018-05-31 00:09:45,252 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:09:45,252 ->   berlin0-10,   18548,  30.0,    28,  4,  29.83,    5765,     11530,          686,        234,  5
2018-05-31 00:09:45,590 -> Dropping indices...[0.337s]
2018-05-31 00:09:45,821 -> 1.Set of disks for t_i...                          |  30.42s |    234 disks
2018-05-31 00:09:53,811 -> 2.Distance Join phase...                           |   7.99s |   1035 combinations
2018-05-31 00:09:58,785 -> 3.Getting candidates...                            |   4.97s |    240 candidates
2018-05-31 00:10:00,029 -> 4.Found flocks...                                  |   1.24s |    213 flocks
2018-05-31 00:10:04,949 -> 5.Updating times...                                |   1.58s |    240 flocks
2018-05-31 00:10:07,581 -> 6.Filter phase...                                  |   2.63s |    267 flocks
2018-05-31 00:10:12,067 -> Reporting locations...                             |   4.49s |  18546 points
2018-05-31 00:10:12,068 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=6,dataset=berlin0-10
2018-05-31 00:10:18,986 -> A.Indexing points... [6.900s] [18546 results]
2018-05-31 00:10:28,440 -> B.Getting pairs... [9.454s] [5758 results]
2018-05-31 00:10:30,880 -> C.Computing centers... [2.439s] [11516 results]
2018-05-31 00:10:31,780 -> D.Indexing centers... [0.900s] [11516 results]
2018-05-31 00:10:38,452 -> E.Getting disks... [6.671s] [11516 results]
2018-05-31 00:10:38,700 -> F.Filtering less-than-mu disks... [0.248s] [1346 results]
2018-05-31 00:10:40,621 -> G.Prunning duplicate candidates... [1.921s] [681 results]
2018-05-31 00:10:40,968 -> H.Indexing candidates... [2.268s] [681 results]
2018-05-31 00:10:41,156 -> I.Getting expansions... [0.188s] [1951 results]
2018-05-31 00:10:41,290 -> J.Finding maximal disks... [0.134s] [225 results]
2018-05-31 00:10:43,142 -> K.Prunning duplicates and subsets... [1.851s] [222 results]
2018-05-31 00:10:43,142 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:10:43,142 ->   berlin0-10,   18546,  30.0,    28,  4,  31.06,    5758,     11516,          681,        222,  6
2018-05-31 00:10:43,589 -> Dropping indices...[0.447s]
2018-05-31 00:10:43,848 -> 1.Set of disks for t_i...                          |  31.78s |    222 disks
2018-05-31 00:10:52,754 -> 2.Distance Join phase...                           |   8.91s |    894 combinations
2018-05-31 00:10:57,867 -> 3.Getting candidates...                            |   5.11s |    252 candidates
2018-05-31 00:10:59,093 -> 4.Found flocks...                                  |   1.23s |    218 flocks
2018-05-31 00:11:05,080 -> 5.Updating times...                                |   1.60s |    252 flocks
2018-05-31 00:11:07,673 -> 6.Filter phase...                                  |   2.59s |    272 flocks
2018-05-31 00:11:12,135 -> Reporting locations...                             |   4.46s |  18546 points
2018-05-31 00:11:12,135 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=7,dataset=berlin0-10
2018-05-31 00:11:19,391 -> A.Indexing points... [7.236s] [18546 results]
2018-05-31 00:11:29,008 -> B.Getting pairs... [9.617s] [5788 results]
2018-05-31 00:11:30,333 -> C.Computing centers... [1.325s] [11576 results]
2018-05-31 00:11:31,221 -> D.Indexing centers... [0.888s] [11576 results]
2018-05-31 00:11:37,700 -> E.Getting disks... [6.479s] [11576 results]
2018-05-31 00:11:37,931 -> F.Filtering less-than-mu disks... [0.230s] [1361 results]
2018-05-31 00:11:39,718 -> G.Prunning duplicate candidates... [1.787s] [688 results]
2018-05-31 00:11:40,033 -> H.Indexing candidates... [2.102s] [688 results]
2018-05-31 00:11:40,180 -> I.Getting expansions... [0.147s] [1882 results]
2018-05-31 00:11:40,319 -> J.Finding maximal disks... [0.139s] [233 results]
2018-05-31 00:11:41,979 -> K.Prunning duplicates and subsets... [1.660s] [231 results]
2018-05-31 00:11:41,979 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:11:41,979 ->   berlin0-10,   18546,  30.0,    28,  4,  29.82,    5788,     11576,          688,        231,  7
2018-05-31 00:11:42,457 -> Dropping indices...[0.478s]
2018-05-31 00:11:42,836 -> 1.Set of disks for t_i...                          |  30.70s |    231 disks
2018-05-31 00:11:51,283 -> 2.Distance Join phase...                           |   8.45s |    934 combinations
2018-05-31 00:11:56,469 -> 3.Getting candidates...                            |   5.19s |    239 candidates
2018-05-31 00:11:57,813 -> 4.Found flocks...                                  |   1.34s |    216 flocks
2018-05-31 00:12:04,427 -> 5.Updating times...                                |   1.73s |    239 flocks
2018-05-31 00:12:07,272 -> 6.Filter phase...                                  |   2.85s |    270 flocks
2018-05-31 00:12:11,595 -> Reporting locations...                             |   4.32s |  18546 points
2018-05-31 00:12:11,596 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=8,dataset=berlin0-10
2018-05-31 00:12:16,325 -> A.Indexing points... [4.711s] [18546 results]
2018-05-31 00:12:22,784 -> B.Getting pairs... [6.459s] [5791 results]
2018-05-31 00:12:24,042 -> C.Computing centers... [1.258s] [11582 results]
2018-05-31 00:12:25,111 -> D.Indexing centers... [1.068s] [11582 results]
2018-05-31 00:12:30,117 -> E.Getting disks... [5.006s] [11582 results]
2018-05-31 00:12:30,326 -> F.Filtering less-than-mu disks... [0.209s] [1316 results]
2018-05-31 00:12:31,893 -> G.Prunning duplicate candidates... [1.567s] [670 results]
2018-05-31 00:12:32,195 -> H.Indexing candidates... [1.869s] [670 results]
2018-05-31 00:12:32,340 -> I.Getting expansions... [0.145s] [1792 results]
2018-05-31 00:12:32,467 -> J.Finding maximal disks... [0.127s] [220 results]
2018-05-31 00:12:33,811 -> K.Prunning duplicates and subsets... [1.344s] [219 results]
2018-05-31 00:12:33,811 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:12:33,811 ->   berlin0-10,   18546,  30.0,    28,  4,  22.20,    5791,     11582,          670,        219,  8
2018-05-31 00:12:34,424 -> Dropping indices...[0.613s]
2018-05-31 00:12:34,712 -> 1.Set of disks for t_i...                          |  23.12s |    219 disks
2018-05-31 00:12:44,302 -> 2.Distance Join phase...                           |   9.59s |    811 combinations
2018-05-31 00:12:49,567 -> 3.Getting candidates...                            |   5.27s |    226 candidates
2018-05-31 00:12:50,933 -> 4.Found flocks...                                  |   1.37s |    197 flocks
2018-05-31 00:13:00,215 -> 5.Updating times...                                |   1.83s |    226 flocks
2018-05-31 00:13:03,021 -> 6.Filter phase...                                  |   2.81s |    247 flocks
2018-05-31 00:13:07,335 -> Reporting locations...                             |   4.31s |  18546 points
2018-05-31 00:13:07,336 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=9,dataset=berlin0-10
2018-05-31 00:13:15,027 -> A.Indexing points... [7.657s] [18546 results]
2018-05-31 00:13:25,792 -> B.Getting pairs... [10.765s] [5802 results]
2018-05-31 00:13:27,066 -> C.Computing centers... [1.274s] [11604 results]
2018-05-31 00:13:28,096 -> D.Indexing centers... [1.030s] [11604 results]
2018-05-31 00:13:34,992 -> E.Getting disks... [6.896s] [11604 results]
2018-05-31 00:13:35,240 -> F.Filtering less-than-mu disks... [0.247s] [1306 results]
2018-05-31 00:13:37,419 -> G.Prunning duplicate candidates... [2.179s] [675 results]
2018-05-31 00:13:37,715 -> H.Indexing candidates... [2.475s] [675 results]
2018-05-31 00:13:37,870 -> I.Getting expansions... [0.155s] [1813 results]
2018-05-31 00:13:38,008 -> J.Finding maximal disks... [0.137s] [212 results]
2018-05-31 00:13:39,895 -> K.Prunning duplicates and subsets... [1.887s] [210 results]
2018-05-31 00:13:39,895 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:13:39,896 ->   berlin0-10,   18546,  30.0,    28,  4,  32.53,    5802,     11604,          675,        210,  9
2018-05-31 00:13:40,568 -> Dropping indices...[0.672s]
2018-05-31 00:13:40,855 -> 1.Set of disks for t_i...                          |  33.52s |    210 disks
2018-05-31 00:13:50,604 -> 2.Distance Join phase...                           |   9.75s |    637 combinations
2018-05-31 00:13:56,400 -> 3.Getting candidates...                            |   5.80s |    219 candidates
2018-05-31 00:13:58,164 -> 4.Found flocks...                                  |   1.76s |    199 flocks
2018-05-31 00:14:07,801 -> 5.Updating times...                                |   2.60s |    219 flocks
2018-05-31 00:14:11,368 -> 6.Filter phase...                                  |   3.57s |    239 flocks
2018-05-31 00:14:15,645 -> Reporting locations...                             |   4.28s |  18546 points
2018-05-31 00:14:15,646 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=10,dataset=berlin0-10
2018-05-31 00:14:23,429 -> A.Indexing points... [7.749s] [18546 results]
2018-05-31 00:14:34,124 -> B.Getting pairs... [10.695s] [5797 results]
2018-05-31 00:14:35,392 -> C.Computing centers... [1.267s] [11594 results]
2018-05-31 00:14:36,368 -> D.Indexing centers... [0.976s] [11594 results]
2018-05-31 00:14:43,640 -> E.Getting disks... [7.272s] [11594 results]
2018-05-31 00:14:43,863 -> F.Filtering less-than-mu disks... [0.223s] [1312 results]
2018-05-31 00:14:45,828 -> G.Prunning duplicate candidates... [1.965s] [675 results]
2018-05-31 00:14:46,155 -> H.Indexing candidates... [2.292s] [675 results]
2018-05-31 00:14:46,305 -> I.Getting expansions... [0.150s] [1804 results]
2018-05-31 00:14:46,438 -> J.Finding maximal disks... [0.133s] [212 results]
2018-05-31 00:14:48,395 -> K.Prunning duplicates and subsets... [1.957s] [211 results]
2018-05-31 00:14:48,395 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:14:48,395 ->   berlin0-10,   18546,  30.0,    28,  4,  32.72,    5797,     11594,          675,        211, 10
2018-05-31 00:14:49,181 -> Dropping indices...[0.786s]
2018-05-31 00:14:49,453 -> 1.Set of disks for t_i...                          |  33.81s |    211 disks
2018-05-31 00:15:01,343 -> 2.Distance Join phase...                           |  11.89s |    600 combinations
2018-05-31 00:15:07,635 -> 3.Getting candidates...                            |   6.29s |    213 candidates
2018-05-31 00:15:09,241 -> 4.Found flocks...                                  |   1.61s |    196 flocks
2018-05-31 00:15:21,118 -> 5.Updating times...                                |   1.99s |    213 flocks
2018-05-31 00:15:23,752 -> 6.Filter phase...                                  |   2.63s |    237 flocks
2018-05-31 00:15:23,752 -> 

PFLOCK_SJ	30.0	4	3	1868

2018-05-31 00:15:30,228 -> Running SpatialJoin...                             | 612.99s |   1868 flocks
2018-05-31 00:15:30,229 -> method=SpatialJoin,cores=28,epsilon=30.0,mu=4,delta=3,time=612.987,master=spark://169.235.27.134:7077
2018-05-31 00:15:30,229 -> Closing app...
java.util.concurrent.RejectedExecutionException: Task scala.concurrent.impl.CallbackRunnable@202a3fb5 rejected from java.util.concurrent.ThreadPoolExecutor@4c81b33e[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 14791]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$1.execute(ExecutionContextImpl.scala:136)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248)
	at scala.concurrent.Promise$class.complete(Promise.scala:55)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:153)
	at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:326)
	at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:326)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at org.spark_project.guava.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$1.execute(ExecutionContextImpl.scala:136)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248)
	at scala.concurrent.Promise$class.complete(Promise.scala:55)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:153)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.processBatch$1(BatchingExecutor.scala:63)
	at scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:78)
	at scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.apply(BatchingExecutor.scala:55)
	at scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.apply(BatchingExecutor.scala:55)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:54)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:601)
	at scala.concurrent.BatchingExecutor$class.execute(BatchingExecutor.scala:106)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:599)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248)
	at scala.concurrent.Promise$class.tryFailure(Promise.scala:112)
	at scala.concurrent.impl.Promise$DefaultPromise.tryFailure(Promise.scala:153)
	at org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$onFailure$1(NettyRpcEnv.scala:205)
	at org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$2.apply(NettyRpcEnv.scala:228)
	at org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$2.apply(NettyRpcEnv.scala:228)
	at org.apache.spark.rpc.netty.RpcOutboxMessage.onFailure(Outbox.scala:75)
	at org.apache.spark.network.client.TransportResponseHandler.failOutstandingRequests(TransportResponseHandler.java:110)
	at org.apache.spark.network.client.TransportResponseHandler.channelInactive(TransportResponseHandler.java:128)
	at org.apache.spark.network.server.TransportChannelHandler.channelInactive(TransportChannelHandler.java:109)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:251)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:237)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:230)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:75)
	at io.netty.handler.timeout.IdleStateHandler.channelInactive(IdleStateHandler.java:257)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:251)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:237)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:230)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:75)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:251)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:237)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:230)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:75)
	at org.apache.spark.network.util.TransportFrameDecoder.channelInactive(TransportFrameDecoder.java:182)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:251)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:237)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:230)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelInactive(DefaultChannelPipeline.java:1289)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:251)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:237)
	at io.netty.channel.DefaultChannelPipeline.fireChannelInactive(DefaultChannelPipeline.java:893)
	at io.netty.channel.AbstractChannel$AbstractUnsafe$7.run(AbstractChannel.java:691)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:376)
	at io.netty.util.concurrent.SingleThreadEventExecutor.confirmShutdown(SingleThreadEventExecutor.java:680)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:465)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:140)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack15: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
FLOCKFINDER=SpatialJoin;TIME=Thu May 31 00:15:31 PDT 2018;RUN=1527750300;NODES=4;ESTART=;EEND=;ESTEP=;MU=4;DELTA=;SCRIPT=DeltaBenchmarker;EVENT=End
FLOCKFINDER=MergeLast;TIME=Thu May 31 00:15:31 PDT 2018;RUN=1527750931;NODES=4;ESTART=;EEND=;ESTEP=;MU=4;DELTA=;SCRIPT=DeltaBenchmarker;EVENT=Start
WARNING:root:Setting 4 nodes...
acald013@dblab-rack12: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack11: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack14: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack15: no org.apache.spark.deploy.worker.Worker to stop
no org.apache.spark.deploy.master.Master to stop
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack15: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack15.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
WARNING:root:4 nodes has been set...
2018-05-31 00:15:38,545 -> Starting app...
2018-05-31 00:15:41,467 -> Starting session                                   |   2.92s |      0 
2018-05-31 00:15:41,481 -> Setting paramaters                                 |   0.01s |      0 
2018-05-31 00:15:44,661 -> Reading data                                       |   3.18s | 203106 points
2018-05-31 00:15:47,940 -> Extracting timestamps                              |   3.28s |     11 timestamps
2018-05-31 00:15:47,949 -> === MergeLast Start ===
2018-05-31 00:15:53,577 -> Reporting locations at t=0...                      |   5.44s |  18093 points
2018-05-31 00:15:53,586 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=0,dataset=berlin0-10
2018-05-31 00:16:01,564 -> A.Indexing points... [7.914s] [18093 results]
2018-05-31 00:16:08,556 -> B.Getting pairs... [6.992s] [5511 results]
2018-05-31 00:16:10,471 -> C.Computing centers... [1.915s] [11022 results]
2018-05-31 00:16:11,877 -> D.Indexing centers... [1.406s] [11022 results]
2018-05-31 00:16:17,610 -> E.Getting disks... [5.733s] [11022 results]
2018-05-31 00:16:17,999 -> F.Filtering less-than-mu disks... [0.389s] [1210 results]
2018-05-31 00:16:20,807 -> G.Prunning duplicate candidates... [2.808s] [599 results]
2018-05-31 00:16:21,270 -> H.Indexing candidates... [3.271s] [599 results]
2018-05-31 00:16:21,465 -> I.Getting expansions... [0.195s] [1657 results]
2018-05-31 00:16:22,094 -> J.Finding maximal disks... [0.629s] [206 results]
2018-05-31 00:16:24,047 -> K.Prunning duplicates and subsets... [1.953s] [205 results]
2018-05-31 00:16:24,047 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:16:24,048 ->   berlin0-10,   18093,  30.0,    28,  4,  30.40,    5511,     11022,          599,        205,  0
2018-05-31 00:16:24,139 -> Dropping indices...[0.091s]
2018-05-31 00:16:24,485 -> 1.Set of disks for t_i...                          |  30.91s |    205 disks
2018-05-31 00:16:29,406 -> Reporting locations at t=2...                      |   4.92s |  18394 points
2018-05-31 00:16:29,406 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=2,dataset=berlin0-10
2018-05-31 00:16:33,840 -> A.Indexing points... [4.415s] [18394 results]
2018-05-31 00:16:39,078 -> B.Getting pairs... [5.238s] [5701 results]
2018-05-31 00:16:40,467 -> C.Computing centers... [1.389s] [11402 results]
2018-05-31 00:16:41,616 -> D.Indexing centers... [1.149s] [11402 results]
2018-05-31 00:16:47,208 -> E.Getting disks... [5.592s] [11402 results]
2018-05-31 00:16:47,522 -> F.Filtering less-than-mu disks... [0.314s] [1336 results]
2018-05-31 00:16:49,188 -> G.Prunning duplicate candidates... [1.666s] [658 results]
2018-05-31 00:16:49,535 -> H.Indexing candidates... [2.013s] [658 results]
2018-05-31 00:16:49,712 -> I.Getting expansions... [0.177s] [1757 results]
2018-05-31 00:16:49,884 -> J.Finding maximal disks... [0.172s] [232 results]
2018-05-31 00:16:51,537 -> K.Prunning duplicates and subsets... [1.653s] [227 results]
2018-05-31 00:16:51,537 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:16:51,537 ->   berlin0-10,   18394,  30.0,    28,  4,  22.11,    5701,     11402,          658,        227,  2
2018-05-31 00:16:51,602 -> Dropping indices...[0.065s]
2018-05-31 00:16:51,855 -> 2.Set of disks for t_i+delta...                    |  22.45s |    205 disks
2018-05-31 00:17:00,042 -> 3.Joining timestams                                |   8.19s |    332 candidates
2018-05-31 00:17:11,850 -> Checking internal timestamps                       |  11.81s |    199 flocks
2018-05-31 00:17:16,948 -> Reporting locations at t=1...                      |   4.74s |  18245 points
2018-05-31 00:17:16,948 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=1,dataset=berlin0-10
2018-05-31 00:17:20,948 -> A.Indexing points... [3.984s] [18245 results]
2018-05-31 00:17:25,461 -> B.Getting pairs... [4.513s] [5629 results]
2018-05-31 00:17:26,775 -> C.Computing centers... [1.314s] [11258 results]
2018-05-31 00:17:27,747 -> D.Indexing centers... [0.972s] [11258 results]
2018-05-31 00:17:32,121 -> E.Getting disks... [4.374s] [11258 results]
2018-05-31 00:17:32,349 -> F.Filtering less-than-mu disks... [0.228s] [1299 results]
2018-05-31 00:17:33,918 -> G.Prunning duplicate candidates... [1.568s] [640 results]
2018-05-31 00:17:34,276 -> H.Indexing candidates... [1.926s] [640 results]
2018-05-31 00:17:34,445 -> I.Getting expansions... [0.169s] [1703 results]
2018-05-31 00:17:34,608 -> J.Finding maximal disks... [0.163s] [220 results]
2018-05-31 00:17:35,743 -> K.Prunning duplicates and subsets... [1.135s] [216 results]
2018-05-31 00:17:35,743 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:17:35,743 ->   berlin0-10,   18245,  30.0,    28,  4,  18.78,    5629,     11258,          640,        216,  1
2018-05-31 00:17:35,834 -> Dropping indices...[0.090s]
2018-05-31 00:17:36,067 -> 1.Set of disks for t_i...                          |  19.12s |    216 disks
2018-05-31 00:17:40,764 -> Reporting locations at t=3...                      |   4.70s |  18548 points
2018-05-31 00:17:40,764 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=3,dataset=berlin0-10
2018-05-31 00:17:48,477 -> A.Indexing points... [7.693s] [18548 results]
2018-05-31 00:17:59,561 -> B.Getting pairs... [11.083s] [5768 results]
2018-05-31 00:18:00,909 -> C.Computing centers... [1.348s] [11536 results]
2018-05-31 00:18:01,840 -> D.Indexing centers... [0.931s] [11536 results]
2018-05-31 00:18:09,054 -> E.Getting disks... [7.213s] [11536 results]
2018-05-31 00:18:09,273 -> F.Filtering less-than-mu disks... [0.219s] [1349 results]
2018-05-31 00:18:11,378 -> G.Prunning duplicate candidates... [2.105s] [675 results]
2018-05-31 00:18:11,734 -> H.Indexing candidates... [2.461s] [675 results]
2018-05-31 00:18:11,889 -> I.Getting expansions... [0.155s] [1875 results]
2018-05-31 00:18:12,036 -> J.Finding maximal disks... [0.147s] [230 results]
2018-05-31 00:18:14,134 -> K.Prunning duplicates and subsets... [2.098s] [225 results]
2018-05-31 00:18:14,134 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:18:14,134 ->   berlin0-10,   18548,  30.0,    28,  4,  33.35,    5768,     11536,          675,        225,  3
2018-05-31 00:18:14,264 -> Dropping indices...[0.130s]
2018-05-31 00:18:14,530 -> 2.Set of disks for t_i+delta...                    |  33.77s |    216 disks
2018-05-31 00:18:21,594 -> 3.Joining timestams                                |   7.06s |    333 candidates
2018-05-31 00:18:31,039 -> Checking internal timestamps                       |   9.45s |    210 flocks
2018-05-31 00:18:36,366 -> Reporting locations at t=2...                      |   4.73s |  18394 points
2018-05-31 00:18:36,607 -> 1.Set of disks for t_i...                          |   0.24s |    227 disks
2018-05-31 00:18:41,293 -> Reporting locations at t=4...                      |   4.69s |  18548 points
2018-05-31 00:18:41,293 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=4,dataset=berlin0-10
2018-05-31 00:18:49,356 -> A.Indexing points... [8.045s] [18548 results]
2018-05-31 00:19:00,382 -> B.Getting pairs... [11.026s] [5775 results]
2018-05-31 00:19:01,649 -> C.Computing centers... [1.267s] [11550 results]
2018-05-31 00:19:02,548 -> D.Indexing centers... [0.899s] [11550 results]
2018-05-31 00:19:09,825 -> E.Getting disks... [7.277s] [11550 results]
2018-05-31 00:19:10,078 -> F.Filtering less-than-mu disks... [0.253s] [1369 results]
2018-05-31 00:19:12,223 -> G.Prunning duplicate candidates... [2.145s] [694 results]
2018-05-31 00:19:12,505 -> H.Indexing candidates... [2.427s] [694 results]
2018-05-31 00:19:12,659 -> I.Getting expansions... [0.154s] [1914 results]
2018-05-31 00:19:12,804 -> J.Finding maximal disks... [0.145s] [245 results]
2018-05-31 00:19:14,827 -> K.Prunning duplicates and subsets... [2.023s] [238 results]
2018-05-31 00:19:14,827 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:19:14,828 ->   berlin0-10,   18548,  30.0,    28,  4,  33.52,    5775,     11550,          694,        238,  4
2018-05-31 00:19:14,967 -> Dropping indices...[0.139s]
2018-05-31 00:19:15,188 -> 2.Set of disks for t_i+delta...                    |  33.90s |    227 disks
2018-05-31 00:19:23,041 -> 3.Joining timestams                                |   7.85s |    360 candidates
2018-05-31 00:19:32,432 -> Checking internal timestamps                       |   9.39s |    220 flocks
2018-05-31 00:19:38,133 -> Reporting locations at t=3...                      |   4.76s |  18548 points
2018-05-31 00:19:38,380 -> 1.Set of disks for t_i...                          |   0.25s |    225 disks
2018-05-31 00:19:43,181 -> Reporting locations at t=5...                      |   4.80s |  18548 points
2018-05-31 00:19:43,182 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=5,dataset=berlin0-10
2018-05-31 00:19:50,769 -> A.Indexing points... [7.566s] [18548 results]
2018-05-31 00:20:01,808 -> B.Getting pairs... [11.039s] [5765 results]
2018-05-31 00:20:03,100 -> C.Computing centers... [1.292s] [11530 results]
2018-05-31 00:20:04,020 -> D.Indexing centers... [0.920s] [11530 results]
2018-05-31 00:20:11,304 -> E.Getting disks... [7.284s] [11530 results]
2018-05-31 00:20:11,527 -> F.Filtering less-than-mu disks... [0.223s] [1362 results]
2018-05-31 00:20:13,540 -> G.Prunning duplicate candidates... [2.013s] [686 results]
2018-05-31 00:20:13,873 -> H.Indexing candidates... [2.346s] [686 results]
2018-05-31 00:20:14,021 -> I.Getting expansions... [0.147s] [1917 results]
2018-05-31 00:20:14,173 -> J.Finding maximal disks... [0.152s] [237 results]
2018-05-31 00:20:16,188 -> K.Prunning duplicates and subsets... [2.015s] [234 results]
2018-05-31 00:20:16,189 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:20:16,189 ->   berlin0-10,   18548,  30.0,    28,  4,  32.99,    5765,     11530,          686,        234,  5
2018-05-31 00:20:16,375 -> Dropping indices...[0.186s]
2018-05-31 00:20:16,630 -> 2.Set of disks for t_i+delta...                    |  33.45s |    225 disks
2018-05-31 00:20:24,288 -> 3.Joining timestams                                |   7.66s |    327 candidates
2018-05-31 00:20:33,612 -> Checking internal timestamps                       |   9.32s |    213 flocks
2018-05-31 00:20:39,468 -> Reporting locations at t=4...                      |   4.79s |  18548 points
2018-05-31 00:20:39,707 -> 1.Set of disks for t_i...                          |   0.24s |    238 disks
2018-05-31 00:20:44,440 -> Reporting locations at t=6...                      |   4.73s |  18546 points
2018-05-31 00:20:44,440 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=6,dataset=berlin0-10
2018-05-31 00:20:51,857 -> A.Indexing points... [7.398s] [18546 results]
2018-05-31 00:21:03,099 -> B.Getting pairs... [11.242s] [5758 results]
2018-05-31 00:21:04,401 -> C.Computing centers... [1.302s] [11516 results]
2018-05-31 00:21:05,313 -> D.Indexing centers... [0.911s] [11516 results]
2018-05-31 00:21:12,463 -> E.Getting disks... [7.150s] [11516 results]
2018-05-31 00:21:12,753 -> F.Filtering less-than-mu disks... [0.290s] [1346 results]
2018-05-31 00:21:15,017 -> G.Prunning duplicate candidates... [2.264s] [681 results]
2018-05-31 00:21:15,325 -> H.Indexing candidates... [2.572s] [681 results]
2018-05-31 00:21:15,531 -> I.Getting expansions... [0.206s] [1951 results]
2018-05-31 00:21:15,676 -> J.Finding maximal disks... [0.145s] [225 results]
2018-05-31 00:21:17,658 -> K.Prunning duplicates and subsets... [1.982s] [222 results]
2018-05-31 00:21:17,659 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:21:17,659 ->   berlin0-10,   18546,  30.0,    28,  4,  33.20,    5758,     11516,          681,        222,  6
2018-05-31 00:21:17,872 -> Dropping indices...[0.213s]
2018-05-31 00:21:18,121 -> 2.Set of disks for t_i+delta...                    |  33.68s |    238 disks
2018-05-31 00:21:25,398 -> 3.Joining timestams                                |   7.28s |    324 candidates
2018-05-31 00:21:34,697 -> Checking internal timestamps                       |   9.30s |    218 flocks
2018-05-31 00:21:40,686 -> Reporting locations at t=5...                      |   4.74s |  18548 points
2018-05-31 00:21:40,928 -> 1.Set of disks for t_i...                          |   0.24s |    234 disks
2018-05-31 00:21:45,659 -> Reporting locations at t=7...                      |   4.73s |  18546 points
2018-05-31 00:21:45,660 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=7,dataset=berlin0-10
2018-05-31 00:21:53,221 -> A.Indexing points... [7.543s] [18546 results]
2018-05-31 00:22:04,626 -> B.Getting pairs... [11.405s] [5788 results]
2018-05-31 00:22:05,934 -> C.Computing centers... [1.308s] [11576 results]
2018-05-31 00:22:06,798 -> D.Indexing centers... [0.864s] [11576 results]
2018-05-31 00:22:14,128 -> E.Getting disks... [7.329s] [11576 results]
2018-05-31 00:22:14,347 -> F.Filtering less-than-mu disks... [0.219s] [1361 results]
2018-05-31 00:22:16,473 -> G.Prunning duplicate candidates... [2.126s] [688 results]
2018-05-31 00:22:16,776 -> H.Indexing candidates... [2.429s] [688 results]
2018-05-31 00:22:16,928 -> I.Getting expansions... [0.152s] [1882 results]
2018-05-31 00:22:17,076 -> J.Finding maximal disks... [0.148s] [233 results]
2018-05-31 00:22:19,489 -> K.Prunning duplicates and subsets... [2.413s] [231 results]
2018-05-31 00:22:19,489 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:22:19,489 ->   berlin0-10,   18546,  30.0,    28,  4,  33.81,    5788,     11576,          688,        231,  7
2018-05-31 00:22:19,730 -> Dropping indices...[0.241s]
2018-05-31 00:22:20,022 -> 2.Set of disks for t_i+delta...                    |  34.36s |    234 disks
2018-05-31 00:22:26,912 -> 3.Joining timestams                                |   6.89s |    320 candidates
2018-05-31 00:22:35,987 -> Checking internal timestamps                       |   9.08s |    216 flocks
2018-05-31 00:22:42,104 -> Reporting locations at t=6...                      |   4.78s |  18546 points
2018-05-31 00:22:42,327 -> 1.Set of disks for t_i...                          |   0.22s |    222 disks
2018-05-31 00:22:46,925 -> Reporting locations at t=8...                      |   4.60s |  18546 points
2018-05-31 00:22:46,925 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=8,dataset=berlin0-10
2018-05-31 00:22:52,047 -> A.Indexing points... [5.105s] [18546 results]
2018-05-31 00:22:58,783 -> B.Getting pairs... [6.736s] [5791 results]
2018-05-31 00:23:00,084 -> C.Computing centers... [1.300s] [11582 results]
2018-05-31 00:23:00,974 -> D.Indexing centers... [0.889s] [11582 results]
2018-05-31 00:23:06,580 -> E.Getting disks... [5.606s] [11582 results]
2018-05-31 00:23:06,844 -> F.Filtering less-than-mu disks... [0.263s] [1316 results]
2018-05-31 00:23:08,684 -> G.Prunning duplicate candidates... [1.840s] [670 results]
2018-05-31 00:23:09,038 -> H.Indexing candidates... [2.194s] [670 results]
2018-05-31 00:23:09,243 -> I.Getting expansions... [0.205s] [1792 results]
2018-05-31 00:23:09,393 -> J.Finding maximal disks... [0.150s] [220 results]
2018-05-31 00:23:11,017 -> K.Prunning duplicates and subsets... [1.624s] [219 results]
2018-05-31 00:23:11,017 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:23:11,017 ->   berlin0-10,   18546,  30.0,    28,  4,  24.08,    5791,     11582,          670,        219,  8
2018-05-31 00:23:11,282 -> Dropping indices...[0.265s]
2018-05-31 00:23:11,502 -> 2.Set of disks for t_i+delta...                    |  24.58s |    222 disks
2018-05-31 00:23:18,881 -> 3.Joining timestams                                |   7.38s |    283 candidates
2018-05-31 00:23:27,874 -> Checking internal timestamps                       |   8.99s |    197 flocks
2018-05-31 00:23:34,178 -> Reporting locations at t=7...                      |   4.78s |  18546 points
2018-05-31 00:23:34,426 -> 1.Set of disks for t_i...                          |   0.25s |    231 disks
2018-05-31 00:23:38,984 -> Reporting locations at t=9...                      |   4.56s |  18546 points
2018-05-31 00:23:38,985 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=9,dataset=berlin0-10
2018-05-31 00:23:46,151 -> A.Indexing points... [7.125s] [18546 results]
2018-05-31 00:23:56,192 -> B.Getting pairs... [10.041s] [5802 results]
2018-05-31 00:23:57,461 -> C.Computing centers... [1.269s] [11604 results]
2018-05-31 00:23:58,408 -> D.Indexing centers... [0.947s] [11604 results]
2018-05-31 00:24:05,333 -> E.Getting disks... [6.925s] [11604 results]
2018-05-31 00:24:05,555 -> F.Filtering less-than-mu disks... [0.222s] [1306 results]
2018-05-31 00:24:07,842 -> G.Prunning duplicate candidates... [2.287s] [675 results]
2018-05-31 00:24:08,178 -> H.Indexing candidates... [2.623s] [675 results]
2018-05-31 00:24:08,446 -> I.Getting expansions... [0.268s] [1813 results]
2018-05-31 00:24:08,589 -> J.Finding maximal disks... [0.143s] [212 results]
2018-05-31 00:24:10,506 -> K.Prunning duplicates and subsets... [1.917s] [210 results]
2018-05-31 00:24:10,506 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:24:10,506 ->   berlin0-10,   18546,  30.0,    28,  4,  31.48,    5802,     11604,          675,        210,  9
2018-05-31 00:24:10,804 -> Dropping indices...[0.298s]
2018-05-31 00:24:11,094 -> 2.Set of disks for t_i+delta...                    |  32.11s |    231 disks
2018-05-31 00:24:18,902 -> 3.Joining timestams                                |   7.81s |    277 candidates
2018-05-31 00:24:28,949 -> Checking internal timestamps                       |  10.05s |    199 flocks
2018-05-31 00:24:35,332 -> Reporting locations at t=8...                      |   4.64s |  18546 points
2018-05-31 00:24:35,565 -> 1.Set of disks for t_i...                          |   0.23s |    219 disks
2018-05-31 00:24:40,122 -> Reporting locations at t=10...                     |   4.56s |  18546 points
2018-05-31 00:24:40,122 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=10,dataset=berlin0-10
2018-05-31 00:24:47,113 -> A.Indexing points... [6.951s] [18546 results]
2018-05-31 00:24:57,199 -> B.Getting pairs... [10.086s] [5797 results]
2018-05-31 00:24:58,487 -> C.Computing centers... [1.288s] [11594 results]
2018-05-31 00:24:59,544 -> D.Indexing centers... [1.057s] [11594 results]
2018-05-31 00:25:06,374 -> E.Getting disks... [6.830s] [11594 results]
2018-05-31 00:25:06,606 -> F.Filtering less-than-mu disks... [0.231s] [1312 results]
2018-05-31 00:25:08,731 -> G.Prunning duplicate candidates... [2.125s] [675 results]
2018-05-31 00:25:09,125 -> H.Indexing candidates... [2.519s] [675 results]
2018-05-31 00:25:09,319 -> I.Getting expansions... [0.194s] [1804 results]
2018-05-31 00:25:09,453 -> J.Finding maximal disks... [0.133s] [212 results]
2018-05-31 00:25:11,349 -> K.Prunning duplicates and subsets... [1.896s] [211 results]
2018-05-31 00:25:11,349 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:25:11,349 ->   berlin0-10,   18546,  30.0,    28,  4,  31.19,    5797,     11594,          675,        211, 10
2018-05-31 00:25:11,775 -> Dropping indices...[0.426s]
2018-05-31 00:25:12,051 -> 2.Set of disks for t_i+delta...                    |  31.93s |    219 disks
2018-05-31 00:25:19,511 -> 3.Joining timestams                                |   7.46s |    277 candidates
2018-05-31 00:25:28,538 -> Checking internal timestamps                       |   9.03s |    196 flocks
2018-05-31 00:25:30,600 -> 

PFLOCK_ML	30.0	4	3	1868

2018-05-31 00:25:32,395 -> Running MergeLast...                               | 584.45s |   1868 flocks
2018-05-31 00:25:32,395 -> method=MergeLast,cores=28,epsilon=30.0,mu=4,delta=3,time=584.446,master=spark://169.235.27.134:7077
2018-05-31 00:25:32,396 -> Closing app...
acald013@dblab-rack15: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
FLOCKFINDER=MergeLast;TIME=Thu May 31 00:25:34 PDT 2018;RUN=1527750931;NODES=4;ESTART=;EEND=;ESTEP=;MU=4;DELTA=;SCRIPT=DeltaBenchmarker;EVENT=End
FLOCKFINDER=SpatialJoin;TIME=Thu May 31 00:25:34 PDT 2018;RUN=1527751534;NODES=4;ESTART=;EEND=;ESTEP=;MU=4;DELTA=;SCRIPT=DeltaBenchmarker;EVENT=Start
WARNING:root:Setting 4 nodes...
acald013@dblab-rack12: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack11: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack14: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack15: no org.apache.spark.deploy.worker.Worker to stop
no org.apache.spark.deploy.master.Master to stop
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack15: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack15.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
WARNING:root:4 nodes has been set...
2018-05-31 00:25:41,389 -> Starting app...
2018-05-31 00:25:44,181 -> Starting session                                   |   2.79s |      0 
2018-05-31 00:25:44,192 -> Setting paramaters                                 |   0.01s |      0 
2018-05-31 00:25:47,463 -> Reading data                                       |   3.27s | 203106 points
2018-05-31 00:25:50,867 -> Extracting timestamps                              |   3.40s |     11 timestamps
2018-05-31 00:25:50,872 -> === SpatialJoin Start ===
2018-05-31 00:25:56,339 -> Reporting locations...                             |   5.22s |  18093 points
2018-05-31 00:25:56,356 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=0,dataset=berlin0-10
2018-05-31 00:26:04,798 -> A.Indexing points... [8.387s] [18093 results]
2018-05-31 00:26:11,975 -> B.Getting pairs... [7.177s] [5511 results]
2018-05-31 00:26:14,133 -> C.Computing centers... [2.157s] [11022 results]
2018-05-31 00:26:15,508 -> D.Indexing centers... [1.375s] [11022 results]
2018-05-31 00:26:21,579 -> E.Getting disks... [6.071s] [11022 results]
2018-05-31 00:26:21,994 -> F.Filtering less-than-mu disks... [0.415s] [1210 results]
2018-05-31 00:26:24,366 -> G.Prunning duplicate candidates... [2.371s] [599 results]
2018-05-31 00:26:24,855 -> H.Indexing candidates... [2.859s] [599 results]
2018-05-31 00:26:25,107 -> I.Getting expansions... [0.252s] [1657 results]
2018-05-31 00:26:25,746 -> J.Finding maximal disks... [0.639s] [206 results]
2018-05-31 00:26:27,753 -> K.Prunning duplicates and subsets... [2.007s] [205 results]
2018-05-31 00:26:27,753 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:26:27,754 ->   berlin0-10,   18093,  30.0,    28,  4,  31.34,    5511,     11022,          599,        205,  0
2018-05-31 00:26:27,838 -> Dropping indices...[0.084s]
2018-05-31 00:26:28,173 -> 1.Set of disks for t_i...                          |  31.83s |    205 disks
2018-05-31 00:26:28,551 -> 4.Found flocks...                                  |   0.38s |      0 flocks
2018-05-31 00:26:29,387 -> 5.Updating times...                                |   0.56s |    205 flocks
2018-05-31 00:26:30,361 -> 6.Filter phase...                                  |   0.97s |    205 flocks
2018-05-31 00:26:35,162 -> Reporting locations...                             |   4.80s |  18245 points
2018-05-31 00:26:35,162 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=1,dataset=berlin0-10
2018-05-31 00:26:39,951 -> A.Indexing points... [4.766s] [18245 results]
2018-05-31 00:26:45,032 -> B.Getting pairs... [5.081s] [5629 results]
2018-05-31 00:26:46,585 -> C.Computing centers... [1.553s] [11258 results]
2018-05-31 00:26:47,621 -> D.Indexing centers... [1.036s] [11258 results]
2018-05-31 00:26:52,458 -> E.Getting disks... [4.837s] [11258 results]
2018-05-31 00:26:52,712 -> F.Filtering less-than-mu disks... [0.254s] [1299 results]
2018-05-31 00:26:54,284 -> G.Prunning duplicate candidates... [1.572s] [640 results]
2018-05-31 00:26:54,610 -> H.Indexing candidates... [1.898s] [640 results]
2018-05-31 00:26:54,771 -> I.Getting expansions... [0.160s] [1703 results]
2018-05-31 00:26:55,088 -> J.Finding maximal disks... [0.317s] [220 results]
2018-05-31 00:26:56,564 -> K.Prunning duplicates and subsets... [1.475s] [216 results]
2018-05-31 00:26:56,564 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:26:56,564 ->   berlin0-10,   18245,  30.0,    28,  4,  21.38,    5629,     11258,          640,        216,  1
2018-05-31 00:26:56,666 -> Dropping indices...[0.102s]
2018-05-31 00:26:56,996 -> 1.Set of disks for t_i...                          |  21.83s |    216 disks
2018-05-31 00:27:00,443 -> 2.Distance Join phase...                           |   3.45s |    486 combinations
2018-05-31 00:27:03,532 -> 3.Getting candidates...                            |   3.09s |    196 candidates
2018-05-31 00:27:04,186 -> 4.Found flocks...                                  |   0.65s |    196 flocks
2018-05-31 00:27:06,340 -> 5.Updating times...                                |   1.28s |    196 flocks
2018-05-31 00:27:08,802 -> 6.Filter phase...                                  |   2.46s |    236 flocks
2018-05-31 00:27:13,596 -> Reporting locations...                             |   4.79s |  18394 points
2018-05-31 00:27:13,597 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=2,dataset=berlin0-10
2018-05-31 00:27:18,018 -> A.Indexing points... [4.401s] [18394 results]
2018-05-31 00:27:22,898 -> B.Getting pairs... [4.880s] [5701 results]
2018-05-31 00:27:24,198 -> C.Computing centers... [1.300s] [11402 results]
2018-05-31 00:27:25,140 -> D.Indexing centers... [0.942s] [11402 results]
2018-05-31 00:27:29,860 -> E.Getting disks... [4.720s] [11402 results]
2018-05-31 00:27:30,081 -> F.Filtering less-than-mu disks... [0.221s] [1336 results]
2018-05-31 00:27:31,479 -> G.Prunning duplicate candidates... [1.398s] [658 results]
2018-05-31 00:27:31,845 -> H.Indexing candidates... [1.764s] [658 results]
2018-05-31 00:27:31,999 -> I.Getting expansions... [0.154s] [1757 results]
2018-05-31 00:27:32,152 -> J.Finding maximal disks... [0.153s] [232 results]
2018-05-31 00:27:33,471 -> K.Prunning duplicates and subsets... [1.319s] [227 results]
2018-05-31 00:27:33,472 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:27:33,472 ->   berlin0-10,   18394,  30.0,    28,  4,  19.86,    5701,     11402,          658,        227,  2
2018-05-31 00:27:33,627 -> Dropping indices...[0.155s]
2018-05-31 00:27:33,884 -> 1.Set of disks for t_i...                          |  20.29s |    227 disks
2018-05-31 00:27:40,616 -> 2.Distance Join phase...                           |   6.73s |    648 combinations
2018-05-31 00:27:44,889 -> 3.Getting candidates...                            |   4.27s |    218 candidates
2018-05-31 00:27:45,954 -> 4.Found flocks...                                  |   1.07s |    218 flocks
2018-05-31 00:27:48,317 -> 5.Updating times...                                |   1.01s |    218 flocks
2018-05-31 00:27:50,142 -> 6.Filter phase...                                  |   1.83s |    248 flocks
2018-05-31 00:27:54,805 -> Reporting locations...                             |   4.66s |  18548 points
2018-05-31 00:27:54,805 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=3,dataset=berlin0-10
2018-05-31 00:28:01,774 -> A.Indexing points... [6.949s] [18548 results]
2018-05-31 00:28:11,306 -> B.Getting pairs... [9.532s] [5768 results]
2018-05-31 00:28:12,574 -> C.Computing centers... [1.268s] [11536 results]
2018-05-31 00:28:13,524 -> D.Indexing centers... [0.949s] [11536 results]
2018-05-31 00:28:20,314 -> E.Getting disks... [6.789s] [11536 results]
2018-05-31 00:28:20,590 -> F.Filtering less-than-mu disks... [0.275s] [1349 results]
2018-05-31 00:28:22,829 -> G.Prunning duplicate candidates... [2.239s] [675 results]
2018-05-31 00:28:23,156 -> H.Indexing candidates... [2.566s] [675 results]
2018-05-31 00:28:23,325 -> I.Getting expansions... [0.169s] [1875 results]
2018-05-31 00:28:23,489 -> J.Finding maximal disks... [0.164s] [230 results]
2018-05-31 00:28:25,297 -> K.Prunning duplicates and subsets... [1.808s] [225 results]
2018-05-31 00:28:25,297 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:28:25,297 ->   berlin0-10,   18548,  30.0,    28,  4,  30.47,    5768,     11536,          675,        225,  3
2018-05-31 00:28:25,514 -> Dropping indices...[0.217s]
2018-05-31 00:28:25,828 -> 1.Set of disks for t_i...                          |  31.02s |    225 disks
2018-05-31 00:28:32,150 -> 2.Distance Join phase...                           |   6.32s |    671 combinations
2018-05-31 00:28:35,959 -> 3.Getting candidates...                            |   3.81s |    220 candidates
2018-05-31 00:28:36,745 -> 4.Found flocks...                                  |   0.79s |    220 flocks
2018-05-31 00:28:39,965 -> 5.Updating times...                                |   1.22s |    220 flocks
2018-05-31 00:28:42,007 -> 6.Filter phase...                                  |   2.04s |    250 flocks
2018-05-31 00:28:46,725 -> Reporting locations...                             |   4.72s |  18548 points
2018-05-31 00:28:46,726 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=4,dataset=berlin0-10
2018-05-31 00:28:53,444 -> A.Indexing points... [6.700s] [18548 results]
2018-05-31 00:29:02,978 -> B.Getting pairs... [9.533s] [5775 results]
2018-05-31 00:29:04,275 -> C.Computing centers... [1.297s] [11550 results]
2018-05-31 00:29:05,172 -> D.Indexing centers... [0.897s] [11550 results]
2018-05-31 00:29:11,649 -> E.Getting disks... [6.477s] [11550 results]
2018-05-31 00:29:11,874 -> F.Filtering less-than-mu disks... [0.225s] [1369 results]
2018-05-31 00:29:13,735 -> G.Prunning duplicate candidates... [1.861s] [694 results]
2018-05-31 00:29:14,036 -> H.Indexing candidates... [2.162s] [694 results]
2018-05-31 00:29:14,187 -> I.Getting expansions... [0.151s] [1914 results]
2018-05-31 00:29:14,338 -> J.Finding maximal disks... [0.151s] [245 results]
2018-05-31 00:29:16,021 -> K.Prunning duplicates and subsets... [1.683s] [238 results]
2018-05-31 00:29:16,021 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:29:16,021 ->   berlin0-10,   18548,  30.0,    28,  4,  29.28,    5775,     11550,          694,        238,  4
2018-05-31 00:29:16,317 -> Dropping indices...[0.296s]
2018-05-31 00:29:16,622 -> 1.Set of disks for t_i...                          |  29.90s |    238 disks
2018-05-31 00:29:23,524 -> 2.Distance Join phase...                           |   6.90s |    701 combinations
2018-05-31 00:29:27,917 -> 3.Getting candidates...                            |   4.39s |    224 candidates
2018-05-31 00:29:28,814 -> 4.Found flocks...                                  |   0.90s |    224 flocks
2018-05-31 00:29:32,710 -> 5.Updating times...                                |   1.52s |    224 flocks
2018-05-31 00:29:34,908 -> 6.Filter phase...                                  |   2.20s |    249 flocks
2018-05-31 00:29:39,669 -> Reporting locations...                             |   4.76s |  18548 points
2018-05-31 00:29:39,670 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=5,dataset=berlin0-10
2018-05-31 00:29:46,596 -> A.Indexing points... [6.907s] [18548 results]
2018-05-31 00:29:56,003 -> B.Getting pairs... [9.406s] [5765 results]
2018-05-31 00:29:57,298 -> C.Computing centers... [1.295s] [11530 results]
2018-05-31 00:29:58,194 -> D.Indexing centers... [0.896s] [11530 results]
2018-05-31 00:30:04,561 -> E.Getting disks... [6.367s] [11530 results]
2018-05-31 00:30:04,864 -> F.Filtering less-than-mu disks... [0.303s] [1362 results]
2018-05-31 00:30:06,758 -> G.Prunning duplicate candidates... [1.894s] [686 results]
2018-05-31 00:30:07,075 -> H.Indexing candidates... [2.211s] [686 results]
2018-05-31 00:30:07,255 -> I.Getting expansions... [0.180s] [1917 results]
2018-05-31 00:30:07,389 -> J.Finding maximal disks... [0.134s] [237 results]
2018-05-31 00:30:09,090 -> K.Prunning duplicates and subsets... [1.701s] [234 results]
2018-05-31 00:30:09,091 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:30:09,091 ->   berlin0-10,   18548,  30.0,    28,  4,  29.40,    5765,     11530,          686,        234,  5
2018-05-31 00:30:09,414 -> Dropping indices...[0.323s]
2018-05-31 00:30:09,660 -> 1.Set of disks for t_i...                          |  29.99s |    234 disks
2018-05-31 00:30:17,119 -> 2.Distance Join phase...                           |   7.46s |    630 combinations
2018-05-31 00:30:21,946 -> 3.Getting candidates...                            |   4.83s |    230 candidates
2018-05-31 00:30:23,032 -> 4.Found flocks...                                  |   1.09s |    230 flocks
2018-05-31 00:30:27,742 -> 5.Updating times...                                |   1.53s |    230 flocks
2018-05-31 00:30:30,163 -> 6.Filter phase...                                  |   2.42s |    259 flocks
2018-05-31 00:30:34,827 -> Reporting locations...                             |   4.66s |  18546 points
2018-05-31 00:30:34,827 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=6,dataset=berlin0-10
2018-05-31 00:30:41,582 -> A.Indexing points... [6.737s] [18546 results]
2018-05-31 00:30:51,206 -> B.Getting pairs... [9.624s] [5758 results]
2018-05-31 00:30:52,426 -> C.Computing centers... [1.220s] [11516 results]
2018-05-31 00:30:53,382 -> D.Indexing centers... [0.956s] [11516 results]
2018-05-31 00:31:00,242 -> E.Getting disks... [6.860s] [11516 results]
2018-05-31 00:31:00,487 -> F.Filtering less-than-mu disks... [0.245s] [1346 results]
2018-05-31 00:31:02,494 -> G.Prunning duplicate candidates... [2.006s] [681 results]
2018-05-31 00:31:02,827 -> H.Indexing candidates... [2.339s] [681 results]
2018-05-31 00:31:03,108 -> I.Getting expansions... [0.281s] [1951 results]
2018-05-31 00:31:03,246 -> J.Finding maximal disks... [0.138s] [225 results]
2018-05-31 00:31:05,268 -> K.Prunning duplicates and subsets... [2.022s] [222 results]
2018-05-31 00:31:05,268 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:31:05,269 ->   berlin0-10,   18546,  30.0,    28,  4,  30.42,    5758,     11516,          681,        222,  6
2018-05-31 00:31:05,712 -> Dropping indices...[0.443s]
2018-05-31 00:31:05,988 -> 1.Set of disks for t_i...                          |  31.16s |    222 disks
2018-05-31 00:31:14,131 -> 2.Distance Join phase...                           |   8.14s |    619 combinations
2018-05-31 00:31:18,829 -> 3.Getting candidates...                            |   4.70s |    224 candidates
2018-05-31 00:31:19,981 -> 4.Found flocks...                                  |   1.15s |    224 flocks
2018-05-31 00:31:26,432 -> 5.Updating times...                                |   1.49s |    224 flocks
2018-05-31 00:31:28,812 -> 6.Filter phase...                                  |   2.38s |    247 flocks
2018-05-31 00:31:33,521 -> Reporting locations...                             |   4.71s |  18546 points
2018-05-31 00:31:33,521 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=7,dataset=berlin0-10
2018-05-31 00:31:40,388 -> A.Indexing points... [6.849s] [18546 results]
2018-05-31 00:31:50,048 -> B.Getting pairs... [9.660s] [5788 results]
2018-05-31 00:31:51,301 -> C.Computing centers... [1.253s] [11576 results]
2018-05-31 00:31:52,315 -> D.Indexing centers... [1.014s] [11576 results]
2018-05-31 00:31:58,831 -> E.Getting disks... [6.516s] [11576 results]
2018-05-31 00:31:59,098 -> F.Filtering less-than-mu disks... [0.267s] [1361 results]
2018-05-31 00:32:01,133 -> G.Prunning duplicate candidates... [2.035s] [688 results]
2018-05-31 00:32:01,478 -> H.Indexing candidates... [2.380s] [688 results]
2018-05-31 00:32:01,655 -> I.Getting expansions... [0.177s] [1882 results]
2018-05-31 00:32:01,790 -> J.Finding maximal disks... [0.135s] [233 results]
2018-05-31 00:32:03,568 -> K.Prunning duplicates and subsets... [1.778s] [231 results]
2018-05-31 00:32:03,568 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:32:03,568 ->   berlin0-10,   18546,  30.0,    28,  4,  30.03,    5788,     11576,          688,        231,  7
2018-05-31 00:32:04,047 -> Dropping indices...[0.479s]
2018-05-31 00:32:04,359 -> 1.Set of disks for t_i...                          |  30.84s |    231 disks
2018-05-31 00:32:12,734 -> 2.Distance Join phase...                           |   8.38s |    597 combinations
2018-05-31 00:32:17,787 -> 3.Getting candidates...                            |   5.05s |    213 candidates
2018-05-31 00:32:19,048 -> 4.Found flocks...                                  |   1.26s |    213 flocks
2018-05-31 00:32:25,202 -> 5.Updating times...                                |   1.69s |    213 flocks
2018-05-31 00:32:27,779 -> 6.Filter phase...                                  |   2.58s |    244 flocks
2018-05-31 00:32:32,353 -> Reporting locations...                             |   4.57s |  18546 points
2018-05-31 00:32:32,353 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=8,dataset=berlin0-10
2018-05-31 00:32:37,129 -> A.Indexing points... [4.758s] [18546 results]
2018-05-31 00:32:43,906 -> B.Getting pairs... [6.777s] [5791 results]
2018-05-31 00:32:45,283 -> C.Computing centers... [1.377s] [11582 results]
2018-05-31 00:32:46,206 -> D.Indexing centers... [0.923s] [11582 results]
2018-05-31 00:32:51,435 -> E.Getting disks... [5.228s] [11582 results]
2018-05-31 00:32:51,638 -> F.Filtering less-than-mu disks... [0.203s] [1316 results]
2018-05-31 00:32:53,052 -> G.Prunning duplicate candidates... [1.414s] [670 results]
2018-05-31 00:32:53,356 -> H.Indexing candidates... [1.718s] [670 results]
2018-05-31 00:32:53,511 -> I.Getting expansions... [0.155s] [1792 results]
2018-05-31 00:32:53,645 -> J.Finding maximal disks... [0.134s] [220 results]
2018-05-31 00:32:55,066 -> K.Prunning duplicates and subsets... [1.421s] [219 results]
2018-05-31 00:32:55,066 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:32:55,066 ->   berlin0-10,   18546,  30.0,    28,  4,  22.70,    5791,     11582,          670,        219,  8
2018-05-31 00:32:55,683 -> Dropping indices...[0.617s]
2018-05-31 00:32:55,982 -> 1.Set of disks for t_i...                          |  23.63s |    219 disks
2018-05-31 00:33:05,088 -> 2.Distance Join phase...                           |   9.11s |    520 combinations
2018-05-31 00:33:10,011 -> 3.Getting candidates...                            |   4.92s |    211 candidates
2018-05-31 00:33:11,377 -> 4.Found flocks...                                  |   1.37s |    211 flocks
2018-05-31 00:33:18,430 -> 5.Updating times...                                |   1.81s |    211 flocks
2018-05-31 00:33:22,780 -> 6.Filter phase...                                  |   4.35s |    232 flocks
2018-05-31 00:33:27,341 -> Reporting locations...                             |   4.56s |  18546 points
2018-05-31 00:33:27,367 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=9,dataset=berlin0-10
2018-05-31 00:33:35,184 -> A.Indexing points... [7.778s] [18546 results]
2018-05-31 00:33:45,890 -> B.Getting pairs... [10.706s] [5802 results]
2018-05-31 00:33:47,259 -> C.Computing centers... [1.369s] [11604 results]
2018-05-31 00:33:48,137 -> D.Indexing centers... [0.878s] [11604 results]
2018-05-31 00:33:55,402 -> E.Getting disks... [7.264s] [11604 results]
2018-05-31 00:33:55,622 -> F.Filtering less-than-mu disks... [0.220s] [1306 results]
2018-05-31 00:33:58,251 -> G.Prunning duplicate candidates... [2.629s] [675 results]
2018-05-31 00:33:58,533 -> H.Indexing candidates... [2.911s] [675 results]
2018-05-31 00:33:58,694 -> I.Getting expansions... [0.160s] [1813 results]
2018-05-31 00:33:58,826 -> J.Finding maximal disks... [0.132s] [212 results]
2018-05-31 00:34:00,752 -> K.Prunning duplicates and subsets... [1.926s] [210 results]
2018-05-31 00:34:00,752 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:34:00,752 ->   berlin0-10,   18546,  30.0,    28,  4,  33.35,    5802,     11604,          675,        210,  9
2018-05-31 00:34:01,413 -> Dropping indices...[0.661s]
2018-05-31 00:34:01,668 -> 1.Set of disks for t_i...                          |  34.30s |    210 disks
2018-05-31 00:34:11,051 -> 2.Distance Join phase...                           |   9.38s |    474 combinations
2018-05-31 00:34:16,589 -> 3.Getting candidates...                            |   5.54s |    206 candidates
2018-05-31 00:34:18,405 -> 4.Found flocks...                                  |   1.82s |    206 flocks
2018-05-31 00:34:26,772 -> 5.Updating times...                                |   2.23s |    206 flocks
2018-05-31 00:34:30,334 -> 6.Filter phase...                                  |   3.56s |    226 flocks
2018-05-31 00:34:34,955 -> Reporting locations...                             |   4.62s |  18546 points
2018-05-31 00:34:34,955 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=10,dataset=berlin0-10
2018-05-31 00:34:42,928 -> A.Indexing points... [7.938s] [18546 results]
2018-05-31 00:34:53,763 -> B.Getting pairs... [10.835s] [5797 results]
2018-05-31 00:34:55,051 -> C.Computing centers... [1.288s] [11594 results]
2018-05-31 00:34:55,948 -> D.Indexing centers... [0.897s] [11594 results]
2018-05-31 00:35:02,972 -> E.Getting disks... [7.024s] [11594 results]
2018-05-31 00:35:03,190 -> F.Filtering less-than-mu disks... [0.218s] [1312 results]
2018-05-31 00:35:05,282 -> G.Prunning duplicate candidates... [2.092s] [675 results]
2018-05-31 00:35:05,588 -> H.Indexing candidates... [2.398s] [675 results]
2018-05-31 00:35:05,741 -> I.Getting expansions... [0.153s] [1804 results]
2018-05-31 00:35:05,916 -> J.Finding maximal disks... [0.175s] [212 results]
2018-05-31 00:35:07,934 -> K.Prunning duplicates and subsets... [2.017s] [211 results]
2018-05-31 00:35:07,935 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:35:07,935 ->   berlin0-10,   18546,  30.0,    28,  4,  32.95,    5797,     11594,          675,        211, 10
2018-05-31 00:35:08,766 -> Dropping indices...[0.831s]
2018-05-31 00:35:09,038 -> 1.Set of disks for t_i...                          |  34.08s |    211 disks
2018-05-31 00:35:19,761 -> 2.Distance Join phase...                           |  10.72s |    458 combinations
2018-05-31 00:35:25,555 -> 3.Getting candidates...                            |   5.79s |    197 candidates
2018-05-31 00:35:27,065 -> 4.Found flocks...                                  |   1.51s |    197 flocks
2018-05-31 00:35:35,462 -> 5.Updating times...                                |   1.83s |    197 flocks
2018-05-31 00:35:38,200 -> 6.Filter phase...                                  |   2.74s |    221 flocks
2018-05-31 00:35:38,200 -> 

PFLOCK_SJ	30.0	4	2	2139

2018-05-31 00:35:44,028 -> Running SpatialJoin...                             | 593.16s |   2139 flocks
2018-05-31 00:35:44,029 -> method=SpatialJoin,cores=28,epsilon=30.0,mu=4,delta=2,time=593.156,master=spark://169.235.27.134:7077
2018-05-31 00:35:44,029 -> Closing app...
acald013@dblab-rack15: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
FLOCKFINDER=SpatialJoin;TIME=Thu May 31 00:35:44 PDT 2018;RUN=1527751534;NODES=4;ESTART=;EEND=;ESTEP=;MU=4;DELTA=;SCRIPT=DeltaBenchmarker;EVENT=End
FLOCKFINDER=MergeLast;TIME=Thu May 31 00:35:44 PDT 2018;RUN=1527752144;NODES=4;ESTART=;EEND=;ESTEP=;MU=4;DELTA=;SCRIPT=DeltaBenchmarker;EVENT=Start
WARNING:root:Setting 4 nodes...
acald013@dblab-rack12: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack15: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack14: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack11: no org.apache.spark.deploy.worker.Worker to stop
no org.apache.spark.deploy.master.Master to stop
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack15: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack15.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
WARNING:root:4 nodes has been set...
2018-05-31 00:35:52,169 -> Starting app...
2018-05-31 00:35:55,014 -> Starting session                                   |   2.84s |      0 
2018-05-31 00:35:55,028 -> Setting paramaters                                 |   0.01s |      0 
2018-05-31 00:35:58,268 -> Reading data                                       |   3.24s | 203106 points
2018-05-31 00:36:01,468 -> Extracting timestamps                              |   3.20s |     11 timestamps
2018-05-31 00:36:01,477 -> === MergeLast Start ===
2018-05-31 00:36:07,781 -> Reporting locations at t=0...                      |   6.10s |  18093 points
2018-05-31 00:36:07,797 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=0,dataset=berlin0-10
2018-05-31 00:36:16,210 -> A.Indexing points... [8.366s] [18093 results]
2018-05-31 00:36:23,699 -> B.Getting pairs... [7.488s] [5511 results]
2018-05-31 00:36:25,790 -> C.Computing centers... [2.091s] [11022 results]
2018-05-31 00:36:27,153 -> D.Indexing centers... [1.363s] [11022 results]
2018-05-31 00:36:32,776 -> E.Getting disks... [5.623s] [11022 results]
2018-05-31 00:36:33,158 -> F.Filtering less-than-mu disks... [0.381s] [1210 results]
2018-05-31 00:36:35,803 -> G.Prunning duplicate candidates... [2.645s] [599 results]
2018-05-31 00:36:36,209 -> H.Indexing candidates... [3.051s] [599 results]
2018-05-31 00:36:36,389 -> I.Getting expansions... [0.180s] [1657 results]
2018-05-31 00:36:37,020 -> J.Finding maximal disks... [0.631s] [206 results]
2018-05-31 00:36:38,778 -> K.Prunning duplicates and subsets... [1.758s] [205 results]
2018-05-31 00:36:38,778 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:36:38,778 ->   berlin0-10,   18093,  30.0,    28,  4,  30.93,    5511,     11022,          599,        205,  0
2018-05-31 00:36:38,870 -> Dropping indices...[0.092s]
2018-05-31 00:36:39,241 -> 1.Set of disks for t_i...                          |  31.46s |    205 disks
2018-05-31 00:36:45,321 -> Reporting locations at t=1...                      |   6.08s |  18245 points
2018-05-31 00:36:45,322 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=1,dataset=berlin0-10
2018-05-31 00:36:50,332 -> A.Indexing points... [4.989s] [18245 results]
2018-05-31 00:36:55,694 -> B.Getting pairs... [5.362s] [5629 results]
2018-05-31 00:36:57,196 -> C.Computing centers... [1.501s] [11258 results]
2018-05-31 00:36:58,250 -> D.Indexing centers... [1.054s] [11258 results]
2018-05-31 00:37:02,911 -> E.Getting disks... [4.661s] [11258 results]
2018-05-31 00:37:03,180 -> F.Filtering less-than-mu disks... [0.269s] [1299 results]
2018-05-31 00:37:04,610 -> G.Prunning duplicate candidates... [1.430s] [640 results]
2018-05-31 00:37:04,939 -> H.Indexing candidates... [1.758s] [640 results]
2018-05-31 00:37:05,125 -> I.Getting expansions... [0.186s] [1703 results]
2018-05-31 00:37:05,297 -> J.Finding maximal disks... [0.172s] [220 results]
2018-05-31 00:37:06,484 -> K.Prunning duplicates and subsets... [1.187s] [216 results]
2018-05-31 00:37:06,484 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:37:06,484 ->   berlin0-10,   18245,  30.0,    28,  4,  21.14,    5629,     11258,          640,        216,  1
2018-05-31 00:37:06,552 -> Dropping indices...[0.068s]
2018-05-31 00:37:06,802 -> 2.Set of disks for t_i+delta...                    |  21.48s |    205 disks
2018-05-31 00:37:14,627 -> 3.Joining timestams                                |   7.82s |    319 candidates
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 20 in stage 1467.0 failed 4 times, most recent failure: Lost task 20.3 in stage 1467.0 (TID 66170, 169.235.27.135, executor 2): java.util.NoSuchElementException: head of empty list
	at scala.collection.immutable.Nil$.head(List.scala:420)
	at scala.collection.immutable.Nil$.head(List.scala:417)
	at scala.collection.generic.TraversableForwarder$class.head(TraversableForwarder.scala:56)
	at scala.collection.mutable.ListBuffer.head(ListBuffer.scala:45)
	at FlockFinderMergeLast$.computeMaximalDisks(FlockFinderMergeLast.scala:277)
	at FlockFinderMergeLast$$anonfun$runMergeLast$1$$anonfun$13.apply(FlockFinderMergeLast.scala:221)
	at FlockFinderMergeLast$$anonfun$runMergeLast$1$$anonfun$13.apply(FlockFinderMergeLast.scala:219)
	at org.apache.spark.sql.execution.MapElementsExec$$anonfun$8$$anonfun$apply$1.apply(objects.scala:237)
	at org.apache.spark.sql.execution.MapElementsExec$$anonfun$8$$anonfun$apply$1.apply(objects.scala:237)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.columnar.InMemoryRelation$$anonfun$1$$anon$1.hasNext(InMemoryRelation.scala:138)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:215)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:957)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:948)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:888)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:948)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:694)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:334)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1958)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:935)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:934)
	at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:275)
	at org.apache.spark.sql.Dataset$$anonfun$org$apache$spark$sql$Dataset$$execute$1$1.apply(Dataset.scala:2371)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:57)
	at org.apache.spark.sql.Dataset.withNewExecutionId(Dataset.scala:2765)
	at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$execute$1(Dataset.scala:2370)
	at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collect(Dataset.scala:2377)
	at org.apache.spark.sql.Dataset$$anonfun$count$1.apply(Dataset.scala:2405)
	at org.apache.spark.sql.Dataset$$anonfun$count$1.apply(Dataset.scala:2404)
	at org.apache.spark.sql.Dataset.withCallback(Dataset.scala:2778)
	at org.apache.spark.sql.Dataset.count(Dataset.scala:2404)
	at FlockFinderMergeLast$$anonfun$runMergeLast$1.apply(FlockFinderMergeLast.scala:228)
	at FlockFinderMergeLast$$anonfun$runMergeLast$1.apply(FlockFinderMergeLast.scala:121)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at FlockFinderMergeLast$.runMergeLast(FlockFinderMergeLast.scala:121)
	at FlockFinderMergeLast$$anonfun$run$1$$anonfun$apply$mcVI$sp$1$$anonfun$apply$mcVI$sp$2.apply$mcVD$sp(FlockFinderMergeLast.scala:91)
	at FlockFinderMergeLast$$anonfun$run$1$$anonfun$apply$mcVI$sp$1$$anonfun$apply$mcVI$sp$2.apply(FlockFinderMergeLast.scala:86)
	at FlockFinderMergeLast$$anonfun$run$1$$anonfun$apply$mcVI$sp$1$$anonfun$apply$mcVI$sp$2.apply(FlockFinderMergeLast.scala:86)
	at scala.collection.immutable.NumericRange.foreach(NumericRange.scala:73)
	at FlockFinderMergeLast$$anonfun$run$1$$anonfun$apply$mcVI$sp$1.apply$mcVI$sp(FlockFinderMergeLast.scala:86)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at FlockFinderMergeLast$$anonfun$run$1.apply$mcVI$sp(FlockFinderMergeLast.scala:86)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at FlockFinderMergeLast$.run(FlockFinderMergeLast.scala:86)
	at FlockFinderMergeLast$.main(FlockFinderMergeLast.scala:585)
	at FlockFinderMergeLast.main(FlockFinderMergeLast.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: java.util.NoSuchElementException: head of empty list
	at scala.collection.immutable.Nil$.head(List.scala:420)
	at scala.collection.immutable.Nil$.head(List.scala:417)
	at scala.collection.generic.TraversableForwarder$class.head(TraversableForwarder.scala:56)
	at scala.collection.mutable.ListBuffer.head(ListBuffer.scala:45)
	at FlockFinderMergeLast$.computeMaximalDisks(FlockFinderMergeLast.scala:277)
	at FlockFinderMergeLast$$anonfun$runMergeLast$1$$anonfun$13.apply(FlockFinderMergeLast.scala:221)
	at FlockFinderMergeLast$$anonfun$runMergeLast$1$$anonfun$13.apply(FlockFinderMergeLast.scala:219)
	at org.apache.spark.sql.execution.MapElementsExec$$anonfun$8$$anonfun$apply$1.apply(objects.scala:237)
	at org.apache.spark.sql.execution.MapElementsExec$$anonfun$8$$anonfun$apply$1.apply(objects.scala:237)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.columnar.InMemoryRelation$$anonfun$1$$anon$1.hasNext(InMemoryRelation.scala:138)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:215)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:957)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:948)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:888)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:948)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:694)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:334)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack15: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
FLOCKFINDER=MergeLast;TIME=Thu May 31 00:37:25 PDT 2018;RUN=1527752144;NODES=4;ESTART=;EEND=;ESTEP=;MU=4;DELTA=;SCRIPT=DeltaBenchmarker;EVENT=End
FLOCKFINDER=SpatialJoin;TIME=Thu May 31 00:37:25 PDT 2018;RUN=1527752245;NODES=4;ESTART=;EEND=;ESTEP=;MU=4;DELTA=;SCRIPT=DeltaBenchmarker;EVENT=Start
WARNING:root:Setting 4 nodes...
acald013@dblab-rack12: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack15: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack14: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack11: no org.apache.spark.deploy.worker.Worker to stop
no org.apache.spark.deploy.master.Master to stop
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack15: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack15.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
WARNING:root:4 nodes has been set...
2018-05-31 00:37:32,959 -> Starting app...
2018-05-31 00:37:35,653 -> Starting session                                   |   2.69s |      0 
2018-05-31 00:37:35,667 -> Setting paramaters                                 |   0.01s |      0 
2018-05-31 00:37:38,842 -> Reading data                                       |   3.18s | 203106 points
2018-05-31 00:37:42,111 -> Extracting timestamps                              |   3.27s |     11 timestamps
2018-05-31 00:37:42,119 -> === SpatialJoin Start ===
2018-05-31 00:37:47,662 -> Reporting locations...                             |   5.30s |  18093 points
2018-05-31 00:37:47,678 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=0,dataset=berlin0-10
2018-05-31 00:37:55,906 -> A.Indexing points... [8.182s] [18093 results]
2018-05-31 00:38:03,459 -> B.Getting pairs... [7.552s] [5511 results]
2018-05-31 00:38:05,566 -> C.Computing centers... [2.107s] [11022 results]
2018-05-31 00:38:06,902 -> D.Indexing centers... [1.336s] [11022 results]
2018-05-31 00:38:12,844 -> E.Getting disks... [5.942s] [11022 results]
2018-05-31 00:38:13,261 -> F.Filtering less-than-mu disks... [0.417s] [1210 results]
2018-05-31 00:38:15,711 -> G.Prunning duplicate candidates... [2.450s] [599 results]
2018-05-31 00:38:16,194 -> H.Indexing candidates... [2.933s] [599 results]
2018-05-31 00:38:16,419 -> I.Getting expansions... [0.225s] [1657 results]
2018-05-31 00:38:17,066 -> J.Finding maximal disks... [0.646s] [206 results]
2018-05-31 00:38:18,842 -> K.Prunning duplicates and subsets... [1.776s] [205 results]
2018-05-31 00:38:18,842 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:38:18,842 ->   berlin0-10,   18093,  30.0,    28,  4,  31.12,    5511,     11022,          599,        205,  0
2018-05-31 00:38:18,909 -> Dropping indices...[0.067s]
2018-05-31 00:38:19,257 -> 1.Set of disks for t_i...                          |  31.60s |    205 disks
2018-05-31 00:38:19,617 -> 4.Found flocks...                                  |   0.36s |      0 flocks
2018-05-31 00:38:20,367 -> 5.Updating times...                                |   0.47s |    205 flocks
2018-05-31 00:38:21,377 -> 6.Filter phase...                                  |   1.01s |    205 flocks
2018-05-31 00:38:27,161 -> Reporting locations...                             |   5.78s |  18245 points
2018-05-31 00:38:27,161 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=1,dataset=berlin0-10
2018-05-31 00:38:31,692 -> A.Indexing points... [4.511s] [18245 results]
2018-05-31 00:38:36,753 -> B.Getting pairs... [5.061s] [5629 results]
2018-05-31 00:38:38,170 -> C.Computing centers... [1.417s] [11258 results]
2018-05-31 00:38:39,374 -> D.Indexing centers... [1.204s] [11258 results]
2018-05-31 00:38:44,048 -> E.Getting disks... [4.674s] [11258 results]
2018-05-31 00:38:44,298 -> F.Filtering less-than-mu disks... [0.250s] [1299 results]
2018-05-31 00:38:45,713 -> G.Prunning duplicate candidates... [1.415s] [640 results]
2018-05-31 00:38:46,072 -> H.Indexing candidates... [1.774s] [640 results]
2018-05-31 00:38:46,237 -> I.Getting expansions... [0.165s] [1703 results]
2018-05-31 00:38:46,516 -> J.Finding maximal disks... [0.279s] [220 results]
2018-05-31 00:38:47,812 -> K.Prunning duplicates and subsets... [1.296s] [216 results]
2018-05-31 00:38:47,812 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:38:47,812 ->   berlin0-10,   18245,  30.0,    28,  4,  20.63,    5629,     11258,          640,        216,  1
2018-05-31 00:38:47,890 -> Dropping indices...[0.078s]
2018-05-31 00:38:48,181 -> 1.Set of disks for t_i...                          |  21.02s |    216 disks
2018-05-31 00:38:51,645 -> 2.Distance Join phase...                           |   3.46s |    645 combinations
2018-05-31 00:38:54,839 -> 3.Getting candidates...                            |   3.19s |    196 candidates
2018-05-31 00:38:55,660 -> 4.Found flocks...                                  |   0.82s |      0 flocks
2018-05-31 00:38:58,063 -> 5.Updating times...                                |   1.45s |    196 flocks
2018-05-31 00:39:00,793 -> 6.Filter phase...                                  |   2.73s |    236 flocks
2018-05-31 00:39:06,094 -> Reporting locations...                             |   5.30s |  18394 points
2018-05-31 00:39:06,094 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=2,dataset=berlin0-10
2018-05-31 00:39:10,226 -> A.Indexing points... [4.113s] [18394 results]
2018-05-31 00:39:14,683 -> B.Getting pairs... [4.457s] [5701 results]
2018-05-31 00:39:16,022 -> C.Computing centers... [1.339s] [11402 results]
2018-05-31 00:39:16,939 -> D.Indexing centers... [0.917s] [11402 results]
2018-05-31 00:39:21,068 -> E.Getting disks... [4.129s] [11402 results]
2018-05-31 00:39:21,292 -> F.Filtering less-than-mu disks... [0.224s] [1336 results]
2018-05-31 00:39:22,559 -> G.Prunning duplicate candidates... [1.267s] [658 results]
2018-05-31 00:39:22,859 -> H.Indexing candidates... [1.567s] [658 results]
2018-05-31 00:39:23,024 -> I.Getting expansions... [0.165s] [1757 results]
2018-05-31 00:39:23,171 -> J.Finding maximal disks... [0.147s] [232 results]
2018-05-31 00:39:24,351 -> K.Prunning duplicates and subsets... [1.180s] [227 results]
2018-05-31 00:39:24,352 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:39:24,352 ->   berlin0-10,   18394,  30.0,    28,  4,  18.24,    5701,     11402,          658,        227,  2
2018-05-31 00:39:24,503 -> Dropping indices...[0.151s]
2018-05-31 00:39:24,744 -> 1.Set of disks for t_i...                          |  18.65s |    227 disks
2018-05-31 00:39:32,064 -> 2.Distance Join phase...                           |   7.32s |    901 combinations
2018-05-31 00:39:36,868 -> 3.Getting candidates...                            |   4.80s |    239 candidates
2018-05-31 00:39:37,650 -> 4.Found flocks...                                  |   0.78s |    199 flocks
2018-05-31 00:39:40,285 -> 5.Updating times...                                |   1.16s |    239 flocks
2018-05-31 00:39:42,308 -> 6.Filter phase...                                  |   2.02s |    268 flocks
2018-05-31 00:39:47,400 -> Reporting locations...                             |   5.09s |  18548 points
2018-05-31 00:39:47,400 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=3,dataset=berlin0-10
2018-05-31 00:39:54,413 -> A.Indexing points... [6.995s] [18548 results]
2018-05-31 00:40:04,617 -> B.Getting pairs... [10.204s] [5768 results]
2018-05-31 00:40:05,892 -> C.Computing centers... [1.275s] [11536 results]
2018-05-31 00:40:06,917 -> D.Indexing centers... [1.025s] [11536 results]
2018-05-31 00:40:14,302 -> E.Getting disks... [7.385s] [11536 results]
2018-05-31 00:40:14,546 -> F.Filtering less-than-mu disks... [0.244s] [1349 results]
2018-05-31 00:40:16,764 -> G.Prunning duplicate candidates... [2.218s] [675 results]
2018-05-31 00:40:17,090 -> H.Indexing candidates... [2.544s] [675 results]
2018-05-31 00:40:17,328 -> I.Getting expansions... [0.238s] [1875 results]
2018-05-31 00:40:17,483 -> J.Finding maximal disks... [0.154s] [230 results]
2018-05-31 00:40:19,487 -> K.Prunning duplicates and subsets... [2.004s] [225 results]
2018-05-31 00:40:19,487 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:40:19,487 ->   berlin0-10,   18548,  30.0,    28,  4,  32.07,    5768,     11536,          675,        225,  3
2018-05-31 00:40:19,671 -> Dropping indices...[0.184s]
2018-05-31 00:40:19,951 -> 1.Set of disks for t_i...                          |  32.55s |    225 disks
2018-05-31 00:40:26,628 -> 2.Distance Join phase...                           |   6.68s |   1012 combinations
2018-05-31 00:40:30,945 -> 3.Getting candidates...                            |   4.32s |    242 candidates
2018-05-31 00:40:31,919 -> 4.Found flocks...                                  |   0.97s |    210 flocks
2018-05-31 00:40:35,357 -> 5.Updating times...                                |   1.33s |    242 flocks
2018-05-31 00:40:37,839 -> 6.Filter phase...                                  |   2.48s |    269 flocks
2018-05-31 00:40:42,863 -> Reporting locations...                             |   5.02s |  18548 points
2018-05-31 00:40:42,863 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=4,dataset=berlin0-10
2018-05-31 00:40:49,769 -> A.Indexing points... [6.887s] [18548 results]
2018-05-31 00:40:59,980 -> B.Getting pairs... [10.211s] [5775 results]
2018-05-31 00:41:01,306 -> C.Computing centers... [1.326s] [11550 results]
2018-05-31 00:41:02,210 -> D.Indexing centers... [0.903s] [11550 results]
2018-05-31 00:41:09,428 -> E.Getting disks... [7.218s] [11550 results]
2018-05-31 00:41:09,651 -> F.Filtering less-than-mu disks... [0.223s] [1369 results]
2018-05-31 00:41:11,817 -> G.Prunning duplicate candidates... [2.166s] [694 results]
2018-05-31 00:41:12,136 -> H.Indexing candidates... [2.485s] [694 results]
2018-05-31 00:41:12,305 -> I.Getting expansions... [0.169s] [1914 results]
2018-05-31 00:41:12,451 -> J.Finding maximal disks... [0.146s] [245 results]
2018-05-31 00:41:14,681 -> K.Prunning duplicates and subsets... [2.230s] [238 results]
2018-05-31 00:41:14,681 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:41:14,681 ->   berlin0-10,   18548,  30.0,    28,  4,  31.80,    5775,     11550,          694,        238,  4
2018-05-31 00:41:14,926 -> Dropping indices...[0.245s]
2018-05-31 00:41:15,213 -> 1.Set of disks for t_i...                          |  32.35s |    238 disks
2018-05-31 00:41:22,974 -> 2.Distance Join phase...                           |   7.76s |   1066 combinations
2018-05-31 00:41:28,008 -> 3.Getting candidates...                            |   5.03s |    250 candidates
2018-05-31 00:41:28,944 -> 4.Found flocks...                                  |   0.94s |    220 flocks
2018-05-31 00:41:33,186 -> 5.Updating times...                                |   1.49s |    250 flocks
2018-05-31 00:41:35,648 -> 6.Filter phase...                                  |   2.46s |    274 flocks
2018-05-31 00:41:40,729 -> Reporting locations...                             |   5.08s |  18548 points
2018-05-31 00:41:40,729 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=5,dataset=berlin0-10
2018-05-31 00:41:47,708 -> A.Indexing points... [6.961s] [18548 results]
2018-05-31 00:41:57,956 -> B.Getting pairs... [10.248s] [5765 results]
2018-05-31 00:41:59,248 -> C.Computing centers... [1.292s] [11530 results]
2018-05-31 00:42:00,243 -> D.Indexing centers... [0.995s] [11530 results]
2018-05-31 00:42:06,979 -> E.Getting disks... [6.736s] [11530 results]
2018-05-31 00:42:07,186 -> F.Filtering less-than-mu disks... [0.207s] [1362 results]
2018-05-31 00:42:09,443 -> G.Prunning duplicate candidates... [2.256s] [686 results]
2018-05-31 00:42:09,797 -> H.Indexing candidates... [2.610s] [686 results]
2018-05-31 00:42:09,977 -> I.Getting expansions... [0.180s] [1917 results]
2018-05-31 00:42:10,113 -> J.Finding maximal disks... [0.136s] [237 results]
2018-05-31 00:42:12,260 -> K.Prunning duplicates and subsets... [2.147s] [234 results]
2018-05-31 00:42:12,260 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:42:12,261 ->   berlin0-10,   18548,  30.0,    28,  4,  31.51,    5765,     11530,          686,        234,  5
2018-05-31 00:42:12,643 -> Dropping indices...[0.382s]
2018-05-31 00:42:12,943 -> 1.Set of disks for t_i...                          |  32.21s |    234 disks
2018-05-31 00:42:20,808 -> 2.Distance Join phase...                           |   7.87s |   1035 combinations
2018-05-31 00:42:25,792 -> 3.Getting candidates...                            |   4.98s |    240 candidates
2018-05-31 00:42:26,864 -> 4.Found flocks...                                  |   1.07s |    213 flocks
2018-05-31 00:42:32,006 -> 5.Updating times...                                |   1.64s |    240 flocks
2018-05-31 00:42:34,631 -> 6.Filter phase...                                  |   2.62s |    267 flocks
2018-05-31 00:42:39,983 -> Reporting locations...                             |   5.35s |  18546 points
2018-05-31 00:42:39,984 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=6,dataset=berlin0-10
2018-05-31 00:42:47,366 -> A.Indexing points... [7.365s] [18546 results]
2018-05-31 00:42:58,046 -> B.Getting pairs... [10.680s] [5758 results]
2018-05-31 00:42:59,419 -> C.Computing centers... [1.373s] [11516 results]
2018-05-31 00:43:00,280 -> D.Indexing centers... [0.861s] [11516 results]
2018-05-31 00:43:07,151 -> E.Getting disks... [6.870s] [11516 results]
2018-05-31 00:43:07,380 -> F.Filtering less-than-mu disks... [0.229s] [1346 results]
2018-05-31 00:43:09,498 -> G.Prunning duplicate candidates... [2.118s] [681 results]
2018-05-31 00:43:09,801 -> H.Indexing candidates... [2.421s] [681 results]
2018-05-31 00:43:09,965 -> I.Getting expansions... [0.164s] [1951 results]
2018-05-31 00:43:10,100 -> J.Finding maximal disks... [0.135s] [225 results]
2018-05-31 00:43:11,932 -> K.Prunning duplicates and subsets... [1.832s] [222 results]
2018-05-31 00:43:11,932 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:43:11,932 ->   berlin0-10,   18546,  30.0,    28,  4,  31.93,    5758,     11516,          681,        222,  6
2018-05-31 00:43:12,392 -> Dropping indices...[0.460s]
2018-05-31 00:43:12,670 -> 1.Set of disks for t_i...                          |  32.69s |    222 disks
2018-05-31 00:43:21,455 -> 2.Distance Join phase...                           |   8.79s |    894 combinations
2018-05-31 00:43:27,780 -> 3.Getting candidates...                            |   6.33s |    252 candidates
2018-05-31 00:43:28,955 -> 4.Found flocks...                                  |   1.18s |    218 flocks
2018-05-31 00:43:34,794 -> 5.Updating times...                                |   1.63s |    252 flocks
2018-05-31 00:43:37,194 -> 6.Filter phase...                                  |   2.40s |    272 flocks
2018-05-31 00:43:42,217 -> Reporting locations...                             |   5.02s |  18546 points
2018-05-31 00:43:42,218 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=7,dataset=berlin0-10
2018-05-31 00:43:49,152 -> A.Indexing points... [6.917s] [18546 results]
2018-05-31 00:43:59,337 -> B.Getting pairs... [10.185s] [5788 results]
2018-05-31 00:44:00,568 -> C.Computing centers... [1.231s] [11576 results]
2018-05-31 00:44:01,474 -> D.Indexing centers... [0.906s] [11576 results]
2018-05-31 00:44:08,416 -> E.Getting disks... [6.942s] [11576 results]
2018-05-31 00:44:08,639 -> F.Filtering less-than-mu disks... [0.223s] [1361 results]
2018-05-31 00:44:10,678 -> G.Prunning duplicate candidates... [2.039s] [688 results]
2018-05-31 00:44:10,980 -> H.Indexing candidates... [2.341s] [688 results]
2018-05-31 00:44:11,147 -> I.Getting expansions... [0.167s] [1882 results]
2018-05-31 00:44:11,287 -> J.Finding maximal disks... [0.140s] [233 results]
2018-05-31 00:44:13,242 -> K.Prunning duplicates and subsets... [1.955s] [231 results]
2018-05-31 00:44:13,242 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:44:13,242 ->   berlin0-10,   18546,  30.0,    28,  4,  31.01,    5788,     11576,          688,        231,  7
2018-05-31 00:44:13,779 -> Dropping indices...[0.537s]
2018-05-31 00:44:14,045 -> 1.Set of disks for t_i...                          |  31.83s |    231 disks
2018-05-31 00:44:22,454 -> 2.Distance Join phase...                           |   8.41s |    934 combinations
2018-05-31 00:44:27,540 -> 3.Getting candidates...                            |   5.09s |    239 candidates
2018-05-31 00:44:28,772 -> 4.Found flocks...                                  |   1.23s |    216 flocks
2018-05-31 00:44:35,454 -> 5.Updating times...                                |   1.73s |    239 flocks
2018-05-31 00:44:38,175 -> 6.Filter phase...                                  |   2.72s |    270 flocks
2018-05-31 00:44:43,108 -> Reporting locations...                             |   4.93s |  18546 points
2018-05-31 00:44:43,109 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=8,dataset=berlin0-10
2018-05-31 00:44:47,850 -> A.Indexing points... [4.724s] [18546 results]
2018-05-31 00:44:54,480 -> B.Getting pairs... [6.630s] [5791 results]
2018-05-31 00:44:55,916 -> C.Computing centers... [1.436s] [11582 results]
2018-05-31 00:44:56,851 -> D.Indexing centers... [0.935s] [11582 results]
2018-05-31 00:45:02,038 -> E.Getting disks... [5.187s] [11582 results]
2018-05-31 00:45:02,253 -> F.Filtering less-than-mu disks... [0.215s] [1316 results]
2018-05-31 00:45:04,105 -> G.Prunning duplicate candidates... [1.852s] [670 results]
2018-05-31 00:45:04,434 -> H.Indexing candidates... [2.181s] [670 results]
2018-05-31 00:45:04,583 -> I.Getting expansions... [0.149s] [1792 results]
2018-05-31 00:45:04,730 -> J.Finding maximal disks... [0.147s] [220 results]
2018-05-31 00:45:06,062 -> K.Prunning duplicates and subsets... [1.332s] [219 results]
2018-05-31 00:45:06,062 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:45:06,063 ->   berlin0-10,   18546,  30.0,    28,  4,  22.94,    5791,     11582,          670,        219,  8
2018-05-31 00:45:06,667 -> Dropping indices...[0.604s]
2018-05-31 00:45:06,943 -> 1.Set of disks for t_i...                          |  23.83s |    219 disks
2018-05-31 00:45:16,449 -> 2.Distance Join phase...                           |   9.51s |    811 combinations
2018-05-31 00:45:21,746 -> 3.Getting candidates...                            |   5.30s |    226 candidates
2018-05-31 00:45:23,081 -> 4.Found flocks...                                  |   1.34s |    197 flocks
2018-05-31 00:45:30,465 -> 5.Updating times...                                |   1.76s |    226 flocks
2018-05-31 00:45:33,215 -> 6.Filter phase...                                  |   2.75s |    247 flocks
2018-05-31 00:45:38,127 -> Reporting locations...                             |   4.91s |  18546 points
2018-05-31 00:45:38,128 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=9,dataset=berlin0-10
2018-05-31 00:45:45,160 -> A.Indexing points... [6.999s] [18546 results]
2018-05-31 00:45:56,049 -> B.Getting pairs... [10.889s] [5802 results]
2018-05-31 00:45:57,423 -> C.Computing centers... [1.374s] [11604 results]
2018-05-31 00:45:58,307 -> D.Indexing centers... [0.883s] [11604 results]
2018-05-31 00:46:05,394 -> E.Getting disks... [7.087s] [11604 results]
2018-05-31 00:46:05,595 -> F.Filtering less-than-mu disks... [0.201s] [1306 results]
2018-05-31 00:46:08,244 -> G.Prunning duplicate candidates... [2.649s] [675 results]
2018-05-31 00:46:08,525 -> H.Indexing candidates... [2.930s] [675 results]
2018-05-31 00:46:08,680 -> I.Getting expansions... [0.155s] [1813 results]
2018-05-31 00:46:08,819 -> J.Finding maximal disks... [0.139s] [212 results]
2018-05-31 00:46:10,737 -> K.Prunning duplicates and subsets... [1.918s] [210 results]
2018-05-31 00:46:10,737 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:46:10,737 ->   berlin0-10,   18546,  30.0,    28,  4,  32.58,    5802,     11604,          675,        210,  9
2018-05-31 00:46:11,359 -> Dropping indices...[0.622s]
2018-05-31 00:46:11,664 -> 1.Set of disks for t_i...                          |  33.54s |    210 disks
2018-05-31 00:46:22,544 -> 2.Distance Join phase...                           |  10.88s |    637 combinations
2018-05-31 00:46:28,407 -> 3.Getting candidates...                            |   5.86s |    219 candidates
2018-05-31 00:46:30,113 -> 4.Found flocks...                                  |   1.71s |    199 flocks
2018-05-31 00:46:39,891 -> 5.Updating times...                                |   2.50s |    219 flocks
2018-05-31 00:46:43,662 -> 6.Filter phase...                                  |   3.77s |    239 flocks
2018-05-31 00:46:48,535 -> Reporting locations...                             |   4.87s |  18546 points
2018-05-31 00:46:48,535 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=10,dataset=berlin0-10
2018-05-31 00:46:56,061 -> A.Indexing points... [7.492s] [18546 results]
2018-05-31 00:47:06,779 -> B.Getting pairs... [10.718s] [5797 results]
2018-05-31 00:47:08,191 -> C.Computing centers... [1.412s] [11594 results]
2018-05-31 00:47:09,111 -> D.Indexing centers... [0.920s] [11594 results]
2018-05-31 00:47:16,058 -> E.Getting disks... [6.947s] [11594 results]
2018-05-31 00:47:16,291 -> F.Filtering less-than-mu disks... [0.233s] [1312 results]
2018-05-31 00:47:18,479 -> G.Prunning duplicate candidates... [2.188s] [675 results]
2018-05-31 00:47:18,805 -> H.Indexing candidates... [2.514s] [675 results]
2018-05-31 00:47:18,958 -> I.Getting expansions... [0.153s] [1804 results]
2018-05-31 00:47:19,088 -> J.Finding maximal disks... [0.130s] [212 results]
2018-05-31 00:47:20,994 -> K.Prunning duplicates and subsets... [1.906s] [211 results]
2018-05-31 00:47:20,994 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:47:20,995 ->   berlin0-10,   18546,  30.0,    28,  4,  32.43,    5797,     11594,          675,        211, 10
2018-05-31 00:47:21,810 -> Dropping indices...[0.815s]
2018-05-31 00:47:22,118 -> 1.Set of disks for t_i...                          |  33.58s |    211 disks
2018-05-31 00:47:33,767 -> 2.Distance Join phase...                           |  11.65s |    599 combinations
2018-05-31 00:47:40,133 -> 3.Getting candidates...                            |   6.37s |    213 candidates
2018-05-31 00:47:41,658 -> 4.Found flocks...                                  |   1.53s |    196 flocks
2018-05-31 00:47:51,204 -> 5.Updating times...                                |   2.18s |    213 flocks
2018-05-31 00:47:54,023 -> 6.Filter phase...                                  |   2.82s |    237 flocks
2018-05-31 00:47:54,023 -> 

PFLOCK_SJ	30.0	4	3	1868

2018-05-31 00:48:00,417 -> Running SpatialJoin...                             | 618.30s |   1868 flocks
2018-05-31 00:48:00,417 -> method=SpatialJoin,cores=28,epsilon=30.0,mu=4,delta=3,time=618.297,master=spark://169.235.27.134:7077
2018-05-31 00:48:00,417 -> Closing app...
acald013@dblab-rack15: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
FLOCKFINDER=SpatialJoin;TIME=Thu May 31 00:48:11 PDT 2018;RUN=1527752245;NODES=4;ESTART=;EEND=;ESTEP=;MU=4;DELTA=;SCRIPT=DeltaBenchmarker;EVENT=End
FLOCKFINDER=MergeLast;TIME=Thu May 31 00:48:11 PDT 2018;RUN=1527752891;NODES=4;ESTART=;EEND=;ESTEP=;MU=4;DELTA=;SCRIPT=DeltaBenchmarker;EVENT=Start
WARNING:root:Setting 4 nodes...
acald013@dblab-rack12: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack15: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack11: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack14: no org.apache.spark.deploy.worker.Worker to stop
no org.apache.spark.deploy.master.Master to stop
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack15: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack15.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
WARNING:root:4 nodes has been set...
2018-05-31 00:48:19,332 -> Starting app...
2018-05-31 00:48:22,284 -> Starting session                                   |   2.95s |      0 
2018-05-31 00:48:22,300 -> Setting paramaters                                 |   0.01s |      0 
2018-05-31 00:48:25,506 -> Reading data                                       |   3.21s | 203106 points
2018-05-31 00:48:28,869 -> Extracting timestamps                              |   3.36s |     11 timestamps
2018-05-31 00:48:28,876 -> === MergeLast Start ===
2018-05-31 00:48:34,212 -> Reporting locations at t=0...                      |   5.16s |  18093 points
2018-05-31 00:48:34,229 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=0,dataset=berlin0-10
2018-05-31 00:48:42,572 -> A.Indexing points... [8.291s] [18093 results]
2018-05-31 00:48:49,986 -> B.Getting pairs... [7.414s] [5511 results]
2018-05-31 00:48:52,133 -> C.Computing centers... [2.146s] [11022 results]
2018-05-31 00:48:54,155 -> D.Indexing centers... [2.022s] [11022 results]
2018-05-31 00:48:59,603 -> E.Getting disks... [5.447s] [11022 results]
2018-05-31 00:48:59,972 -> F.Filtering less-than-mu disks... [0.369s] [1210 results]
2018-05-31 00:49:02,532 -> G.Prunning duplicate candidates... [2.560s] [599 results]
2018-05-31 00:49:03,046 -> H.Indexing candidates... [3.074s] [599 results]
2018-05-31 00:49:03,253 -> I.Getting expansions... [0.207s] [1657 results]
2018-05-31 00:49:03,690 -> J.Finding maximal disks... [0.437s] [206 results]
2018-05-31 00:49:05,517 -> K.Prunning duplicates and subsets... [1.827s] [205 results]
2018-05-31 00:49:05,518 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:49:05,518 ->   berlin0-10,   18093,  30.0,    28,  4,  31.24,    5511,     11022,          599,        205,  0
2018-05-31 00:49:05,590 -> Dropping indices...[0.072s]
2018-05-31 00:49:05,856 -> 1.Set of disks for t_i...                          |  31.64s |    205 disks
2018-05-31 00:49:11,148 -> Reporting locations at t=2...                      |   5.29s |  18394 points
2018-05-31 00:49:11,149 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=2,dataset=berlin0-10
2018-05-31 00:49:16,157 -> A.Indexing points... [4.984s] [18394 results]
2018-05-31 00:49:21,487 -> B.Getting pairs... [5.329s] [5701 results]
2018-05-31 00:49:22,901 -> C.Computing centers... [1.414s] [11402 results]
2018-05-31 00:49:23,863 -> D.Indexing centers... [0.962s] [11402 results]
2018-05-31 00:49:28,728 -> E.Getting disks... [4.865s] [11402 results]
2018-05-31 00:49:29,007 -> F.Filtering less-than-mu disks... [0.278s] [1336 results]
2018-05-31 00:49:30,994 -> G.Prunning duplicate candidates... [1.987s] [658 results]
2018-05-31 00:49:31,348 -> H.Indexing candidates... [2.341s] [658 results]
2018-05-31 00:49:31,536 -> I.Getting expansions... [0.188s] [1757 results]
2018-05-31 00:49:31,690 -> J.Finding maximal disks... [0.154s] [232 results]
2018-05-31 00:49:32,863 -> K.Prunning duplicates and subsets... [1.173s] [227 results]
2018-05-31 00:49:32,863 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:49:32,864 ->   berlin0-10,   18394,  30.0,    28,  4,  21.69,    5701,     11402,          658,        227,  2
2018-05-31 00:49:32,932 -> Dropping indices...[0.068s]
2018-05-31 00:49:33,189 -> 2.Set of disks for t_i+delta...                    |  22.04s |    205 disks
2018-05-31 00:49:42,207 -> 3.Joining timestams                                |   9.02s |    332 candidates
2018-05-31 00:49:54,351 -> Checking internal timestamps                       |  12.14s |    199 flocks
2018-05-31 00:49:59,945 -> Reporting locations at t=1...                      |   5.21s |  18245 points
2018-05-31 00:49:59,945 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=1,dataset=berlin0-10
2018-05-31 00:50:04,301 -> A.Indexing points... [4.336s] [18245 results]
2018-05-31 00:50:09,289 -> B.Getting pairs... [4.987s] [5629 results]
2018-05-31 00:50:10,663 -> C.Computing centers... [1.374s] [11258 results]
2018-05-31 00:50:11,640 -> D.Indexing centers... [0.977s] [11258 results]
2018-05-31 00:50:16,245 -> E.Getting disks... [4.605s] [11258 results]
2018-05-31 00:50:16,517 -> F.Filtering less-than-mu disks... [0.272s] [1299 results]
2018-05-31 00:50:18,121 -> G.Prunning duplicate candidates... [1.603s] [640 results]
2018-05-31 00:50:18,469 -> H.Indexing candidates... [1.951s] [640 results]
2018-05-31 00:50:18,639 -> I.Getting expansions... [0.170s] [1703 results]
2018-05-31 00:50:18,797 -> J.Finding maximal disks... [0.157s] [220 results]
2018-05-31 00:50:20,092 -> K.Prunning duplicates and subsets... [1.295s] [216 results]
2018-05-31 00:50:20,092 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:50:20,092 ->   berlin0-10,   18245,  30.0,    28,  4,  20.13,    5629,     11258,          640,        216,  1
2018-05-31 00:50:20,179 -> Dropping indices...[0.087s]
2018-05-31 00:50:20,400 -> 1.Set of disks for t_i...                          |  20.46s |    216 disks
2018-05-31 00:50:25,509 -> Reporting locations at t=3...                      |   5.11s |  18548 points
2018-05-31 00:50:25,509 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=3,dataset=berlin0-10
2018-05-31 00:50:32,727 -> A.Indexing points... [7.193s] [18548 results]
2018-05-31 00:50:43,134 -> B.Getting pairs... [10.406s] [5768 results]
2018-05-31 00:50:44,482 -> C.Computing centers... [1.347s] [11536 results]
2018-05-31 00:50:45,451 -> D.Indexing centers... [0.969s] [11536 results]
2018-05-31 00:50:52,692 -> E.Getting disks... [7.241s] [11536 results]
2018-05-31 00:50:52,931 -> F.Filtering less-than-mu disks... [0.239s] [1349 results]
2018-05-31 00:50:55,743 -> G.Prunning duplicate candidates... [2.812s] [675 results]
2018-05-31 00:50:56,078 -> H.Indexing candidates... [3.147s] [675 results]
2018-05-31 00:50:56,251 -> I.Getting expansions... [0.173s] [1875 results]
2018-05-31 00:50:56,693 -> J.Finding maximal disks... [0.442s] [230 results]
2018-05-31 00:50:58,688 -> K.Prunning duplicates and subsets... [1.995s] [225 results]
2018-05-31 00:50:58,688 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:50:58,688 ->   berlin0-10,   18548,  30.0,    28,  4,  33.15,    5768,     11536,          675,        225,  3
2018-05-31 00:50:58,804 -> Dropping indices...[0.116s]
2018-05-31 00:50:59,024 -> 2.Set of disks for t_i+delta...                    |  33.52s |    216 disks
2018-05-31 00:51:06,928 -> 3.Joining timestams                                |   7.90s |    333 candidates
2018-05-31 00:51:16,604 -> Checking internal timestamps                       |   9.68s |    210 flocks
2018-05-31 00:51:22,438 -> Reporting locations at t=2...                      |   5.16s |  18394 points
2018-05-31 00:51:22,685 -> 1.Set of disks for t_i...                          |   0.25s |    227 disks
2018-05-31 00:51:27,747 -> Reporting locations at t=4...                      |   5.06s |  18548 points
2018-05-31 00:51:27,748 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=4,dataset=berlin0-10
2018-05-31 00:51:34,854 -> A.Indexing points... [7.084s] [18548 results]
2018-05-31 00:51:45,057 -> B.Getting pairs... [10.202s] [5775 results]
2018-05-31 00:51:46,303 -> C.Computing centers... [1.246s] [11550 results]
2018-05-31 00:51:47,380 -> D.Indexing centers... [1.077s] [11550 results]
2018-05-31 00:51:54,119 -> E.Getting disks... [6.739s] [11550 results]
2018-05-31 00:51:54,326 -> F.Filtering less-than-mu disks... [0.207s] [1369 results]
2018-05-31 00:51:56,302 -> G.Prunning duplicate candidates... [1.976s] [694 results]
2018-05-31 00:51:56,638 -> H.Indexing candidates... [2.312s] [694 results]
2018-05-31 00:51:56,817 -> I.Getting expansions... [0.179s] [1914 results]
2018-05-31 00:51:56,960 -> J.Finding maximal disks... [0.143s] [245 results]
2018-05-31 00:51:59,042 -> K.Prunning duplicates and subsets... [2.081s] [238 results]
2018-05-31 00:51:59,042 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:51:59,042 ->   berlin0-10,   18548,  30.0,    28,  4,  31.27,    5775,     11550,          694,        238,  4
2018-05-31 00:51:59,197 -> Dropping indices...[0.155s]
2018-05-31 00:51:59,413 -> 2.Set of disks for t_i+delta...                    |  31.67s |    227 disks
2018-05-31 00:52:06,920 -> 3.Joining timestams                                |   7.51s |    360 candidates
2018-05-31 00:52:16,777 -> Checking internal timestamps                       |   9.86s |    220 flocks
2018-05-31 00:52:22,785 -> Reporting locations at t=3...                      |   5.15s |  18548 points
2018-05-31 00:52:23,036 -> 1.Set of disks for t_i...                          |   0.25s |    225 disks
2018-05-31 00:52:28,138 -> Reporting locations at t=5...                      |   5.10s |  18548 points
2018-05-31 00:52:28,138 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=5,dataset=berlin0-10
2018-05-31 00:52:35,305 -> A.Indexing points... [7.146s] [18548 results]
2018-05-31 00:52:45,510 -> B.Getting pairs... [10.205s] [5765 results]
2018-05-31 00:52:46,792 -> C.Computing centers... [1.282s] [11530 results]
2018-05-31 00:52:47,731 -> D.Indexing centers... [0.939s] [11530 results]
2018-05-31 00:52:54,670 -> E.Getting disks... [6.939s] [11530 results]
2018-05-31 00:52:54,875 -> F.Filtering less-than-mu disks... [0.205s] [1362 results]
2018-05-31 00:52:56,830 -> G.Prunning duplicate candidates... [1.955s] [686 results]
2018-05-31 00:52:57,199 -> H.Indexing candidates... [2.324s] [686 results]
2018-05-31 00:52:57,356 -> I.Getting expansions... [0.157s] [1917 results]
2018-05-31 00:52:57,492 -> J.Finding maximal disks... [0.136s] [237 results]
2018-05-31 00:52:59,411 -> K.Prunning duplicates and subsets... [1.919s] [234 results]
2018-05-31 00:52:59,411 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:52:59,411 ->   berlin0-10,   18548,  30.0,    28,  4,  31.25,    5765,     11530,          686,        234,  5
2018-05-31 00:52:59,603 -> Dropping indices...[0.192s]
2018-05-31 00:52:59,840 -> 2.Set of disks for t_i+delta...                    |  31.70s |    225 disks
2018-05-31 00:53:07,304 -> 3.Joining timestams                                |   7.46s |    327 candidates
2018-05-31 00:53:17,004 -> Checking internal timestamps                       |   9.70s |    213 flocks
2018-05-31 00:53:23,302 -> Reporting locations at t=4...                      |   5.17s |  18548 points
2018-05-31 00:53:23,558 -> 1.Set of disks for t_i...                          |   0.26s |    238 disks
2018-05-31 00:53:28,781 -> Reporting locations at t=6...                      |   5.22s |  18546 points
2018-05-31 00:53:28,781 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=6,dataset=berlin0-10
2018-05-31 00:53:35,868 -> A.Indexing points... [7.066s] [18546 results]
2018-05-31 00:53:46,212 -> B.Getting pairs... [10.343s] [5758 results]
2018-05-31 00:53:47,465 -> C.Computing centers... [1.253s] [11516 results]
2018-05-31 00:53:48,364 -> D.Indexing centers... [0.899s] [11516 results]
2018-05-31 00:53:55,393 -> E.Getting disks... [7.029s] [11516 results]
2018-05-31 00:53:55,593 -> F.Filtering less-than-mu disks... [0.200s] [1346 results]
2018-05-31 00:53:57,836 -> G.Prunning duplicate candidates... [2.243s] [681 results]
2018-05-31 00:53:58,232 -> H.Indexing candidates... [2.639s] [681 results]
2018-05-31 00:53:58,402 -> I.Getting expansions... [0.170s] [1951 results]
2018-05-31 00:53:58,540 -> J.Finding maximal disks... [0.138s] [225 results]
2018-05-31 00:54:00,473 -> K.Prunning duplicates and subsets... [1.933s] [222 results]
2018-05-31 00:54:00,473 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:54:00,473 ->   berlin0-10,   18546,  30.0,    28,  4,  31.67,    5758,     11516,          681,        222,  6
2018-05-31 00:54:00,711 -> Dropping indices...[0.238s]
2018-05-31 00:54:01,025 -> 2.Set of disks for t_i+delta...                    |  32.24s |    238 disks
2018-05-31 00:54:08,329 -> 3.Joining timestams                                |   7.30s |    324 candidates
2018-05-31 00:54:18,221 -> Checking internal timestamps                       |   9.89s |    218 flocks
2018-05-31 00:54:24,690 -> Reporting locations at t=5...                      |   5.17s |  18548 points
2018-05-31 00:54:24,960 -> 1.Set of disks for t_i...                          |   0.27s |    234 disks
2018-05-31 00:54:30,085 -> Reporting locations at t=7...                      |   5.13s |  18546 points
2018-05-31 00:54:30,085 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=7,dataset=berlin0-10
2018-05-31 00:54:37,175 -> A.Indexing points... [7.070s] [18546 results]
2018-05-31 00:54:47,542 -> B.Getting pairs... [10.367s] [5788 results]
2018-05-31 00:54:48,792 -> C.Computing centers... [1.250s] [11576 results]
2018-05-31 00:54:49,744 -> D.Indexing centers... [0.952s] [11576 results]
2018-05-31 00:54:56,911 -> E.Getting disks... [7.167s] [11576 results]
2018-05-31 00:54:57,144 -> F.Filtering less-than-mu disks... [0.233s] [1361 results]
2018-05-31 00:54:59,216 -> G.Prunning duplicate candidates... [2.072s] [688 results]
2018-05-31 00:54:59,564 -> H.Indexing candidates... [2.420s] [688 results]
2018-05-31 00:54:59,781 -> I.Getting expansions... [0.217s] [1882 results]
2018-05-31 00:54:59,930 -> J.Finding maximal disks... [0.149s] [233 results]
2018-05-31 00:55:01,999 -> K.Prunning duplicates and subsets... [2.069s] [231 results]
2018-05-31 00:55:01,999 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:55:01,999 ->   berlin0-10,   18546,  30.0,    28,  4,  31.89,    5788,     11576,          688,        231,  7
2018-05-31 00:55:02,221 -> Dropping indices...[0.221s]
2018-05-31 00:55:02,441 -> 2.Set of disks for t_i+delta...                    |  32.36s |    234 disks
2018-05-31 00:55:09,803 -> 3.Joining timestams                                |   7.36s |    320 candidates
2018-05-31 00:55:19,490 -> Checking internal timestamps                       |   9.69s |    216 flocks
2018-05-31 00:55:25,998 -> Reporting locations at t=6...                      |   5.14s |  18546 points
2018-05-31 00:55:26,344 -> 1.Set of disks for t_i...                          |   0.35s |    222 disks
2018-05-31 00:55:31,387 -> Reporting locations at t=8...                      |   5.04s |  18546 points
2018-05-31 00:55:31,388 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=8,dataset=berlin0-10
2018-05-31 00:55:35,757 -> A.Indexing points... [4.349s] [18546 results]
2018-05-31 00:55:41,766 -> B.Getting pairs... [6.009s] [5791 results]
2018-05-31 00:55:43,053 -> C.Computing centers... [1.287s] [11582 results]
2018-05-31 00:55:44,163 -> D.Indexing centers... [1.110s] [11582 results]
2018-05-31 00:55:48,994 -> E.Getting disks... [4.831s] [11582 results]
2018-05-31 00:55:49,205 -> F.Filtering less-than-mu disks... [0.211s] [1316 results]
2018-05-31 00:55:51,078 -> G.Prunning duplicate candidates... [1.873s] [670 results]
2018-05-31 00:55:51,484 -> H.Indexing candidates... [2.279s] [670 results]
2018-05-31 00:55:51,644 -> I.Getting expansions... [0.160s] [1792 results]
2018-05-31 00:55:51,773 -> J.Finding maximal disks... [0.129s] [220 results]
2018-05-31 00:55:53,301 -> K.Prunning duplicates and subsets... [1.528s] [219 results]
2018-05-31 00:55:53,301 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:55:53,301 ->   berlin0-10,   18546,  30.0,    28,  4,  21.89,    5791,     11582,          670,        219,  8
2018-05-31 00:55:53,627 -> Dropping indices...[0.325s]
2018-05-31 00:55:53,874 -> 2.Set of disks for t_i+delta...                    |  22.49s |    222 disks
2018-05-31 00:56:00,894 -> 3.Joining timestams                                |   7.02s |    283 candidates
2018-05-31 00:56:10,750 -> Checking internal timestamps                       |   9.86s |    197 flocks
2018-05-31 00:56:17,749 -> Reporting locations at t=7...                      |   5.39s |  18546 points
2018-05-31 00:56:18,011 -> 1.Set of disks for t_i...                          |   0.26s |    231 disks
2018-05-31 00:56:23,225 -> Reporting locations at t=9...                      |   5.21s |  18546 points
2018-05-31 00:56:23,225 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=9,dataset=berlin0-10
2018-05-31 00:56:30,699 -> A.Indexing points... [7.432s] [18546 results]
2018-05-31 00:56:41,619 -> B.Getting pairs... [10.920s] [5802 results]
2018-05-31 00:56:42,916 -> C.Computing centers... [1.297s] [11604 results]
2018-05-31 00:56:43,889 -> D.Indexing centers... [0.973s] [11604 results]
2018-05-31 00:56:51,910 -> E.Getting disks... [8.021s] [11604 results]
2018-05-31 00:56:52,127 -> F.Filtering less-than-mu disks... [0.216s] [1306 results]
2018-05-31 00:56:54,401 -> G.Prunning duplicate candidates... [2.274s] [675 results]
2018-05-31 00:56:54,730 -> H.Indexing candidates... [2.603s] [675 results]
2018-05-31 00:56:54,875 -> I.Getting expansions... [0.145s] [1813 results]
2018-05-31 00:56:55,003 -> J.Finding maximal disks... [0.128s] [212 results]
2018-05-31 00:56:57,016 -> K.Prunning duplicates and subsets... [2.013s] [210 results]
2018-05-31 00:56:57,016 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:56:57,016 ->   berlin0-10,   18546,  30.0,    28,  4,  33.75,    5802,     11604,          675,        210,  9
2018-05-31 00:56:57,294 -> Dropping indices...[0.278s]
2018-05-31 00:56:57,566 -> 2.Set of disks for t_i+delta...                    |  34.34s |    231 disks
2018-05-31 00:57:05,534 -> 3.Joining timestams                                |   7.97s |    277 candidates
2018-05-31 00:57:15,273 -> Checking internal timestamps                       |   9.74s |    199 flocks
2018-05-31 00:57:22,483 -> Reporting locations at t=8...                      |   5.25s |  18546 points
2018-05-31 00:57:22,735 -> 1.Set of disks for t_i...                          |   0.25s |    219 disks
2018-05-31 00:57:27,886 -> Reporting locations at t=10...                     |   5.15s |  18546 points
2018-05-31 00:57:27,887 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=10,dataset=berlin0-10
2018-05-31 00:57:35,094 -> A.Indexing points... [7.170s] [18546 results]
2018-05-31 00:57:45,987 -> B.Getting pairs... [10.892s] [5797 results]
2018-05-31 00:57:47,276 -> C.Computing centers... [1.289s] [11594 results]
2018-05-31 00:57:48,257 -> D.Indexing centers... [0.981s] [11594 results]
2018-05-31 00:57:55,536 -> E.Getting disks... [7.279s] [11594 results]
2018-05-31 00:57:55,766 -> F.Filtering less-than-mu disks... [0.230s] [1312 results]
2018-05-31 00:57:58,067 -> G.Prunning duplicate candidates... [2.301s] [675 results]
2018-05-31 00:57:58,392 -> H.Indexing candidates... [2.626s] [675 results]
2018-05-31 00:57:58,641 -> I.Getting expansions... [0.249s] [1804 results]
2018-05-31 00:57:58,781 -> J.Finding maximal disks... [0.140s] [212 results]
2018-05-31 00:58:00,824 -> K.Prunning duplicates and subsets... [2.043s] [211 results]
2018-05-31 00:58:00,824 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:58:00,824 ->   berlin0-10,   18546,  30.0,    28,  4,  32.90,    5797,     11594,          675,        211, 10
2018-05-31 00:58:01,212 -> Dropping indices...[0.388s]
2018-05-31 00:58:01,495 -> 2.Set of disks for t_i+delta...                    |  33.61s |    219 disks
2018-05-31 00:58:08,435 -> 3.Joining timestams                                |   6.94s |    277 candidates
2018-05-31 00:58:18,050 -> Checking internal timestamps                       |   9.62s |    196 flocks
2018-05-31 00:58:20,081 -> 

PFLOCK_ML	30.0	4	3	1868

2018-05-31 00:58:22,001 -> Running MergeLast...                               | 593.13s |   1868 flocks
2018-05-31 00:58:22,001 -> method=MergeLast,cores=28,epsilon=30.0,mu=4,delta=3,time=593.125,master=spark://169.235.27.134:7077
2018-05-31 00:58:22,001 -> Closing app...
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack15: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
FLOCKFINDER=MergeLast;TIME=Thu May 31 00:58:29 PDT 2018;RUN=1527752891;NODES=4;ESTART=;EEND=;ESTEP=;MU=4;DELTA=;SCRIPT=DeltaBenchmarker;EVENT=End
FLOCKFINDER=SpatialJoin;TIME=Thu May 31 00:58:29 PDT 2018;RUN=1527753509;NODES=4;ESTART=;EEND=;ESTEP=;MU=4;DELTA=;SCRIPT=DeltaBenchmarker;EVENT=Start
WARNING:root:Setting 4 nodes...
acald013@dblab-rack12: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack15: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack11: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack14: no org.apache.spark.deploy.worker.Worker to stop
no org.apache.spark.deploy.master.Master to stop
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack15: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack15.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
WARNING:root:4 nodes has been set...
2018-05-31 00:58:36,387 -> Starting app...
2018-05-31 00:58:39,242 -> Starting session                                   |   2.86s |      0 
2018-05-31 00:58:39,259 -> Setting paramaters                                 |   0.02s |      0 
2018-05-31 00:58:42,295 -> Reading data                                       |   3.04s | 203106 points
2018-05-31 00:58:45,706 -> Extracting timestamps                              |   3.41s |     11 timestamps
2018-05-31 00:58:45,711 -> === SpatialJoin Start ===
2018-05-31 00:58:51,206 -> Reporting locations...                             |   5.32s |  18093 points
2018-05-31 00:58:51,220 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=0,dataset=berlin0-10
2018-05-31 00:58:59,579 -> A.Indexing points... [8.312s] [18093 results]
2018-05-31 00:59:06,842 -> B.Getting pairs... [7.263s] [5511 results]
2018-05-31 00:59:09,096 -> C.Computing centers... [2.254s] [11022 results]
2018-05-31 00:59:10,511 -> D.Indexing centers... [1.414s] [11022 results]
2018-05-31 00:59:15,808 -> E.Getting disks... [5.297s] [11022 results]
2018-05-31 00:59:16,202 -> F.Filtering less-than-mu disks... [0.394s] [1210 results]
2018-05-31 00:59:18,588 -> G.Prunning duplicate candidates... [2.385s] [599 results]
2018-05-31 00:59:19,071 -> H.Indexing candidates... [2.868s] [599 results]
2018-05-31 00:59:19,416 -> I.Getting expansions... [0.345s] [1657 results]
2018-05-31 00:59:19,974 -> J.Finding maximal disks... [0.557s] [206 results]
2018-05-31 00:59:21,684 -> K.Prunning duplicates and subsets... [1.710s] [205 results]
2018-05-31 00:59:21,684 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:59:21,684 ->   berlin0-10,   18093,  30.0,    28,  4,  30.42,    5511,     11022,          599,        205,  0
2018-05-31 00:59:21,750 -> Dropping indices...[0.065s]
2018-05-31 00:59:22,054 -> 1.Set of disks for t_i...                          |  30.85s |    205 disks
2018-05-31 00:59:22,448 -> 4.Found flocks...                                  |   0.39s |      0 flocks
2018-05-31 00:59:23,317 -> 5.Updating times...                                |   0.56s |    205 flocks
2018-05-31 00:59:24,444 -> 6.Filter phase...                                  |   1.13s |    205 flocks
2018-05-31 00:59:29,135 -> Reporting locations...                             |   4.69s |  18245 points
2018-05-31 00:59:29,135 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=1,dataset=berlin0-10
2018-05-31 00:59:33,439 -> A.Indexing points... [4.285s] [18245 results]
2018-05-31 00:59:38,411 -> B.Getting pairs... [4.972s] [5629 results]
2018-05-31 00:59:39,806 -> C.Computing centers... [1.395s] [11258 results]
2018-05-31 00:59:40,885 -> D.Indexing centers... [1.079s] [11258 results]
2018-05-31 00:59:45,588 -> E.Getting disks... [4.703s] [11258 results]
2018-05-31 00:59:45,828 -> F.Filtering less-than-mu disks... [0.240s] [1299 results]
2018-05-31 00:59:47,211 -> G.Prunning duplicate candidates... [1.383s] [640 results]
2018-05-31 00:59:47,521 -> H.Indexing candidates... [1.693s] [640 results]
2018-05-31 00:59:47,673 -> I.Getting expansions... [0.152s] [1703 results]
2018-05-31 00:59:47,868 -> J.Finding maximal disks... [0.195s] [220 results]
2018-05-31 00:59:49,253 -> K.Prunning duplicates and subsets... [1.385s] [216 results]
2018-05-31 00:59:49,253 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 00:59:49,253 ->   berlin0-10,   18245,  30.0,    28,  4,  20.10,    5629,     11258,          640,        216,  1
2018-05-31 00:59:49,345 -> Dropping indices...[0.092s]
2018-05-31 00:59:49,640 -> 1.Set of disks for t_i...                          |  20.51s |    216 disks
2018-05-31 00:59:53,082 -> 2.Distance Join phase...                           |   3.44s |    486 combinations
2018-05-31 00:59:56,082 -> 3.Getting candidates...                            |   3.00s |    196 candidates
2018-05-31 00:59:56,797 -> 4.Found flocks...                                  |   0.72s |    196 flocks
2018-05-31 00:59:59,027 -> 5.Updating times...                                |   1.37s |    196 flocks
2018-05-31 01:00:01,437 -> 6.Filter phase...                                  |   2.41s |    236 flocks
2018-05-31 01:00:06,022 -> Reporting locations...                             |   4.59s |  18394 points
2018-05-31 01:00:06,022 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=2,dataset=berlin0-10
2018-05-31 01:00:10,050 -> A.Indexing points... [4.009s] [18394 results]
2018-05-31 01:00:14,677 -> B.Getting pairs... [4.626s] [5701 results]
2018-05-31 01:00:15,981 -> C.Computing centers... [1.304s] [11402 results]
2018-05-31 01:00:16,866 -> D.Indexing centers... [0.885s] [11402 results]
2018-05-31 01:00:21,342 -> E.Getting disks... [4.476s] [11402 results]
2018-05-31 01:00:21,592 -> F.Filtering less-than-mu disks... [0.250s] [1336 results]
2018-05-31 01:00:22,873 -> G.Prunning duplicate candidates... [1.280s] [658 results]
2018-05-31 01:00:23,194 -> H.Indexing candidates... [1.601s] [658 results]
2018-05-31 01:00:23,351 -> I.Getting expansions... [0.157s] [1757 results]
2018-05-31 01:00:23,504 -> J.Finding maximal disks... [0.152s] [232 results]
2018-05-31 01:00:24,666 -> K.Prunning duplicates and subsets... [1.162s] [227 results]
2018-05-31 01:00:24,666 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:00:24,666 ->   berlin0-10,   18394,  30.0,    28,  4,  18.63,    5701,     11402,          658,        227,  2
2018-05-31 01:00:24,830 -> Dropping indices...[0.164s]
2018-05-31 01:00:25,066 -> 1.Set of disks for t_i...                          |  19.04s |    227 disks
2018-05-31 01:00:31,832 -> 2.Distance Join phase...                           |   6.77s |    648 combinations
2018-05-31 01:00:36,295 -> 3.Getting candidates...                            |   4.46s |    218 candidates
2018-05-31 01:00:36,974 -> 4.Found flocks...                                  |   0.68s |    218 flocks
2018-05-31 01:00:39,552 -> 5.Updating times...                                |   1.13s |    218 flocks
2018-05-31 01:00:41,512 -> 6.Filter phase...                                  |   1.96s |    248 flocks
2018-05-31 01:00:46,369 -> Reporting locations...                             |   4.86s |  18548 points
2018-05-31 01:00:46,371 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=3,dataset=berlin0-10
2018-05-31 01:00:54,025 -> A.Indexing points... [7.640s] [18548 results]
2018-05-31 01:01:05,250 -> B.Getting pairs... [11.225s] [5768 results]
2018-05-31 01:01:06,555 -> C.Computing centers... [1.305s] [11536 results]
2018-05-31 01:01:07,457 -> D.Indexing centers... [0.902s] [11536 results]
2018-05-31 01:01:14,472 -> E.Getting disks... [7.015s] [11536 results]
2018-05-31 01:01:14,692 -> F.Filtering less-than-mu disks... [0.220s] [1349 results]
2018-05-31 01:01:16,840 -> G.Prunning duplicate candidates... [2.148s] [675 results]
2018-05-31 01:01:17,174 -> H.Indexing candidates... [2.482s] [675 results]
2018-05-31 01:01:17,323 -> I.Getting expansions... [0.149s] [1875 results]
2018-05-31 01:01:17,471 -> J.Finding maximal disks... [0.148s] [230 results]
2018-05-31 01:01:19,608 -> K.Prunning duplicates and subsets... [2.137s] [225 results]
2018-05-31 01:01:19,608 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:01:19,609 ->   berlin0-10,   18548,  30.0,    28,  4,  33.22,    5768,     11536,          675,        225,  3
2018-05-31 01:01:19,820 -> Dropping indices...[0.211s]
2018-05-31 01:01:20,059 -> 1.Set of disks for t_i...                          |  33.69s |    225 disks
2018-05-31 01:01:26,303 -> 2.Distance Join phase...                           |   6.24s |    671 combinations
2018-05-31 01:01:30,205 -> 3.Getting candidates...                            |   3.90s |    220 candidates
2018-05-31 01:01:31,001 -> 4.Found flocks...                                  |   0.80s |    220 flocks
2018-05-31 01:01:34,200 -> 5.Updating times...                                |   1.22s |    220 flocks
2018-05-31 01:01:36,255 -> 6.Filter phase...                                  |   2.06s |    250 flocks
2018-05-31 01:01:40,830 -> Reporting locations...                             |   4.58s |  18548 points
2018-05-31 01:01:40,831 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=4,dataset=berlin0-10
2018-05-31 01:01:48,175 -> A.Indexing points... [7.327s] [18548 results]
2018-05-31 01:01:58,995 -> B.Getting pairs... [10.820s] [5775 results]
2018-05-31 01:02:00,265 -> C.Computing centers... [1.270s] [11550 results]
2018-05-31 01:02:01,278 -> D.Indexing centers... [1.013s] [11550 results]
2018-05-31 01:02:08,060 -> E.Getting disks... [6.782s] [11550 results]
2018-05-31 01:02:08,273 -> F.Filtering less-than-mu disks... [0.213s] [1369 results]
2018-05-31 01:02:10,707 -> G.Prunning duplicate candidates... [2.433s] [694 results]
2018-05-31 01:02:10,989 -> H.Indexing candidates... [2.715s] [694 results]
2018-05-31 01:02:11,146 -> I.Getting expansions... [0.157s] [1914 results]
2018-05-31 01:02:11,305 -> J.Finding maximal disks... [0.159s] [245 results]
2018-05-31 01:02:13,128 -> K.Prunning duplicates and subsets... [1.823s] [238 results]
2018-05-31 01:02:13,128 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:02:13,128 ->   berlin0-10,   18548,  30.0,    28,  4,  32.28,    5775,     11550,          694,        238,  4
2018-05-31 01:02:13,405 -> Dropping indices...[0.276s]
2018-05-31 01:02:13,683 -> 1.Set of disks for t_i...                          |  32.85s |    238 disks
2018-05-31 01:02:20,738 -> 2.Distance Join phase...                           |   7.06s |    701 combinations
2018-05-31 01:02:25,018 -> 3.Getting candidates...                            |   4.28s |    224 candidates
2018-05-31 01:02:25,949 -> 4.Found flocks...                                  |   0.93s |    224 flocks
2018-05-31 01:02:29,971 -> 5.Updating times...                                |   1.38s |    224 flocks
2018-05-31 01:02:32,220 -> 6.Filter phase...                                  |   2.25s |    249 flocks
2018-05-31 01:02:36,775 -> Reporting locations...                             |   4.56s |  18548 points
2018-05-31 01:02:36,776 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=5,dataset=berlin0-10
2018-05-31 01:02:44,304 -> A.Indexing points... [7.513s] [18548 results]
2018-05-31 01:02:54,909 -> B.Getting pairs... [10.605s] [5765 results]
2018-05-31 01:02:56,174 -> C.Computing centers... [1.265s] [11530 results]
2018-05-31 01:02:57,059 -> D.Indexing centers... [0.885s] [11530 results]
2018-05-31 01:03:04,084 -> E.Getting disks... [7.007s] [11530 results]
2018-05-31 01:03:04,305 -> F.Filtering less-than-mu disks... [0.220s] [1362 results]
2018-05-31 01:03:06,741 -> G.Prunning duplicate candidates... [2.436s] [686 results]
2018-05-31 01:03:07,113 -> H.Indexing candidates... [2.808s] [686 results]
2018-05-31 01:03:07,280 -> I.Getting expansions... [0.167s] [1917 results]
2018-05-31 01:03:07,427 -> J.Finding maximal disks... [0.147s] [237 results]
2018-05-31 01:03:09,253 -> K.Prunning duplicates and subsets... [1.826s] [234 results]
2018-05-31 01:03:09,253 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:03:09,253 ->   berlin0-10,   18548,  30.0,    28,  4,  32.46,    5765,     11530,          686,        234,  5
2018-05-31 01:03:09,571 -> Dropping indices...[0.318s]
2018-05-31 01:03:09,873 -> 1.Set of disks for t_i...                          |  33.10s |    234 disks
2018-05-31 01:03:18,063 -> 2.Distance Join phase...                           |   8.19s |    630 combinations
2018-05-31 01:03:22,698 -> 3.Getting candidates...                            |   4.64s |    230 candidates
2018-05-31 01:03:23,708 -> 4.Found flocks...                                  |   1.01s |    230 flocks
2018-05-31 01:03:28,466 -> 5.Updating times...                                |   1.57s |    230 flocks
2018-05-31 01:03:30,677 -> 6.Filter phase...                                  |   2.21s |    259 flocks
2018-05-31 01:03:35,221 -> Reporting locations...                             |   4.54s |  18546 points
2018-05-31 01:03:35,222 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=6,dataset=berlin0-10
2018-05-31 01:03:43,140 -> A.Indexing points... [7.901s] [18546 results]
2018-05-31 01:03:53,739 -> B.Getting pairs... [10.599s] [5758 results]
2018-05-31 01:03:55,105 -> C.Computing centers... [1.366s] [11516 results]
2018-05-31 01:03:56,026 -> D.Indexing centers... [0.921s] [11516 results]
2018-05-31 01:04:03,025 -> E.Getting disks... [6.999s] [11516 results]
2018-05-31 01:04:03,225 -> F.Filtering less-than-mu disks... [0.200s] [1346 results]
2018-05-31 01:04:05,165 -> G.Prunning duplicate candidates... [1.940s] [681 results]
2018-05-31 01:04:05,477 -> H.Indexing candidates... [2.252s] [681 results]
2018-05-31 01:04:05,665 -> I.Getting expansions... [0.188s] [1951 results]
2018-05-31 01:04:05,823 -> J.Finding maximal disks... [0.158s] [225 results]
2018-05-31 01:04:07,653 -> K.Prunning duplicates and subsets... [1.830s] [222 results]
2018-05-31 01:04:07,653 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:04:07,653 ->   berlin0-10,   18546,  30.0,    28,  4,  32.41,    5758,     11516,          681,        222,  6
2018-05-31 01:04:08,041 -> Dropping indices...[0.388s]
2018-05-31 01:04:08,276 -> 1.Set of disks for t_i...                          |  33.05s |    222 disks
2018-05-31 01:04:16,711 -> 2.Distance Join phase...                           |   8.44s |    619 combinations
2018-05-31 01:04:21,257 -> 3.Getting candidates...                            |   4.55s |    224 candidates
2018-05-31 01:04:22,485 -> 4.Found flocks...                                  |   1.23s |    224 flocks
2018-05-31 01:04:29,206 -> 5.Updating times...                                |   2.90s |    224 flocks
2018-05-31 01:04:31,491 -> 6.Filter phase...                                  |   2.29s |    247 flocks
2018-05-31 01:04:36,038 -> Reporting locations...                             |   4.55s |  18546 points
2018-05-31 01:04:36,038 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=7,dataset=berlin0-10
2018-05-31 01:04:43,679 -> A.Indexing points... [7.625s] [18546 results]
2018-05-31 01:04:54,275 -> B.Getting pairs... [10.596s] [5788 results]
2018-05-31 01:04:55,671 -> C.Computing centers... [1.396s] [11576 results]
2018-05-31 01:04:56,610 -> D.Indexing centers... [0.939s] [11576 results]
2018-05-31 01:05:03,846 -> E.Getting disks... [7.235s] [11576 results]
2018-05-31 01:05:04,088 -> F.Filtering less-than-mu disks... [0.242s] [1361 results]
2018-05-31 01:05:06,615 -> G.Prunning duplicate candidates... [2.527s] [688 results]
2018-05-31 01:05:06,930 -> H.Indexing candidates... [2.842s] [688 results]
2018-05-31 01:05:07,090 -> I.Getting expansions... [0.160s] [1882 results]
2018-05-31 01:05:07,225 -> J.Finding maximal disks... [0.135s] [233 results]
2018-05-31 01:05:09,337 -> K.Prunning duplicates and subsets... [2.112s] [231 results]
2018-05-31 01:05:09,337 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:05:09,337 ->   berlin0-10,   18546,  30.0,    28,  4,  33.28,    5788,     11576,          688,        231,  7
2018-05-31 01:05:09,807 -> Dropping indices...[0.470s]
2018-05-31 01:05:10,094 -> 1.Set of disks for t_i...                          |  34.06s |    231 disks
2018-05-31 01:05:18,947 -> 2.Distance Join phase...                           |   8.85s |    597 combinations
2018-05-31 01:05:24,039 -> 3.Getting candidates...                            |   5.09s |    213 candidates
2018-05-31 01:05:25,272 -> 4.Found flocks...                                  |   1.23s |    213 flocks
2018-05-31 01:05:31,272 -> 5.Updating times...                                |   1.50s |    213 flocks
2018-05-31 01:05:33,583 -> 6.Filter phase...                                  |   2.31s |    244 flocks
2018-05-31 01:05:38,077 -> Reporting locations...                             |   4.49s |  18546 points
2018-05-31 01:05:38,077 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=8,dataset=berlin0-10
2018-05-31 01:05:43,137 -> A.Indexing points... [5.046s] [18546 results]
2018-05-31 01:05:49,644 -> B.Getting pairs... [6.507s] [5791 results]
2018-05-31 01:05:50,914 -> C.Computing centers... [1.270s] [11582 results]
2018-05-31 01:05:51,830 -> D.Indexing centers... [0.916s] [11582 results]
2018-05-31 01:05:57,281 -> E.Getting disks... [5.451s] [11582 results]
2018-05-31 01:05:57,636 -> F.Filtering less-than-mu disks... [0.355s] [1316 results]
2018-05-31 01:05:59,365 -> G.Prunning duplicate candidates... [1.729s] [670 results]
2018-05-31 01:05:59,662 -> H.Indexing candidates... [2.026s] [670 results]
2018-05-31 01:05:59,822 -> I.Getting expansions... [0.160s] [1792 results]
2018-05-31 01:05:59,962 -> J.Finding maximal disks... [0.140s] [220 results]
2018-05-31 01:06:01,596 -> K.Prunning duplicates and subsets... [1.634s] [219 results]
2018-05-31 01:06:01,597 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:06:01,597 ->   berlin0-10,   18546,  30.0,    28,  4,  23.51,    5791,     11582,          670,        219,  8
2018-05-31 01:06:02,162 -> Dropping indices...[0.565s]
2018-05-31 01:06:02,393 -> 1.Set of disks for t_i...                          |  24.32s |    219 disks
2018-05-31 01:06:11,293 -> 2.Distance Join phase...                           |   8.90s |    520 combinations
2018-05-31 01:06:16,344 -> 3.Getting candidates...                            |   5.05s |    211 candidates
2018-05-31 01:06:17,787 -> 4.Found flocks...                                  |   1.44s |    211 flocks
2018-05-31 01:06:25,014 -> 5.Updating times...                                |   1.92s |    211 flocks
2018-05-31 01:06:27,701 -> 6.Filter phase...                                  |   2.69s |    232 flocks
2018-05-31 01:06:32,215 -> Reporting locations...                             |   4.51s |  18546 points
2018-05-31 01:06:32,216 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=9,dataset=berlin0-10
2018-05-31 01:06:39,107 -> A.Indexing points... [6.862s] [18546 results]
2018-05-31 01:06:49,306 -> B.Getting pairs... [10.199s] [5802 results]
2018-05-31 01:06:50,749 -> C.Computing centers... [1.443s] [11604 results]
2018-05-31 01:06:51,716 -> D.Indexing centers... [0.967s] [11604 results]
2018-05-31 01:06:59,410 -> E.Getting disks... [7.694s] [11604 results]
2018-05-31 01:06:59,649 -> F.Filtering less-than-mu disks... [0.238s] [1306 results]
2018-05-31 01:07:01,531 -> G.Prunning duplicate candidates... [1.882s] [675 results]
2018-05-31 01:07:01,832 -> H.Indexing candidates... [2.183s] [675 results]
2018-05-31 01:07:02,011 -> I.Getting expansions... [0.179s] [1813 results]
2018-05-31 01:07:02,148 -> J.Finding maximal disks... [0.137s] [212 results]
2018-05-31 01:07:03,890 -> K.Prunning duplicates and subsets... [1.742s] [210 results]
2018-05-31 01:07:03,890 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:07:03,890 ->   berlin0-10,   18546,  30.0,    28,  4,  31.65,    5802,     11604,          675,        210,  9
2018-05-31 01:07:04,537 -> Dropping indices...[0.647s]
2018-05-31 01:07:04,934 -> 1.Set of disks for t_i...                          |  32.72s |    210 disks
2018-05-31 01:07:14,622 -> 2.Distance Join phase...                           |   9.69s |    474 combinations
2018-05-31 01:07:20,230 -> 3.Getting candidates...                            |   5.61s |    206 candidates
2018-05-31 01:07:21,877 -> 4.Found flocks...                                  |   1.65s |    206 flocks
2018-05-31 01:07:30,714 -> 5.Updating times...                                |   2.29s |    206 flocks
2018-05-31 01:07:34,154 -> 6.Filter phase...                                  |   3.44s |    226 flocks
2018-05-31 01:07:38,725 -> Reporting locations...                             |   4.57s |  18546 points
2018-05-31 01:07:38,725 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=10,dataset=berlin0-10
2018-05-31 01:07:45,528 -> A.Indexing points... [6.773s] [18546 results]
2018-05-31 01:07:55,511 -> B.Getting pairs... [9.983s] [5797 results]
2018-05-31 01:07:56,756 -> C.Computing centers... [1.245s] [11594 results]
2018-05-31 01:07:57,780 -> D.Indexing centers... [1.024s] [11594 results]
2018-05-31 01:08:04,332 -> E.Getting disks... [6.552s] [11594 results]
2018-05-31 01:08:04,754 -> F.Filtering less-than-mu disks... [0.421s] [1312 results]
2018-05-31 01:08:06,824 -> G.Prunning duplicate candidates... [2.070s] [675 results]
2018-05-31 01:08:07,128 -> H.Indexing candidates... [2.374s] [675 results]
2018-05-31 01:08:07,277 -> I.Getting expansions... [0.149s] [1804 results]
2018-05-31 01:08:07,398 -> J.Finding maximal disks... [0.121s] [212 results]
2018-05-31 01:08:09,215 -> K.Prunning duplicates and subsets... [1.817s] [211 results]
2018-05-31 01:08:09,215 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:08:09,215 ->   berlin0-10,   18546,  30.0,    28,  4,  30.46,    5797,     11594,          675,        211, 10
2018-05-31 01:08:09,973 -> Dropping indices...[0.758s]
2018-05-31 01:08:10,266 -> 1.Set of disks for t_i...                          |  31.54s |    211 disks
2018-05-31 01:08:21,287 -> 2.Distance Join phase...                           |  11.02s |    457 combinations
2018-05-31 01:08:27,130 -> 3.Getting candidates...                            |   5.84s |    197 candidates
2018-05-31 01:08:28,658 -> 4.Found flocks...                                  |   1.53s |    197 flocks
2018-05-31 01:08:37,813 -> 5.Updating times...                                |   1.93s |    197 flocks
2018-05-31 01:08:40,453 -> 6.Filter phase...                                  |   2.64s |    221 flocks
2018-05-31 01:08:40,453 -> 

PFLOCK_SJ	30.0	4	2	2139

2018-05-31 01:08:46,668 -> Running SpatialJoin...                             | 600.96s |   2139 flocks
2018-05-31 01:08:46,668 -> method=SpatialJoin,cores=28,epsilon=30.0,mu=4,delta=2,time=600.957,master=spark://169.235.27.134:7077
2018-05-31 01:08:46,668 -> Closing app...
acald013@dblab-rack15: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
FLOCKFINDER=SpatialJoin;TIME=Thu May 31 01:08:58 PDT 2018;RUN=1527753509;NODES=4;ESTART=;EEND=;ESTEP=;MU=4;DELTA=;SCRIPT=DeltaBenchmarker;EVENT=End
FLOCKFINDER=MergeLast;TIME=Thu May 31 01:08:58 PDT 2018;RUN=1527754138;NODES=4;ESTART=;EEND=;ESTEP=;MU=4;DELTA=;SCRIPT=DeltaBenchmarker;EVENT=Start
WARNING:root:Setting 4 nodes...
acald013@dblab-rack12: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack15: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack11: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack14: no org.apache.spark.deploy.worker.Worker to stop
no org.apache.spark.deploy.master.Master to stop
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack15: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack15.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
WARNING:root:4 nodes has been set...
2018-05-31 01:09:05,491 -> Starting app...
2018-05-31 01:09:08,435 -> Starting session                                   |   2.95s |      0 
2018-05-31 01:09:08,450 -> Setting paramaters                                 |   0.02s |      0 
2018-05-31 01:09:11,660 -> Reading data                                       |   3.21s | 203106 points
2018-05-31 01:09:15,013 -> Extracting timestamps                              |   3.35s |     11 timestamps
2018-05-31 01:09:15,021 -> === MergeLast Start ===
2018-05-31 01:09:20,318 -> Reporting locations at t=0...                      |   5.09s |  18093 points
2018-05-31 01:09:20,334 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=0,dataset=berlin0-10
2018-05-31 01:09:29,197 -> A.Indexing points... [8.811s] [18093 results]
2018-05-31 01:09:36,587 -> B.Getting pairs... [7.389s] [5511 results]
2018-05-31 01:09:38,715 -> C.Computing centers... [2.128s] [11022 results]
2018-05-31 01:09:40,060 -> D.Indexing centers... [1.345s] [11022 results]
2018-05-31 01:09:46,542 -> E.Getting disks... [6.481s] [11022 results]
2018-05-31 01:09:47,211 -> F.Filtering less-than-mu disks... [0.669s] [1210 results]
2018-05-31 01:09:50,415 -> G.Prunning duplicate candidates... [3.204s] [599 results]
2018-05-31 01:09:51,070 -> H.Indexing candidates... [3.858s] [599 results]
2018-05-31 01:09:51,583 -> I.Getting expansions... [0.513s] [1657 results]
2018-05-31 01:09:52,084 -> J.Finding maximal disks... [0.501s] [206 results]
2018-05-31 01:09:54,051 -> K.Prunning duplicates and subsets... [1.967s] [205 results]
2018-05-31 01:09:54,052 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:09:54,052 ->   berlin0-10,   18093,  30.0,    28,  4,  33.67,    5511,     11022,          599,        205,  0
2018-05-31 01:09:54,133 -> Dropping indices...[0.081s]
2018-05-31 01:09:54,463 -> 1.Set of disks for t_i...                          |  34.15s |    205 disks
2018-05-31 01:09:59,205 -> Reporting locations at t=1...                      |   4.74s |  18245 points
2018-05-31 01:09:59,206 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=1,dataset=berlin0-10
2018-05-31 01:10:04,119 -> A.Indexing points... [4.885s] [18245 results]
2018-05-31 01:10:09,037 -> B.Getting pairs... [4.918s] [5629 results]
2018-05-31 01:10:10,473 -> C.Computing centers... [1.436s] [11258 results]
2018-05-31 01:10:11,658 -> D.Indexing centers... [1.184s] [11258 results]
2018-05-31 01:10:16,250 -> E.Getting disks... [4.592s] [11258 results]
2018-05-31 01:10:16,560 -> F.Filtering less-than-mu disks... [0.310s] [1299 results]
2018-05-31 01:10:18,247 -> G.Prunning duplicate candidates... [1.687s] [640 results]
2018-05-31 01:10:18,649 -> H.Indexing candidates... [2.089s] [640 results]
2018-05-31 01:10:18,840 -> I.Getting expansions... [0.191s] [1703 results]
2018-05-31 01:10:19,202 -> J.Finding maximal disks... [0.360s] [220 results]
2018-05-31 01:10:20,742 -> K.Prunning duplicates and subsets... [1.540s] [216 results]
2018-05-31 01:10:20,743 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:10:20,743 ->   berlin0-10,   18245,  30.0,    28,  4,  21.51,    5629,     11258,          640,        216,  1
2018-05-31 01:10:20,827 -> Dropping indices...[0.084s]
2018-05-31 01:10:21,074 -> 2.Set of disks for t_i+delta...                    |  21.87s |    205 disks
2018-05-31 01:10:31,791 -> 3.Joining timestams                                |  10.72s |    319 candidates
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 15 in stage 1467.0 failed 4 times, most recent failure: Lost task 15.3 in stage 1467.0 (TID 66182, 169.235.27.134, executor 2): java.util.NoSuchElementException: head of empty list
	at scala.collection.immutable.Nil$.head(List.scala:420)
	at scala.collection.immutable.Nil$.head(List.scala:417)
	at scala.collection.generic.TraversableForwarder$class.head(TraversableForwarder.scala:56)
	at scala.collection.mutable.ListBuffer.head(ListBuffer.scala:45)
	at FlockFinderMergeLast$.computeMaximalDisks(FlockFinderMergeLast.scala:277)
	at FlockFinderMergeLast$$anonfun$runMergeLast$1$$anonfun$13.apply(FlockFinderMergeLast.scala:221)
	at FlockFinderMergeLast$$anonfun$runMergeLast$1$$anonfun$13.apply(FlockFinderMergeLast.scala:219)
	at org.apache.spark.sql.execution.MapElementsExec$$anonfun$8$$anonfun$apply$1.apply(objects.scala:237)
	at org.apache.spark.sql.execution.MapElementsExec$$anonfun$8$$anonfun$apply$1.apply(objects.scala:237)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.columnar.InMemoryRelation$$anonfun$1$$anon$1.hasNext(InMemoryRelation.scala:138)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:215)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:957)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:948)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:888)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:948)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:694)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:334)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1958)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:935)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:934)
	at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:275)
	at org.apache.spark.sql.Dataset$$anonfun$org$apache$spark$sql$Dataset$$execute$1$1.apply(Dataset.scala:2371)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:57)
	at org.apache.spark.sql.Dataset.withNewExecutionId(Dataset.scala:2765)
	at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$execute$1(Dataset.scala:2370)
	at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collect(Dataset.scala:2377)
	at org.apache.spark.sql.Dataset$$anonfun$count$1.apply(Dataset.scala:2405)
	at org.apache.spark.sql.Dataset$$anonfun$count$1.apply(Dataset.scala:2404)
	at org.apache.spark.sql.Dataset.withCallback(Dataset.scala:2778)
	at org.apache.spark.sql.Dataset.count(Dataset.scala:2404)
	at FlockFinderMergeLast$$anonfun$runMergeLast$1.apply(FlockFinderMergeLast.scala:228)
	at FlockFinderMergeLast$$anonfun$runMergeLast$1.apply(FlockFinderMergeLast.scala:121)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at FlockFinderMergeLast$.runMergeLast(FlockFinderMergeLast.scala:121)
	at FlockFinderMergeLast$$anonfun$run$1$$anonfun$apply$mcVI$sp$1$$anonfun$apply$mcVI$sp$2.apply$mcVD$sp(FlockFinderMergeLast.scala:91)
	at FlockFinderMergeLast$$anonfun$run$1$$anonfun$apply$mcVI$sp$1$$anonfun$apply$mcVI$sp$2.apply(FlockFinderMergeLast.scala:86)
	at FlockFinderMergeLast$$anonfun$run$1$$anonfun$apply$mcVI$sp$1$$anonfun$apply$mcVI$sp$2.apply(FlockFinderMergeLast.scala:86)
	at scala.collection.immutable.NumericRange.foreach(NumericRange.scala:73)
	at FlockFinderMergeLast$$anonfun$run$1$$anonfun$apply$mcVI$sp$1.apply$mcVI$sp(FlockFinderMergeLast.scala:86)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at FlockFinderMergeLast$$anonfun$run$1.apply$mcVI$sp(FlockFinderMergeLast.scala:86)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at FlockFinderMergeLast$.run(FlockFinderMergeLast.scala:86)
	at FlockFinderMergeLast$.main(FlockFinderMergeLast.scala:585)
	at FlockFinderMergeLast.main(FlockFinderMergeLast.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: java.util.NoSuchElementException: head of empty list
	at scala.collection.immutable.Nil$.head(List.scala:420)
	at scala.collection.immutable.Nil$.head(List.scala:417)
	at scala.collection.generic.TraversableForwarder$class.head(TraversableForwarder.scala:56)
	at scala.collection.mutable.ListBuffer.head(ListBuffer.scala:45)
	at FlockFinderMergeLast$.computeMaximalDisks(FlockFinderMergeLast.scala:277)
	at FlockFinderMergeLast$$anonfun$runMergeLast$1$$anonfun$13.apply(FlockFinderMergeLast.scala:221)
	at FlockFinderMergeLast$$anonfun$runMergeLast$1$$anonfun$13.apply(FlockFinderMergeLast.scala:219)
	at org.apache.spark.sql.execution.MapElementsExec$$anonfun$8$$anonfun$apply$1.apply(objects.scala:237)
	at org.apache.spark.sql.execution.MapElementsExec$$anonfun$8$$anonfun$apply$1.apply(objects.scala:237)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.columnar.InMemoryRelation$$anonfun$1$$anon$1.hasNext(InMemoryRelation.scala:138)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:215)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:957)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:948)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:888)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:948)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:694)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:334)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack15: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
FLOCKFINDER=MergeLast;TIME=Thu May 31 01:10:42 PDT 2018;RUN=1527754138;NODES=4;ESTART=;EEND=;ESTEP=;MU=4;DELTA=;SCRIPT=DeltaBenchmarker;EVENT=End
FLOCKFINDER=SpatialJoin;TIME=Thu May 31 01:10:42 PDT 2018;RUN=1527754242;NODES=4;ESTART=;EEND=;ESTEP=;MU=4;DELTA=;SCRIPT=DeltaBenchmarker;EVENT=Start
WARNING:root:Setting 4 nodes...
acald013@dblab-rack12: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack15: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack14: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack11: no org.apache.spark.deploy.worker.Worker to stop
no org.apache.spark.deploy.master.Master to stop
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack15: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack15.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
WARNING:root:4 nodes has been set...
2018-05-31 01:10:49,212 -> Starting app...
2018-05-31 01:10:52,220 -> Starting session                                   |   3.01s |      0 
2018-05-31 01:10:52,240 -> Setting paramaters                                 |   0.02s |      0 
2018-05-31 01:10:55,290 -> Reading data                                       |   3.05s | 203106 points
2018-05-31 01:10:58,570 -> Extracting timestamps                              |   3.28s |     11 timestamps
2018-05-31 01:10:58,579 -> === SpatialJoin Start ===
2018-05-31 01:11:04,056 -> Reporting locations...                             |   5.23s |  18093 points
2018-05-31 01:11:04,069 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=0,dataset=berlin0-10
2018-05-31 01:11:12,226 -> A.Indexing points... [8.117s] [18093 results]
2018-05-31 01:11:19,008 -> B.Getting pairs... [6.781s] [5511 results]
2018-05-31 01:11:20,920 -> C.Computing centers... [1.912s] [11022 results]
2018-05-31 01:11:22,370 -> D.Indexing centers... [1.449s] [11022 results]
2018-05-31 01:11:27,728 -> E.Getting disks... [5.358s] [11022 results]
2018-05-31 01:11:28,100 -> F.Filtering less-than-mu disks... [0.372s] [1210 results]
2018-05-31 01:11:30,892 -> G.Prunning duplicate candidates... [2.792s] [599 results]
2018-05-31 01:11:31,315 -> H.Indexing candidates... [3.215s] [599 results]
2018-05-31 01:11:31,560 -> I.Getting expansions... [0.245s] [1657 results]
2018-05-31 01:11:32,015 -> J.Finding maximal disks... [0.455s] [206 results]
2018-05-31 01:11:33,570 -> K.Prunning duplicates and subsets... [1.555s] [205 results]
2018-05-31 01:11:33,570 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:11:33,571 ->   berlin0-10,   18093,  30.0,    28,  4,  29.46,    5511,     11022,          599,        205,  0
2018-05-31 01:11:33,649 -> Dropping indices...[0.077s]
2018-05-31 01:11:33,943 -> 1.Set of disks for t_i...                          |  29.89s |    205 disks
2018-05-31 01:11:34,341 -> 4.Found flocks...                                  |   0.40s |      0 flocks
2018-05-31 01:11:35,129 -> 5.Updating times...                                |   0.47s |    205 flocks
2018-05-31 01:11:36,004 -> 6.Filter phase...                                  |   0.88s |    205 flocks
2018-05-31 01:11:40,933 -> Reporting locations...                             |   4.93s |  18245 points
2018-05-31 01:11:40,933 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=1,dataset=berlin0-10
2018-05-31 01:11:45,277 -> A.Indexing points... [4.324s] [18245 results]
2018-05-31 01:11:50,328 -> B.Getting pairs... [5.051s] [5629 results]
2018-05-31 01:11:51,732 -> C.Computing centers... [1.404s] [11258 results]
2018-05-31 01:11:52,716 -> D.Indexing centers... [0.984s] [11258 results]
2018-05-31 01:11:57,769 -> E.Getting disks... [5.053s] [11258 results]
2018-05-31 01:11:58,002 -> F.Filtering less-than-mu disks... [0.233s] [1299 results]
2018-05-31 01:11:59,337 -> G.Prunning duplicate candidates... [1.335s] [640 results]
2018-05-31 01:11:59,684 -> H.Indexing candidates... [1.682s] [640 results]
2018-05-31 01:11:59,874 -> I.Getting expansions... [0.190s] [1703 results]
2018-05-31 01:12:00,353 -> J.Finding maximal disks... [0.479s] [220 results]
2018-05-31 01:12:01,786 -> K.Prunning duplicates and subsets... [1.433s] [216 results]
2018-05-31 01:12:01,786 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:12:01,786 ->   berlin0-10,   18245,  30.0,    28,  4,  20.83,    5629,     11258,          640,        216,  1
2018-05-31 01:12:01,868 -> Dropping indices...[0.082s]
2018-05-31 01:12:02,168 -> 1.Set of disks for t_i...                          |  21.24s |    216 disks
2018-05-31 01:12:05,957 -> 2.Distance Join phase...                           |   3.79s |    645 combinations
2018-05-31 01:12:09,144 -> 3.Getting candidates...                            |   3.19s |    196 candidates
2018-05-31 01:12:09,895 -> 4.Found flocks...                                  |   0.75s |      0 flocks
2018-05-31 01:12:12,336 -> 5.Updating times...                                |   1.44s |    196 flocks
2018-05-31 01:12:15,164 -> 6.Filter phase...                                  |   2.83s |    236 flocks
2018-05-31 01:12:20,037 -> Reporting locations...                             |   4.87s |  18394 points
2018-05-31 01:12:20,038 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=2,dataset=berlin0-10
2018-05-31 01:12:24,289 -> A.Indexing points... [4.231s] [18394 results]
2018-05-31 01:12:28,918 -> B.Getting pairs... [4.629s] [5701 results]
2018-05-31 01:12:30,229 -> C.Computing centers... [1.311s] [11402 results]
2018-05-31 01:12:31,146 -> D.Indexing centers... [0.917s] [11402 results]
2018-05-31 01:12:35,353 -> E.Getting disks... [4.207s] [11402 results]
2018-05-31 01:12:35,567 -> F.Filtering less-than-mu disks... [0.214s] [1336 results]
2018-05-31 01:12:36,877 -> G.Prunning duplicate candidates... [1.310s] [658 results]
2018-05-31 01:12:37,218 -> H.Indexing candidates... [1.651s] [658 results]
2018-05-31 01:12:37,368 -> I.Getting expansions... [0.150s] [1757 results]
2018-05-31 01:12:37,523 -> J.Finding maximal disks... [0.155s] [232 results]
2018-05-31 01:12:38,654 -> K.Prunning duplicates and subsets... [1.131s] [227 results]
2018-05-31 01:12:38,655 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:12:38,655 ->   berlin0-10,   18394,  30.0,    28,  4,  18.60,    5701,     11402,          658,        227,  2
2018-05-31 01:12:38,800 -> Dropping indices...[0.145s]
2018-05-31 01:12:39,031 -> 1.Set of disks for t_i...                          |  18.99s |    227 disks
2018-05-31 01:12:46,324 -> 2.Distance Join phase...                           |   7.29s |    901 combinations
2018-05-31 01:12:51,167 -> 3.Getting candidates...                            |   4.84s |    239 candidates
2018-05-31 01:12:51,937 -> 4.Found flocks...                                  |   0.77s |    199 flocks
2018-05-31 01:12:54,600 -> 5.Updating times...                                |   1.22s |    239 flocks
2018-05-31 01:12:56,710 -> 6.Filter phase...                                  |   2.11s |    268 flocks
2018-05-31 01:13:01,576 -> Reporting locations...                             |   4.87s |  18548 points
2018-05-31 01:13:01,577 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=3,dataset=berlin0-10
2018-05-31 01:13:08,909 -> A.Indexing points... [7.315s] [18548 results]
2018-05-31 01:13:19,825 -> B.Getting pairs... [10.916s] [5768 results]
2018-05-31 01:13:21,096 -> C.Computing centers... [1.271s] [11536 results]
2018-05-31 01:13:21,979 -> D.Indexing centers... [0.883s] [11536 results]
2018-05-31 01:13:28,814 -> E.Getting disks... [6.835s] [11536 results]
2018-05-31 01:13:29,024 -> F.Filtering less-than-mu disks... [0.210s] [1349 results]
2018-05-31 01:13:31,403 -> G.Prunning duplicate candidates... [2.379s] [675 results]
2018-05-31 01:13:31,753 -> H.Indexing candidates... [2.729s] [675 results]
2018-05-31 01:13:31,929 -> I.Getting expansions... [0.176s] [1875 results]
2018-05-31 01:13:32,073 -> J.Finding maximal disks... [0.144s] [230 results]
2018-05-31 01:13:33,883 -> K.Prunning duplicates and subsets... [1.810s] [225 results]
2018-05-31 01:13:33,883 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:13:33,883 ->   berlin0-10,   18548,  30.0,    28,  4,  32.29,    5768,     11536,          675,        225,  3
2018-05-31 01:13:34,071 -> Dropping indices...[0.188s]
2018-05-31 01:13:34,318 -> 1.Set of disks for t_i...                          |  32.74s |    225 disks
2018-05-31 01:13:40,970 -> 2.Distance Join phase...                           |   6.65s |   1012 combinations
2018-05-31 01:13:45,352 -> 3.Getting candidates...                            |   4.38s |    242 candidates
2018-05-31 01:13:46,269 -> 4.Found flocks...                                  |   0.92s |    210 flocks
2018-05-31 01:13:49,732 -> 5.Updating times...                                |   1.42s |    242 flocks
2018-05-31 01:13:51,954 -> 6.Filter phase...                                  |   2.22s |    269 flocks
2018-05-31 01:13:56,811 -> Reporting locations...                             |   4.86s |  18548 points
2018-05-31 01:13:56,811 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=4,dataset=berlin0-10
2018-05-31 01:14:04,162 -> A.Indexing points... [7.333s] [18548 results]
2018-05-31 01:14:14,666 -> B.Getting pairs... [10.504s] [5775 results]
2018-05-31 01:14:15,914 -> C.Computing centers... [1.248s] [11550 results]
2018-05-31 01:14:16,811 -> D.Indexing centers... [0.896s] [11550 results]
2018-05-31 01:14:23,800 -> E.Getting disks... [6.989s] [11550 results]
2018-05-31 01:14:24,018 -> F.Filtering less-than-mu disks... [0.218s] [1369 results]
2018-05-31 01:14:25,960 -> G.Prunning duplicate candidates... [1.942s] [694 results]
2018-05-31 01:14:26,269 -> H.Indexing candidates... [2.251s] [694 results]
2018-05-31 01:14:26,417 -> I.Getting expansions... [0.148s] [1914 results]
2018-05-31 01:14:26,559 -> J.Finding maximal disks... [0.142s] [245 results]
2018-05-31 01:14:28,368 -> K.Prunning duplicates and subsets... [1.809s] [238 results]
2018-05-31 01:14:28,368 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:14:28,369 ->   berlin0-10,   18548,  30.0,    28,  4,  31.54,    5775,     11550,          694,        238,  4
2018-05-31 01:14:28,649 -> Dropping indices...[0.280s]
2018-05-31 01:14:28,874 -> 1.Set of disks for t_i...                          |  32.06s |    238 disks
2018-05-31 01:14:36,359 -> 2.Distance Join phase...                           |   7.49s |   1066 combinations
2018-05-31 01:14:41,027 -> 3.Getting candidates...                            |   4.67s |    250 candidates
2018-05-31 01:14:41,966 -> 4.Found flocks...                                  |   0.94s |    220 flocks
2018-05-31 01:14:46,155 -> 5.Updating times...                                |   1.53s |    250 flocks
2018-05-31 01:14:48,446 -> 6.Filter phase...                                  |   2.29s |    274 flocks
2018-05-31 01:14:53,250 -> Reporting locations...                             |   4.80s |  18548 points
2018-05-31 01:14:53,251 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=5,dataset=berlin0-10
2018-05-31 01:15:00,537 -> A.Indexing points... [7.272s] [18548 results]
2018-05-31 01:15:10,989 -> B.Getting pairs... [10.452s] [5765 results]
2018-05-31 01:15:12,322 -> C.Computing centers... [1.333s] [11530 results]
2018-05-31 01:15:13,211 -> D.Indexing centers... [0.889s] [11530 results]
2018-05-31 01:15:20,252 -> E.Getting disks... [7.041s] [11530 results]
2018-05-31 01:15:20,486 -> F.Filtering less-than-mu disks... [0.234s] [1362 results]
2018-05-31 01:15:22,576 -> G.Prunning duplicate candidates... [2.090s] [686 results]
2018-05-31 01:15:22,858 -> H.Indexing candidates... [2.372s] [686 results]
2018-05-31 01:15:23,011 -> I.Getting expansions... [0.153s] [1917 results]
2018-05-31 01:15:23,152 -> J.Finding maximal disks... [0.141s] [237 results]
2018-05-31 01:15:25,008 -> K.Prunning duplicates and subsets... [1.856s] [234 results]
2018-05-31 01:15:25,008 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:15:25,008 ->   berlin0-10,   18548,  30.0,    28,  4,  31.74,    5765,     11530,          686,        234,  5
2018-05-31 01:15:25,334 -> Dropping indices...[0.325s]
2018-05-31 01:15:25,617 -> 1.Set of disks for t_i...                          |  32.37s |    234 disks
2018-05-31 01:15:33,435 -> 2.Distance Join phase...                           |   7.82s |   1035 combinations
2018-05-31 01:15:38,365 -> 3.Getting candidates...                            |   4.93s |    240 candidates
2018-05-31 01:15:39,400 -> 4.Found flocks...                                  |   1.04s |    213 flocks
2018-05-31 01:15:44,579 -> 5.Updating times...                                |   1.77s |    240 flocks
2018-05-31 01:15:47,100 -> 6.Filter phase...                                  |   2.52s |    267 flocks
2018-05-31 01:15:51,921 -> Reporting locations...                             |   4.82s |  18546 points
2018-05-31 01:15:51,921 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=6,dataset=berlin0-10
2018-05-31 01:15:59,518 -> A.Indexing points... [7.582s] [18546 results]
2018-05-31 01:16:10,048 -> B.Getting pairs... [10.530s] [5758 results]
2018-05-31 01:16:11,287 -> C.Computing centers... [1.239s] [11516 results]
2018-05-31 01:16:12,182 -> D.Indexing centers... [0.895s] [11516 results]
2018-05-31 01:16:19,054 -> E.Getting disks... [6.872s] [11516 results]
2018-05-31 01:16:19,261 -> F.Filtering less-than-mu disks... [0.207s] [1346 results]
2018-05-31 01:16:21,241 -> G.Prunning duplicate candidates... [1.980s] [681 results]
2018-05-31 01:16:21,577 -> H.Indexing candidates... [2.316s] [681 results]
2018-05-31 01:16:21,736 -> I.Getting expansions... [0.159s] [1951 results]
2018-05-31 01:16:21,872 -> J.Finding maximal disks... [0.136s] [225 results]
2018-05-31 01:16:23,697 -> K.Prunning duplicates and subsets... [1.824s] [222 results]
2018-05-31 01:16:23,697 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:16:23,697 ->   berlin0-10,   18546,  30.0,    28,  4,  31.76,    5758,     11516,          681,        222,  6
2018-05-31 01:16:24,084 -> Dropping indices...[0.386s]
2018-05-31 01:16:24,380 -> 1.Set of disks for t_i...                          |  32.46s |    222 disks
2018-05-31 01:16:32,978 -> 2.Distance Join phase...                           |   8.60s |    894 combinations
2018-05-31 01:16:38,021 -> 3.Getting candidates...                            |   5.04s |    252 candidates
2018-05-31 01:16:39,165 -> 4.Found flocks...                                  |   1.14s |    218 flocks
2018-05-31 01:16:46,294 -> 5.Updating times...                                |   1.64s |    252 flocks
2018-05-31 01:16:48,902 -> 6.Filter phase...                                  |   2.61s |    272 flocks
2018-05-31 01:16:53,711 -> Reporting locations...                             |   4.81s |  18546 points
2018-05-31 01:16:53,711 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=7,dataset=berlin0-10
2018-05-31 01:17:00,833 -> A.Indexing points... [7.107s] [18546 results]
2018-05-31 01:17:11,535 -> B.Getting pairs... [10.702s] [5788 results]
2018-05-31 01:17:12,797 -> C.Computing centers... [1.262s] [11576 results]
2018-05-31 01:17:13,711 -> D.Indexing centers... [0.914s] [11576 results]
2018-05-31 01:17:20,723 -> E.Getting disks... [7.012s] [11576 results]
2018-05-31 01:17:20,978 -> F.Filtering less-than-mu disks... [0.255s] [1361 results]
2018-05-31 01:17:22,990 -> G.Prunning duplicate candidates... [2.012s] [688 results]
2018-05-31 01:17:23,377 -> H.Indexing candidates... [2.399s] [688 results]
2018-05-31 01:17:23,580 -> I.Getting expansions... [0.203s] [1882 results]
2018-05-31 01:17:23,711 -> J.Finding maximal disks... [0.131s] [233 results]
2018-05-31 01:17:25,845 -> K.Prunning duplicates and subsets... [2.134s] [231 results]
2018-05-31 01:17:25,845 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:17:25,845 ->   berlin0-10,   18546,  30.0,    28,  4,  32.12,    5788,     11576,          688,        231,  7
2018-05-31 01:17:26,357 -> Dropping indices...[0.512s]
2018-05-31 01:17:26,658 -> 1.Set of disks for t_i...                          |  32.95s |    231 disks
2018-05-31 01:17:35,017 -> 2.Distance Join phase...                           |   8.36s |    934 combinations
2018-05-31 01:17:40,444 -> 3.Getting candidates...                            |   5.43s |    239 candidates
2018-05-31 01:17:41,712 -> 4.Found flocks...                                  |   1.27s |    216 flocks
2018-05-31 01:17:48,494 -> 5.Updating times...                                |   1.76s |    239 flocks
2018-05-31 01:17:51,072 -> 6.Filter phase...                                  |   2.58s |    270 flocks
2018-05-31 01:17:55,734 -> Reporting locations...                             |   4.66s |  18546 points
2018-05-31 01:17:55,734 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=8,dataset=berlin0-10
2018-05-31 01:18:00,847 -> A.Indexing points... [5.097s] [18546 results]
2018-05-31 01:18:07,271 -> B.Getting pairs... [6.424s] [5791 results]
2018-05-31 01:18:08,510 -> C.Computing centers... [1.239s] [11582 results]
2018-05-31 01:18:09,389 -> D.Indexing centers... [0.878s] [11582 results]
2018-05-31 01:18:14,818 -> E.Getting disks... [5.429s] [11582 results]
2018-05-31 01:18:15,017 -> F.Filtering less-than-mu disks... [0.198s] [1316 results]
2018-05-31 01:18:16,512 -> G.Prunning duplicate candidates... [1.495s] [670 results]
2018-05-31 01:18:16,837 -> H.Indexing candidates... [1.820s] [670 results]
2018-05-31 01:18:18,501 -> I.Getting expansions... [1.663s] [1792 results]
2018-05-31 01:18:18,649 -> J.Finding maximal disks... [0.148s] [220 results]
2018-05-31 01:18:19,912 -> K.Prunning duplicates and subsets... [1.263s] [219 results]
2018-05-31 01:18:19,912 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:18:19,912 ->   berlin0-10,   18546,  30.0,    28,  4,  24.16,    5791,     11582,          670,        219,  8
2018-05-31 01:18:20,503 -> Dropping indices...[0.591s]
2018-05-31 01:18:20,779 -> 1.Set of disks for t_i...                          |  25.05s |    219 disks
2018-05-31 01:18:30,929 -> 2.Distance Join phase...                           |  10.15s |    811 combinations
2018-05-31 01:18:36,160 -> 3.Getting candidates...                            |   5.23s |    226 candidates
2018-05-31 01:18:37,489 -> 4.Found flocks...                                  |   1.33s |    197 flocks
2018-05-31 01:18:44,895 -> 5.Updating times...                                |   1.89s |    226 flocks
2018-05-31 01:18:47,533 -> 6.Filter phase...                                  |   2.64s |    247 flocks
2018-05-31 01:18:52,229 -> Reporting locations...                             |   4.70s |  18546 points
2018-05-31 01:18:52,229 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=9,dataset=berlin0-10
2018-05-31 01:18:59,313 -> A.Indexing points... [7.055s] [18546 results]
2018-05-31 01:19:08,833 -> B.Getting pairs... [9.519s] [5802 results]
2018-05-31 01:19:10,052 -> C.Computing centers... [1.218s] [11604 results]
2018-05-31 01:19:10,958 -> D.Indexing centers... [0.906s] [11604 results]
2018-05-31 01:19:17,493 -> E.Getting disks... [6.534s] [11604 results]
2018-05-31 01:19:17,717 -> F.Filtering less-than-mu disks... [0.224s] [1306 results]
2018-05-31 01:19:19,711 -> G.Prunning duplicate candidates... [1.994s] [675 results]
2018-05-31 01:19:20,008 -> H.Indexing candidates... [2.291s] [675 results]
2018-05-31 01:19:20,168 -> I.Getting expansions... [0.160s] [1813 results]
2018-05-31 01:19:20,300 -> J.Finding maximal disks... [0.132s] [212 results]
2018-05-31 01:19:22,098 -> K.Prunning duplicates and subsets... [1.798s] [210 results]
2018-05-31 01:19:22,098 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:19:22,098 ->   berlin0-10,   18546,  30.0,    28,  4,  29.84,    5802,     11604,          675,        210,  9
2018-05-31 01:19:22,783 -> Dropping indices...[0.684s]
2018-05-31 01:19:23,068 -> 1.Set of disks for t_i...                          |  30.84s |    210 disks
2018-05-31 01:19:32,373 -> 2.Distance Join phase...                           |   9.30s |    637 combinations
2018-05-31 01:19:38,110 -> 3.Getting candidates...                            |   5.74s |    219 candidates
2018-05-31 01:19:39,772 -> 4.Found flocks...                                  |   1.66s |    199 flocks
2018-05-31 01:19:49,095 -> 5.Updating times...                                |   2.50s |    219 flocks
2018-05-31 01:19:52,635 -> 6.Filter phase...                                  |   3.54s |    239 flocks
2018-05-31 01:19:57,332 -> Reporting locations...                             |   4.70s |  18546 points
2018-05-31 01:19:57,332 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=10,dataset=berlin0-10
2018-05-31 01:20:04,554 -> A.Indexing points... [7.190s] [18546 results]
2018-05-31 01:20:14,198 -> B.Getting pairs... [9.644s] [5797 results]
2018-05-31 01:20:15,445 -> C.Computing centers... [1.247s] [11594 results]
2018-05-31 01:20:16,384 -> D.Indexing centers... [0.939s] [11594 results]
2018-05-31 01:20:23,053 -> E.Getting disks... [6.669s] [11594 results]
2018-05-31 01:20:23,256 -> F.Filtering less-than-mu disks... [0.203s] [1312 results]
2018-05-31 01:20:25,431 -> G.Prunning duplicate candidates... [2.175s] [675 results]
2018-05-31 01:20:25,802 -> H.Indexing candidates... [2.546s] [675 results]
2018-05-31 01:20:25,958 -> I.Getting expansions... [0.156s] [1804 results]
2018-05-31 01:20:26,094 -> J.Finding maximal disks... [0.136s] [212 results]
2018-05-31 01:20:27,927 -> K.Prunning duplicates and subsets... [1.833s] [211 results]
2018-05-31 01:20:27,927 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:20:27,927 ->   berlin0-10,   18546,  30.0,    28,  4,  30.56,    5797,     11594,          675,        211, 10
2018-05-31 01:20:28,715 -> Dropping indices...[0.788s]
2018-05-31 01:20:28,992 -> 1.Set of disks for t_i...                          |  31.66s |    211 disks
2018-05-31 01:20:40,368 -> 2.Distance Join phase...                           |  11.38s |    598 combinations
2018-05-31 01:20:46,931 -> 3.Getting candidates...                            |   6.56s |    213 candidates
2018-05-31 01:20:48,546 -> 4.Found flocks...                                  |   1.62s |    196 flocks
2018-05-31 01:20:58,064 -> 5.Updating times...                                |   1.98s |    213 flocks
2018-05-31 01:21:01,007 -> 6.Filter phase...                                  |   2.94s |    237 flocks
2018-05-31 01:21:01,007 -> 

PFLOCK_SJ	30.0	4	3	1868

2018-05-31 01:21:07,278 -> Running SpatialJoin...                             | 608.70s |   1868 flocks
2018-05-31 01:21:07,279 -> method=SpatialJoin,cores=28,epsilon=30.0,mu=4,delta=3,time=608.698,master=spark://169.235.27.134:7077
2018-05-31 01:21:07,279 -> Closing app...
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack15: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
FLOCKFINDER=SpatialJoin;TIME=Thu May 31 01:21:13 PDT 2018;RUN=1527754242;NODES=4;ESTART=;EEND=;ESTEP=;MU=4;DELTA=;SCRIPT=DeltaBenchmarker;EVENT=End
FLOCKFINDER=MergeLast;TIME=Thu May 31 01:21:13 PDT 2018;RUN=1527754873;NODES=4;ESTART=;EEND=;ESTEP=;MU=4;DELTA=;SCRIPT=DeltaBenchmarker;EVENT=Start
WARNING:root:Setting 4 nodes...
acald013@dblab-rack12: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack14: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack15: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack11: no org.apache.spark.deploy.worker.Worker to stop
no org.apache.spark.deploy.master.Master to stop
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack15: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack15.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
WARNING:root:4 nodes has been set...
2018-05-31 01:21:21,219 -> Starting app...
2018-05-31 01:21:24,059 -> Starting session                                   |   2.84s |      0 
2018-05-31 01:21:24,075 -> Setting paramaters                                 |   0.01s |      0 
2018-05-31 01:21:27,172 -> Reading data                                       |   3.10s | 203106 points
2018-05-31 01:21:30,499 -> Extracting timestamps                              |   3.33s |     11 timestamps
2018-05-31 01:21:30,505 -> === MergeLast Start ===
2018-05-31 01:21:35,989 -> Reporting locations at t=0...                      |   5.28s |  18093 points
2018-05-31 01:21:36,006 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=0,dataset=berlin0-10
2018-05-31 01:21:44,379 -> A.Indexing points... [8.326s] [18093 results]
2018-05-31 01:21:51,871 -> B.Getting pairs... [7.492s] [5511 results]
2018-05-31 01:21:53,924 -> C.Computing centers... [2.053s] [11022 results]
2018-05-31 01:21:55,280 -> D.Indexing centers... [1.356s] [11022 results]
2018-05-31 01:22:01,566 -> E.Getting disks... [6.286s] [11022 results]
2018-05-31 01:22:01,979 -> F.Filtering less-than-mu disks... [0.413s] [1210 results]
2018-05-31 01:22:04,232 -> G.Prunning duplicate candidates... [2.253s] [599 results]
2018-05-31 01:22:04,800 -> H.Indexing candidates... [2.821s] [599 results]
2018-05-31 01:22:05,021 -> I.Getting expansions... [0.220s] [1657 results]
2018-05-31 01:22:05,648 -> J.Finding maximal disks... [0.627s] [206 results]
2018-05-31 01:22:07,525 -> K.Prunning duplicates and subsets... [1.877s] [205 results]
2018-05-31 01:22:07,525 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:22:07,525 ->   berlin0-10,   18093,  30.0,    28,  4,  31.47,    5511,     11022,          599,        205,  0
2018-05-31 01:22:07,587 -> Dropping indices...[0.062s]
2018-05-31 01:22:07,905 -> 1.Set of disks for t_i...                          |  31.92s |    205 disks
2018-05-31 01:22:12,627 -> Reporting locations at t=2...                      |   4.72s |  18394 points
2018-05-31 01:22:12,628 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=2,dataset=berlin0-10
2018-05-31 01:22:17,555 -> A.Indexing points... [4.906s] [18394 results]
2018-05-31 01:22:22,666 -> B.Getting pairs... [5.110s] [5701 results]
2018-05-31 01:22:24,127 -> C.Computing centers... [1.461s] [11402 results]
2018-05-31 01:22:25,099 -> D.Indexing centers... [0.972s] [11402 results]
2018-05-31 01:22:29,910 -> E.Getting disks... [4.810s] [11402 results]
2018-05-31 01:22:30,188 -> F.Filtering less-than-mu disks... [0.278s] [1336 results]
2018-05-31 01:22:31,789 -> G.Prunning duplicate candidates... [1.600s] [658 results]
2018-05-31 01:22:32,142 -> H.Indexing candidates... [1.953s] [658 results]
2018-05-31 01:22:32,301 -> I.Getting expansions... [0.159s] [1757 results]
2018-05-31 01:22:32,633 -> J.Finding maximal disks... [0.332s] [232 results]
2018-05-31 01:22:34,038 -> K.Prunning duplicates and subsets... [1.405s] [227 results]
2018-05-31 01:22:34,038 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:22:34,038 ->   berlin0-10,   18394,  30.0,    28,  4,  21.39,    5701,     11402,          658,        227,  2
2018-05-31 01:22:34,121 -> Dropping indices...[0.083s]
2018-05-31 01:22:34,358 -> 2.Set of disks for t_i+delta...                    |  21.73s |    205 disks
2018-05-31 01:22:42,356 -> 3.Joining timestams                                |   8.00s |    332 candidates
2018-05-31 01:22:54,182 -> Checking internal timestamps                       |  11.83s |    199 flocks
2018-05-31 01:22:59,500 -> Reporting locations at t=1...                      |   4.95s |  18245 points
2018-05-31 01:22:59,500 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=1,dataset=berlin0-10
2018-05-31 01:23:03,895 -> A.Indexing points... [4.376s] [18245 results]
2018-05-31 01:23:08,456 -> B.Getting pairs... [4.560s] [5629 results]
2018-05-31 01:23:09,826 -> C.Computing centers... [1.370s] [11258 results]
2018-05-31 01:23:10,793 -> D.Indexing centers... [0.967s] [11258 results]
2018-05-31 01:23:15,233 -> E.Getting disks... [4.440s] [11258 results]
2018-05-31 01:23:15,493 -> F.Filtering less-than-mu disks... [0.259s] [1299 results]
2018-05-31 01:23:17,296 -> G.Prunning duplicate candidates... [1.803s] [640 results]
2018-05-31 01:23:17,623 -> H.Indexing candidates... [2.130s] [640 results]
2018-05-31 01:23:17,770 -> I.Getting expansions... [0.147s] [1703 results]
2018-05-31 01:23:17,930 -> J.Finding maximal disks... [0.160s] [220 results]
2018-05-31 01:23:19,077 -> K.Prunning duplicates and subsets... [1.147s] [216 results]
2018-05-31 01:23:19,077 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:23:19,077 ->   berlin0-10,   18245,  30.0,    28,  4,  19.56,    5629,     11258,          640,        216,  1
2018-05-31 01:23:19,177 -> Dropping indices...[0.100s]
2018-05-31 01:23:19,418 -> 1.Set of disks for t_i...                          |  19.92s |    216 disks
2018-05-31 01:23:24,215 -> Reporting locations at t=3...                      |   4.80s |  18548 points
2018-05-31 01:23:24,215 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=3,dataset=berlin0-10
2018-05-31 01:23:31,405 -> A.Indexing points... [7.163s] [18548 results]
2018-05-31 01:23:41,785 -> B.Getting pairs... [10.380s] [5768 results]
2018-05-31 01:23:43,093 -> C.Computing centers... [1.308s] [11536 results]
2018-05-31 01:23:44,381 -> D.Indexing centers... [1.288s] [11536 results]
2018-05-31 01:23:51,322 -> E.Getting disks... [6.941s] [11536 results]
2018-05-31 01:23:51,558 -> F.Filtering less-than-mu disks... [0.236s] [1349 results]
2018-05-31 01:23:53,719 -> G.Prunning duplicate candidates... [2.161s] [675 results]
2018-05-31 01:23:54,059 -> H.Indexing candidates... [2.501s] [675 results]
2018-05-31 01:23:54,267 -> I.Getting expansions... [0.208s] [1875 results]
2018-05-31 01:23:54,425 -> J.Finding maximal disks... [0.158s] [230 results]
2018-05-31 01:23:56,351 -> K.Prunning duplicates and subsets... [1.926s] [225 results]
2018-05-31 01:23:56,351 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:23:56,351 ->   berlin0-10,   18548,  30.0,    28,  4,  32.11,    5768,     11536,          675,        225,  3
2018-05-31 01:23:56,498 -> Dropping indices...[0.147s]
2018-05-31 01:23:56,738 -> 2.Set of disks for t_i+delta...                    |  32.52s |    216 disks
2018-05-31 01:24:03,819 -> 3.Joining timestams                                |   7.08s |    333 candidates
2018-05-31 01:24:13,051 -> Checking internal timestamps                       |   9.23s |    210 flocks
2018-05-31 01:24:18,417 -> Reporting locations at t=2...                      |   4.77s |  18394 points
2018-05-31 01:24:18,696 -> 1.Set of disks for t_i...                          |   0.28s |    227 disks
2018-05-31 01:24:23,490 -> Reporting locations at t=4...                      |   4.79s |  18548 points
2018-05-31 01:24:23,491 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=4,dataset=berlin0-10
2018-05-31 01:24:30,591 -> A.Indexing points... [7.079s] [18548 results]
2018-05-31 01:24:40,765 -> B.Getting pairs... [10.173s] [5775 results]
2018-05-31 01:24:42,069 -> C.Computing centers... [1.304s] [11550 results]
2018-05-31 01:24:42,984 -> D.Indexing centers... [0.915s] [11550 results]
2018-05-31 01:24:50,462 -> E.Getting disks... [7.477s] [11550 results]
2018-05-31 01:24:50,705 -> F.Filtering less-than-mu disks... [0.243s] [1369 results]
2018-05-31 01:24:52,845 -> G.Prunning duplicate candidates... [2.140s] [694 results]
2018-05-31 01:24:53,185 -> H.Indexing candidates... [2.480s] [694 results]
2018-05-31 01:24:53,356 -> I.Getting expansions... [0.171s] [1914 results]
2018-05-31 01:24:53,502 -> J.Finding maximal disks... [0.146s] [245 results]
2018-05-31 01:24:55,476 -> K.Prunning duplicates and subsets... [1.973s] [238 results]
2018-05-31 01:24:55,476 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:24:55,476 ->   berlin0-10,   18548,  30.0,    28,  4,  31.96,    5775,     11550,          694,        238,  4
2018-05-31 01:24:55,657 -> Dropping indices...[0.181s]
2018-05-31 01:24:55,883 -> 2.Set of disks for t_i+delta...                    |  32.39s |    227 disks
2018-05-31 01:25:03,523 -> 3.Joining timestams                                |   7.64s |    360 candidates
2018-05-31 01:25:12,881 -> Checking internal timestamps                       |   9.36s |    220 flocks
2018-05-31 01:25:18,609 -> Reporting locations at t=3...                      |   4.78s |  18548 points
2018-05-31 01:25:18,855 -> 1.Set of disks for t_i...                          |   0.25s |    225 disks
2018-05-31 01:25:23,680 -> Reporting locations at t=5...                      |   4.83s |  18548 points
2018-05-31 01:25:23,680 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=5,dataset=berlin0-10
2018-05-31 01:25:30,618 -> A.Indexing points... [6.916s] [18548 results]
2018-05-31 01:25:40,743 -> B.Getting pairs... [10.125s] [5765 results]
2018-05-31 01:25:42,084 -> C.Computing centers... [1.341s] [11530 results]
2018-05-31 01:25:42,978 -> D.Indexing centers... [0.893s] [11530 results]
2018-05-31 01:25:49,862 -> E.Getting disks... [6.884s] [11530 results]
2018-05-31 01:25:50,067 -> F.Filtering less-than-mu disks... [0.205s] [1362 results]
2018-05-31 01:25:52,048 -> G.Prunning duplicate candidates... [1.981s] [686 results]
2018-05-31 01:25:52,353 -> H.Indexing candidates... [2.286s] [686 results]
2018-05-31 01:25:52,508 -> I.Getting expansions... [0.155s] [1917 results]
2018-05-31 01:25:52,672 -> J.Finding maximal disks... [0.164s] [237 results]
2018-05-31 01:25:54,658 -> K.Prunning duplicates and subsets... [1.986s] [234 results]
2018-05-31 01:25:54,658 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:25:54,658 ->   berlin0-10,   18548,  30.0,    28,  4,  30.96,    5765,     11530,          686,        234,  5
2018-05-31 01:25:54,849 -> Dropping indices...[0.191s]
2018-05-31 01:25:55,112 -> 2.Set of disks for t_i+delta...                    |  31.43s |    225 disks
2018-05-31 01:26:02,528 -> 3.Joining timestams                                |   7.42s |    327 candidates
2018-05-31 01:26:12,137 -> Checking internal timestamps                       |   9.61s |    213 flocks
2018-05-31 01:26:17,972 -> Reporting locations at t=4...                      |   4.84s |  18548 points
2018-05-31 01:26:18,226 -> 1.Set of disks for t_i...                          |   0.25s |    238 disks
2018-05-31 01:26:23,036 -> Reporting locations at t=6...                      |   4.81s |  18546 points
2018-05-31 01:26:23,036 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=6,dataset=berlin0-10
2018-05-31 01:26:29,983 -> A.Indexing points... [6.928s] [18546 results]
2018-05-31 01:26:40,258 -> B.Getting pairs... [10.275s] [5758 results]
2018-05-31 01:26:41,601 -> C.Computing centers... [1.343s] [11516 results]
2018-05-31 01:26:42,515 -> D.Indexing centers... [0.914s] [11516 results]
2018-05-31 01:26:49,388 -> E.Getting disks... [6.872s] [11516 results]
2018-05-31 01:26:49,596 -> F.Filtering less-than-mu disks... [0.208s] [1346 results]
2018-05-31 01:26:51,766 -> G.Prunning duplicate candidates... [2.170s] [681 results]
2018-05-31 01:26:52,080 -> H.Indexing candidates... [2.484s] [681 results]
2018-05-31 01:26:52,264 -> I.Getting expansions... [0.184s] [1951 results]
2018-05-31 01:26:52,402 -> J.Finding maximal disks... [0.138s] [225 results]
2018-05-31 01:26:54,226 -> K.Prunning duplicates and subsets... [1.824s] [222 results]
2018-05-31 01:26:54,227 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:26:54,227 ->   berlin0-10,   18546,  30.0,    28,  4,  31.17,    5758,     11516,          681,        222,  6
2018-05-31 01:26:54,455 -> Dropping indices...[0.228s]
2018-05-31 01:26:54,677 -> 2.Set of disks for t_i+delta...                    |  31.64s |    238 disks
2018-05-31 01:27:02,495 -> 3.Joining timestams                                |   7.82s |    324 candidates
2018-05-31 01:27:11,806 -> Checking internal timestamps                       |   9.31s |    218 flocks
2018-05-31 01:27:17,888 -> Reporting locations at t=5...                      |   4.85s |  18548 points
2018-05-31 01:27:18,154 -> 1.Set of disks for t_i...                          |   0.27s |    234 disks
2018-05-31 01:27:22,947 -> Reporting locations at t=7...                      |   4.79s |  18546 points
2018-05-31 01:27:22,947 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=7,dataset=berlin0-10
2018-05-31 01:27:29,929 -> A.Indexing points... [6.961s] [18546 results]
2018-05-31 01:27:40,341 -> B.Getting pairs... [10.412s] [5788 results]
2018-05-31 01:27:41,650 -> C.Computing centers... [1.309s] [11576 results]
2018-05-31 01:27:42,600 -> D.Indexing centers... [0.950s] [11576 results]
2018-05-31 01:27:49,459 -> E.Getting disks... [6.859s] [11576 results]
2018-05-31 01:27:49,665 -> F.Filtering less-than-mu disks... [0.206s] [1361 results]
2018-05-31 01:27:51,924 -> G.Prunning duplicate candidates... [2.259s] [688 results]
2018-05-31 01:27:52,266 -> H.Indexing candidates... [2.601s] [688 results]
2018-05-31 01:27:52,411 -> I.Getting expansions... [0.145s] [1882 results]
2018-05-31 01:27:52,544 -> J.Finding maximal disks... [0.133s] [233 results]
2018-05-31 01:27:54,404 -> K.Prunning duplicates and subsets... [1.860s] [231 results]
2018-05-31 01:27:54,404 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:27:54,404 ->   berlin0-10,   18546,  30.0,    28,  4,  31.44,    5788,     11576,          688,        231,  7
2018-05-31 01:27:54,676 -> Dropping indices...[0.271s]
2018-05-31 01:27:54,946 -> 2.Set of disks for t_i+delta...                    |  32.00s |    234 disks
2018-05-31 01:28:01,986 -> 3.Joining timestams                                |   7.04s |    320 candidates
2018-05-31 01:28:11,144 -> Checking internal timestamps                       |   9.16s |    216 flocks
2018-05-31 01:28:17,287 -> Reporting locations at t=6...                      |   4.83s |  18546 points
2018-05-31 01:28:17,533 -> 1.Set of disks for t_i...                          |   0.25s |    222 disks
2018-05-31 01:28:22,283 -> Reporting locations at t=8...                      |   4.75s |  18546 points
2018-05-31 01:28:22,283 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=8,dataset=berlin0-10
2018-05-31 01:28:26,559 -> A.Indexing points... [4.252s] [18546 results]
2018-05-31 01:28:32,472 -> B.Getting pairs... [5.912s] [5791 results]
2018-05-31 01:28:33,733 -> C.Computing centers... [1.261s] [11582 results]
2018-05-31 01:28:34,745 -> D.Indexing centers... [1.012s] [11582 results]
2018-05-31 01:28:40,074 -> E.Getting disks... [5.328s] [11582 results]
2018-05-31 01:28:40,359 -> F.Filtering less-than-mu disks... [0.285s] [1316 results]
2018-05-31 01:28:42,155 -> G.Prunning duplicate candidates... [1.796s] [670 results]
2018-05-31 01:28:42,567 -> H.Indexing candidates... [2.208s] [670 results]
2018-05-31 01:28:42,752 -> I.Getting expansions... [0.185s] [1792 results]
2018-05-31 01:28:42,896 -> J.Finding maximal disks... [0.144s] [220 results]
2018-05-31 01:28:44,156 -> K.Prunning duplicates and subsets... [1.259s] [219 results]
2018-05-31 01:28:44,156 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:28:44,156 ->   berlin0-10,   18546,  30.0,    28,  4,  21.85,    5791,     11582,          670,        219,  8
2018-05-31 01:28:44,482 -> Dropping indices...[0.326s]
2018-05-31 01:28:44,752 -> 2.Set of disks for t_i+delta...                    |  22.47s |    222 disks
2018-05-31 01:28:51,863 -> 3.Joining timestams                                |   7.11s |    283 candidates
2018-05-31 01:29:00,777 -> Checking internal timestamps                       |   8.91s |    197 flocks
2018-05-31 01:29:07,110 -> Reporting locations at t=7...                      |   4.87s |  18546 points
2018-05-31 01:29:07,370 -> 1.Set of disks for t_i...                          |   0.26s |    231 disks
2018-05-31 01:29:12,004 -> Reporting locations at t=9...                      |   4.63s |  18546 points
2018-05-31 01:29:12,005 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=9,dataset=berlin0-10
2018-05-31 01:29:19,535 -> A.Indexing points... [7.492s] [18546 results]
2018-05-31 01:29:30,406 -> B.Getting pairs... [10.871s] [5802 results]
2018-05-31 01:29:31,688 -> C.Computing centers... [1.282s] [11604 results]
2018-05-31 01:29:32,671 -> D.Indexing centers... [0.983s] [11604 results]
2018-05-31 01:29:39,891 -> E.Getting disks... [7.219s] [11604 results]
2018-05-31 01:29:40,144 -> F.Filtering less-than-mu disks... [0.253s] [1306 results]
2018-05-31 01:29:42,364 -> G.Prunning duplicate candidates... [2.220s] [675 results]
2018-05-31 01:29:42,690 -> H.Indexing candidates... [2.546s] [675 results]
2018-05-31 01:29:42,866 -> I.Getting expansions... [0.176s] [1813 results]
2018-05-31 01:29:43,013 -> J.Finding maximal disks... [0.147s] [212 results]
2018-05-31 01:29:45,012 -> K.Prunning duplicates and subsets... [1.999s] [210 results]
2018-05-31 01:29:45,012 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:29:45,012 ->   berlin0-10,   18546,  30.0,    28,  4,  32.97,    5802,     11604,          675,        210,  9
2018-05-31 01:29:45,365 -> Dropping indices...[0.353s]
2018-05-31 01:29:45,658 -> 2.Set of disks for t_i+delta...                    |  33.65s |    231 disks
2018-05-31 01:29:53,200 -> 3.Joining timestams                                |   7.54s |    277 candidates
2018-05-31 01:30:02,772 -> Checking internal timestamps                       |   9.57s |    199 flocks
2018-05-31 01:30:09,204 -> Reporting locations at t=8...                      |   4.75s |  18546 points
2018-05-31 01:30:09,485 -> 1.Set of disks for t_i...                          |   0.28s |    219 disks
2018-05-31 01:30:14,158 -> Reporting locations at t=10...                     |   4.67s |  18546 points
2018-05-31 01:30:14,159 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=10,dataset=berlin0-10
2018-05-31 01:30:21,351 -> A.Indexing points... [7.154s] [18546 results]
2018-05-31 01:30:32,129 -> B.Getting pairs... [10.778s] [5797 results]
2018-05-31 01:30:33,394 -> C.Computing centers... [1.265s] [11594 results]
2018-05-31 01:30:34,459 -> D.Indexing centers... [1.065s] [11594 results]
2018-05-31 01:30:41,478 -> E.Getting disks... [7.019s] [11594 results]
2018-05-31 01:30:41,734 -> F.Filtering less-than-mu disks... [0.256s] [1312 results]
2018-05-31 01:30:43,875 -> G.Prunning duplicate candidates... [2.141s] [675 results]
2018-05-31 01:30:44,210 -> H.Indexing candidates... [2.476s] [675 results]
2018-05-31 01:30:44,371 -> I.Getting expansions... [0.161s] [1804 results]
2018-05-31 01:30:44,500 -> J.Finding maximal disks... [0.129s] [212 results]
2018-05-31 01:30:46,411 -> K.Prunning duplicates and subsets... [1.911s] [211 results]
2018-05-31 01:30:46,411 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:30:46,411 ->   berlin0-10,   18546,  30.0,    28,  4,  32.21,    5797,     11594,          675,        211, 10
2018-05-31 01:30:46,814 -> Dropping indices...[0.403s]
2018-05-31 01:30:47,097 -> 2.Set of disks for t_i+delta...                    |  32.94s |    219 disks
2018-05-31 01:30:55,023 -> 3.Joining timestams                                |   7.93s |    277 candidates
2018-05-31 01:31:04,026 -> Checking internal timestamps                       |   9.00s |    196 flocks
2018-05-31 01:31:05,944 -> 

PFLOCK_ML	30.0	4	3	1868

2018-05-31 01:31:07,735 -> Running MergeLast...                               | 577.23s |   1868 flocks
2018-05-31 01:31:07,735 -> method=MergeLast,cores=28,epsilon=30.0,mu=4,delta=3,time=577.23,master=spark://169.235.27.134:7077
2018-05-31 01:31:07,736 -> Closing app...
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack15: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
FLOCKFINDER=MergeLast;TIME=Thu May 31 01:31:09 PDT 2018;RUN=1527754873;NODES=4;ESTART=;EEND=;ESTEP=;MU=4;DELTA=;SCRIPT=DeltaBenchmarker;EVENT=End
FLOCKFINDER=SpatialJoin;TIME=Thu May 31 01:31:09 PDT 2018;RUN=1527755469;NODES=4;ESTART=;EEND=;ESTEP=;MU=4;DELTA=;SCRIPT=DeltaBenchmarker;EVENT=Start
WARNING:root:Setting 4 nodes...
acald013@dblab-rack15: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack11: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack14: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack12: no org.apache.spark.deploy.worker.Worker to stop
no org.apache.spark.deploy.master.Master to stop
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack15: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack15.out
WARNING:root:4 nodes has been set...
2018-05-31 01:31:16,482 -> Starting app...
2018-05-31 01:31:19,313 -> Starting session                                   |   2.83s |      0 
2018-05-31 01:31:19,326 -> Setting paramaters                                 |   0.01s |      0 
2018-05-31 01:31:22,504 -> Reading data                                       |   3.18s | 203106 points
2018-05-31 01:31:25,758 -> Extracting timestamps                              |   3.25s |     11 timestamps
2018-05-31 01:31:25,763 -> === SpatialJoin Start ===
2018-05-31 01:31:31,383 -> Reporting locations...                             |   5.36s |  18093 points
2018-05-31 01:31:31,395 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=0,dataset=berlin0-10
2018-05-31 01:31:39,890 -> A.Indexing points... [8.461s] [18093 results]
2018-05-31 01:31:46,976 -> B.Getting pairs... [7.086s] [5511 results]
2018-05-31 01:31:49,120 -> C.Computing centers... [2.144s] [11022 results]
2018-05-31 01:31:50,394 -> D.Indexing centers... [1.274s] [11022 results]
2018-05-31 01:31:55,697 -> E.Getting disks... [5.303s] [11022 results]
2018-05-31 01:31:56,134 -> F.Filtering less-than-mu disks... [0.437s] [1210 results]
2018-05-31 01:31:58,689 -> G.Prunning duplicate candidates... [2.555s] [599 results]
2018-05-31 01:31:59,152 -> H.Indexing candidates... [3.018s] [599 results]
2018-05-31 01:31:59,370 -> I.Getting expansions... [0.218s] [1657 results]
2018-05-31 01:32:00,011 -> J.Finding maximal disks... [0.641s] [206 results]
2018-05-31 01:32:01,989 -> K.Prunning duplicates and subsets... [1.978s] [205 results]
2018-05-31 01:32:01,989 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:32:01,989 ->   berlin0-10,   18093,  30.0,    28,  4,  30.56,    5511,     11022,          599,        205,  0
2018-05-31 01:32:02,064 -> Dropping indices...[0.075s]
2018-05-31 01:32:02,415 -> 1.Set of disks for t_i...                          |  31.03s |    205 disks
2018-05-31 01:32:02,797 -> 4.Found flocks...                                  |   0.38s |      0 flocks
2018-05-31 01:32:03,548 -> 5.Updating times...                                |   0.46s |    205 flocks
2018-05-31 01:32:04,443 -> 6.Filter phase...                                  |   0.90s |    205 flocks
2018-05-31 01:32:09,637 -> Reporting locations...                             |   5.19s |  18245 points
2018-05-31 01:32:09,637 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=1,dataset=berlin0-10
2018-05-31 01:32:14,146 -> A.Indexing points... [4.491s] [18245 results]
2018-05-31 01:32:19,270 -> B.Getting pairs... [5.123s] [5629 results]
2018-05-31 01:32:20,702 -> C.Computing centers... [1.432s] [11258 results]
2018-05-31 01:32:21,852 -> D.Indexing centers... [1.150s] [11258 results]
2018-05-31 01:32:27,439 -> E.Getting disks... [5.587s] [11258 results]
2018-05-31 01:32:27,727 -> F.Filtering less-than-mu disks... [0.288s] [1299 results]
2018-05-31 01:32:29,170 -> G.Prunning duplicate candidates... [1.443s] [640 results]
2018-05-31 01:32:29,509 -> H.Indexing candidates... [1.782s] [640 results]
2018-05-31 01:32:29,695 -> I.Getting expansions... [0.186s] [1703 results]
2018-05-31 01:32:30,025 -> J.Finding maximal disks... [0.330s] [220 results]
2018-05-31 01:32:31,740 -> K.Prunning duplicates and subsets... [1.715s] [216 results]
2018-05-31 01:32:31,740 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:32:31,740 ->   berlin0-10,   18245,  30.0,    28,  4,  22.09,    5629,     11258,          640,        216,  1
2018-05-31 01:32:31,836 -> Dropping indices...[0.096s]
2018-05-31 01:32:32,097 -> 1.Set of disks for t_i...                          |  22.46s |    216 disks
2018-05-31 01:32:35,542 -> 2.Distance Join phase...                           |   3.45s |    486 combinations
2018-05-31 01:32:38,629 -> 3.Getting candidates...                            |   3.09s |    196 candidates
2018-05-31 01:32:39,418 -> 4.Found flocks...                                  |   0.79s |    196 flocks
2018-05-31 01:32:41,909 -> 5.Updating times...                                |   1.52s |    196 flocks
2018-05-31 01:32:44,460 -> 6.Filter phase...                                  |   2.55s |    236 flocks
2018-05-31 01:32:49,325 -> Reporting locations...                             |   4.87s |  18394 points
2018-05-31 01:32:49,325 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=2,dataset=berlin0-10
2018-05-31 01:32:53,289 -> A.Indexing points... [3.950s] [18394 results]
2018-05-31 01:32:58,149 -> B.Getting pairs... [4.860s] [5701 results]
2018-05-31 01:32:59,488 -> C.Computing centers... [1.339s] [11402 results]
2018-05-31 01:33:00,351 -> D.Indexing centers... [0.863s] [11402 results]
2018-05-31 01:33:04,749 -> E.Getting disks... [4.398s] [11402 results]
2018-05-31 01:33:04,992 -> F.Filtering less-than-mu disks... [0.243s] [1336 results]
2018-05-31 01:33:06,330 -> G.Prunning duplicate candidates... [1.338s] [658 results]
2018-05-31 01:33:06,634 -> H.Indexing candidates... [1.642s] [658 results]
2018-05-31 01:33:06,794 -> I.Getting expansions... [0.160s] [1757 results]
2018-05-31 01:33:06,950 -> J.Finding maximal disks... [0.156s] [232 results]
2018-05-31 01:33:08,085 -> K.Prunning duplicates and subsets... [1.135s] [227 results]
2018-05-31 01:33:08,085 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:33:08,085 ->   berlin0-10,   18394,  30.0,    28,  4,  18.75,    5701,     11402,          658,        227,  2
2018-05-31 01:33:08,204 -> Dropping indices...[0.119s]
2018-05-31 01:33:08,461 -> 1.Set of disks for t_i...                          |  19.14s |    227 disks
2018-05-31 01:33:15,130 -> 2.Distance Join phase...                           |   6.67s |    648 combinations
2018-05-31 01:33:19,356 -> 3.Getting candidates...                            |   4.23s |    218 candidates
2018-05-31 01:33:20,063 -> 4.Found flocks...                                  |   0.71s |    218 flocks
2018-05-31 01:33:22,554 -> 5.Updating times...                                |   1.10s |    218 flocks
2018-05-31 01:33:24,343 -> 6.Filter phase...                                  |   1.79s |    248 flocks
2018-05-31 01:33:29,016 -> Reporting locations...                             |   4.67s |  18548 points
2018-05-31 01:33:29,016 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=3,dataset=berlin0-10
2018-05-31 01:33:36,607 -> A.Indexing points... [7.580s] [18548 results]
2018-05-31 01:33:47,210 -> B.Getting pairs... [10.603s] [5768 results]
2018-05-31 01:33:48,558 -> C.Computing centers... [1.348s] [11536 results]
2018-05-31 01:33:49,453 -> D.Indexing centers... [0.895s] [11536 results]
2018-05-31 01:33:57,045 -> E.Getting disks... [7.592s] [11536 results]
2018-05-31 01:33:57,265 -> F.Filtering less-than-mu disks... [0.220s] [1349 results]
2018-05-31 01:33:59,461 -> G.Prunning duplicate candidates... [2.196s] [675 results]
2018-05-31 01:33:59,752 -> H.Indexing candidates... [2.487s] [675 results]
2018-05-31 01:33:59,909 -> I.Getting expansions... [0.157s] [1875 results]
2018-05-31 01:34:00,064 -> J.Finding maximal disks... [0.154s] [230 results]
2018-05-31 01:34:02,505 -> K.Prunning duplicates and subsets... [2.441s] [225 results]
2018-05-31 01:34:02,505 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:34:02,505 ->   berlin0-10,   18548,  30.0,    28,  4,  33.48,    5768,     11536,          675,        225,  3
2018-05-31 01:34:02,690 -> Dropping indices...[0.185s]
2018-05-31 01:34:02,963 -> 1.Set of disks for t_i...                          |  33.95s |    225 disks
2018-05-31 01:34:09,219 -> 2.Distance Join phase...                           |   6.26s |    671 combinations
2018-05-31 01:34:13,253 -> 3.Getting candidates...                            |   4.03s |    220 candidates
2018-05-31 01:34:14,051 -> 4.Found flocks...                                  |   0.80s |    220 flocks
2018-05-31 01:34:17,287 -> 5.Updating times...                                |   1.35s |    220 flocks
2018-05-31 01:34:19,263 -> 6.Filter phase...                                  |   1.98s |    250 flocks
2018-05-31 01:34:23,986 -> Reporting locations...                             |   4.72s |  18548 points
2018-05-31 01:34:23,987 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=4,dataset=berlin0-10
2018-05-31 01:34:31,914 -> A.Indexing points... [7.909s] [18548 results]
2018-05-31 01:34:42,578 -> B.Getting pairs... [10.664s] [5775 results]
2018-05-31 01:34:43,813 -> C.Computing centers... [1.235s] [11550 results]
2018-05-31 01:34:44,801 -> D.Indexing centers... [0.988s] [11550 results]
2018-05-31 01:34:51,822 -> E.Getting disks... [7.021s] [11550 results]
2018-05-31 01:34:52,043 -> F.Filtering less-than-mu disks... [0.220s] [1369 results]
2018-05-31 01:34:54,016 -> G.Prunning duplicate candidates... [1.973s] [694 results]
2018-05-31 01:34:54,308 -> H.Indexing candidates... [2.265s] [694 results]
2018-05-31 01:34:54,455 -> I.Getting expansions... [0.147s] [1914 results]
2018-05-31 01:34:54,593 -> J.Finding maximal disks... [0.138s] [245 results]
2018-05-31 01:34:56,472 -> K.Prunning duplicates and subsets... [1.879s] [238 results]
2018-05-31 01:34:56,472 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:34:56,472 ->   berlin0-10,   18548,  30.0,    28,  4,  32.47,    5775,     11550,          694,        238,  4
2018-05-31 01:34:56,732 -> Dropping indices...[0.260s]
2018-05-31 01:34:57,036 -> 1.Set of disks for t_i...                          |  33.05s |    238 disks
2018-05-31 01:35:03,979 -> 2.Distance Join phase...                           |   6.94s |    701 combinations
2018-05-31 01:35:08,246 -> 3.Getting candidates...                            |   4.27s |    224 candidates
2018-05-31 01:35:09,255 -> 4.Found flocks...                                  |   1.01s |    224 flocks
2018-05-31 01:35:13,220 -> 5.Updating times...                                |   1.39s |    224 flocks
2018-05-31 01:35:15,567 -> 6.Filter phase...                                  |   2.35s |    249 flocks
2018-05-31 01:35:20,308 -> Reporting locations...                             |   4.74s |  18548 points
2018-05-31 01:35:20,308 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=5,dataset=berlin0-10
2018-05-31 01:35:27,838 -> A.Indexing points... [7.513s] [18548 results]
2018-05-31 01:35:38,539 -> B.Getting pairs... [10.701s] [5765 results]
2018-05-31 01:35:39,785 -> C.Computing centers... [1.246s] [11530 results]
2018-05-31 01:35:40,677 -> D.Indexing centers... [0.892s] [11530 results]
2018-05-31 01:35:47,556 -> E.Getting disks... [6.879s] [11530 results]
2018-05-31 01:35:47,761 -> F.Filtering less-than-mu disks... [0.205s] [1362 results]
2018-05-31 01:35:49,842 -> G.Prunning duplicate candidates... [2.081s] [686 results]
2018-05-31 01:35:50,148 -> H.Indexing candidates... [2.387s] [686 results]
2018-05-31 01:35:50,308 -> I.Getting expansions... [0.160s] [1917 results]
2018-05-31 01:35:50,480 -> J.Finding maximal disks... [0.140s] [237 results]
2018-05-31 01:35:52,462 -> K.Prunning duplicates and subsets... [1.982s] [234 results]
2018-05-31 01:35:52,462 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:35:52,462 ->   berlin0-10,   18548,  30.0,    28,  4,  32.14,    5765,     11530,          686,        234,  5
2018-05-31 01:35:52,762 -> Dropping indices...[0.300s]
2018-05-31 01:35:52,988 -> 1.Set of disks for t_i...                          |  32.68s |    234 disks
2018-05-31 01:36:00,482 -> 2.Distance Join phase...                           |   7.49s |    630 combinations
2018-05-31 01:36:05,213 -> 3.Getting candidates...                            |   4.73s |    230 candidates
2018-05-31 01:36:06,262 -> 4.Found flocks...                                  |   1.05s |    230 flocks
2018-05-31 01:36:10,962 -> 5.Updating times...                                |   1.46s |    230 flocks
2018-05-31 01:36:13,153 -> 6.Filter phase...                                  |   2.19s |    259 flocks
2018-05-31 01:36:17,828 -> Reporting locations...                             |   4.68s |  18546 points
2018-05-31 01:36:17,829 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=6,dataset=berlin0-10
2018-05-31 01:36:25,530 -> A.Indexing points... [7.685s] [18546 results]
2018-05-31 01:36:36,221 -> B.Getting pairs... [10.691s] [5758 results]
2018-05-31 01:36:37,467 -> C.Computing centers... [1.246s] [11516 results]
2018-05-31 01:36:38,343 -> D.Indexing centers... [0.876s] [11516 results]
2018-05-31 01:36:45,236 -> E.Getting disks... [6.893s] [11516 results]
2018-05-31 01:36:45,453 -> F.Filtering less-than-mu disks... [0.217s] [1346 results]
2018-05-31 01:36:47,524 -> G.Prunning duplicate candidates... [2.071s] [681 results]
2018-05-31 01:36:47,831 -> H.Indexing candidates... [2.378s] [681 results]
2018-05-31 01:36:47,981 -> I.Getting expansions... [0.150s] [1951 results]
2018-05-31 01:36:48,114 -> J.Finding maximal disks... [0.133s] [225 results]
2018-05-31 01:36:50,081 -> K.Prunning duplicates and subsets... [1.967s] [222 results]
2018-05-31 01:36:50,081 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:36:50,081 ->   berlin0-10,   18546,  30.0,    28,  4,  32.24,    5758,     11516,          681,        222,  6
2018-05-31 01:36:50,493 -> Dropping indices...[0.412s]
2018-05-31 01:36:50,736 -> 1.Set of disks for t_i...                          |  32.91s |    222 disks
2018-05-31 01:36:58,899 -> 2.Distance Join phase...                           |   8.16s |    619 combinations
2018-05-31 01:37:04,019 -> 3.Getting candidates...                            |   5.12s |    224 candidates
2018-05-31 01:37:05,132 -> 4.Found flocks...                                  |   1.11s |    224 flocks
2018-05-31 01:37:10,485 -> 5.Updating times...                                |   1.56s |    224 flocks
2018-05-31 01:37:12,897 -> 6.Filter phase...                                  |   2.41s |    247 flocks
2018-05-31 01:37:17,688 -> Reporting locations...                             |   4.79s |  18546 points
2018-05-31 01:37:17,688 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=7,dataset=berlin0-10
2018-05-31 01:37:26,851 -> A.Indexing points... [9.147s] [18546 results]
2018-05-31 01:37:37,574 -> B.Getting pairs... [10.722s] [5788 results]
2018-05-31 01:37:38,856 -> C.Computing centers... [1.282s] [11576 results]
2018-05-31 01:37:39,759 -> D.Indexing centers... [0.903s] [11576 results]
2018-05-31 01:37:46,842 -> E.Getting disks... [7.083s] [11576 results]
2018-05-31 01:37:47,089 -> F.Filtering less-than-mu disks... [0.247s] [1361 results]
2018-05-31 01:37:49,183 -> G.Prunning duplicate candidates... [2.093s] [688 results]
2018-05-31 01:37:49,483 -> H.Indexing candidates... [2.393s] [688 results]
2018-05-31 01:37:49,633 -> I.Getting expansions... [0.150s] [1882 results]
2018-05-31 01:37:49,765 -> J.Finding maximal disks... [0.132s] [233 results]
2018-05-31 01:37:51,925 -> K.Prunning duplicates and subsets... [2.160s] [231 results]
2018-05-31 01:37:51,925 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:37:51,925 ->   berlin0-10,   18546,  30.0,    28,  4,  34.22,    5788,     11576,          688,        231,  7
2018-05-31 01:37:52,381 -> Dropping indices...[0.455s]
2018-05-31 01:37:52,610 -> 1.Set of disks for t_i...                          |  34.92s |    231 disks
2018-05-31 01:38:01,162 -> 2.Distance Join phase...                           |   8.55s |    597 combinations
2018-05-31 01:38:05,858 -> 3.Getting candidates...                            |   4.70s |    213 candidates
2018-05-31 01:38:07,114 -> 4.Found flocks...                                  |   1.26s |    213 flocks
2018-05-31 01:38:13,290 -> 5.Updating times...                                |   1.62s |    213 flocks
2018-05-31 01:38:15,585 -> 6.Filter phase...                                  |   2.30s |    244 flocks
2018-05-31 01:38:20,189 -> Reporting locations...                             |   4.60s |  18546 points
2018-05-31 01:38:20,190 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=8,dataset=berlin0-10
2018-05-31 01:38:25,436 -> A.Indexing points... [5.230s] [18546 results]
2018-05-31 01:38:31,896 -> B.Getting pairs... [6.460s] [5791 results]
2018-05-31 01:38:33,272 -> C.Computing centers... [1.375s] [11582 results]
2018-05-31 01:38:34,196 -> D.Indexing centers... [0.924s] [11582 results]
2018-05-31 01:38:39,681 -> E.Getting disks... [5.485s] [11582 results]
2018-05-31 01:38:40,020 -> F.Filtering less-than-mu disks... [0.338s] [1316 results]
2018-05-31 01:38:41,841 -> G.Prunning duplicate candidates... [1.821s] [670 results]
2018-05-31 01:38:42,135 -> H.Indexing candidates... [2.115s] [670 results]
2018-05-31 01:38:42,337 -> I.Getting expansions... [0.202s] [1792 results]
2018-05-31 01:38:42,477 -> J.Finding maximal disks... [0.140s] [220 results]
2018-05-31 01:38:43,930 -> K.Prunning duplicates and subsets... [1.452s] [219 results]
2018-05-31 01:38:43,930 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:38:43,930 ->   berlin0-10,   18546,  30.0,    28,  4,  23.72,    5791,     11582,          670,        219,  8
2018-05-31 01:38:44,510 -> Dropping indices...[0.580s]
2018-05-31 01:38:44,789 -> 1.Set of disks for t_i...                          |  24.60s |    219 disks
2018-05-31 01:38:53,606 -> 2.Distance Join phase...                           |   8.82s |    520 combinations
2018-05-31 01:38:58,548 -> 3.Getting candidates...                            |   4.94s |    211 candidates
2018-05-31 01:38:59,916 -> 4.Found flocks...                                  |   1.37s |    211 flocks
2018-05-31 01:39:06,717 -> 5.Updating times...                                |   1.83s |    211 flocks
2018-05-31 01:39:09,532 -> 6.Filter phase...                                  |   2.82s |    232 flocks
2018-05-31 01:39:14,160 -> Reporting locations...                             |   4.63s |  18546 points
2018-05-31 01:39:14,161 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=9,dataset=berlin0-10
2018-05-31 01:39:21,353 -> A.Indexing points... [7.157s] [18546 results]
2018-05-31 01:39:31,481 -> B.Getting pairs... [10.128s] [5802 results]
2018-05-31 01:39:32,865 -> C.Computing centers... [1.384s] [11604 results]
2018-05-31 01:39:33,785 -> D.Indexing centers... [0.920s] [11604 results]
2018-05-31 01:39:40,595 -> E.Getting disks... [6.810s] [11604 results]
2018-05-31 01:39:40,801 -> F.Filtering less-than-mu disks... [0.206s] [1306 results]
2018-05-31 01:39:42,971 -> G.Prunning duplicate candidates... [2.170s] [675 results]
2018-05-31 01:39:43,301 -> H.Indexing candidates... [2.500s] [675 results]
2018-05-31 01:39:43,449 -> I.Getting expansions... [0.148s] [1813 results]
2018-05-31 01:39:43,580 -> J.Finding maximal disks... [0.131s] [212 results]
2018-05-31 01:39:45,475 -> K.Prunning duplicates and subsets... [1.895s] [210 results]
2018-05-31 01:39:45,475 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:39:45,475 ->   berlin0-10,   18546,  30.0,    28,  4,  31.28,    5802,     11604,          675,        210,  9
2018-05-31 01:39:46,128 -> Dropping indices...[0.653s]
2018-05-31 01:39:46,431 -> 1.Set of disks for t_i...                          |  32.27s |    210 disks
2018-05-31 01:39:56,046 -> 2.Distance Join phase...                           |   9.62s |    474 combinations
2018-05-31 01:40:02,653 -> 3.Getting candidates...                            |   6.61s |    206 candidates
2018-05-31 01:40:04,310 -> 4.Found flocks...                                  |   1.66s |    206 flocks
2018-05-31 01:40:12,753 -> 5.Updating times...                                |   2.31s |    206 flocks
2018-05-31 01:40:16,020 -> 6.Filter phase...                                  |   3.27s |    226 flocks
2018-05-31 01:40:20,669 -> Reporting locations...                             |   4.65s |  18546 points
2018-05-31 01:40:20,669 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=10,dataset=berlin0-10
2018-05-31 01:40:27,947 -> A.Indexing points... [7.243s] [18546 results]
2018-05-31 01:40:37,997 -> B.Getting pairs... [10.050s] [5797 results]
2018-05-31 01:40:39,287 -> C.Computing centers... [1.290s] [11594 results]
2018-05-31 01:40:40,201 -> D.Indexing centers... [0.914s] [11594 results]
2018-05-31 01:40:47,035 -> E.Getting disks... [6.834s] [11594 results]
2018-05-31 01:40:47,291 -> F.Filtering less-than-mu disks... [0.256s] [1312 results]
2018-05-31 01:40:49,720 -> G.Prunning duplicate candidates... [2.429s] [675 results]
2018-05-31 01:40:50,024 -> H.Indexing candidates... [2.733s] [675 results]
2018-05-31 01:40:50,195 -> I.Getting expansions... [0.171s] [1804 results]
2018-05-31 01:40:50,330 -> J.Finding maximal disks... [0.135s] [212 results]
2018-05-31 01:40:52,290 -> K.Prunning duplicates and subsets... [1.960s] [211 results]
2018-05-31 01:40:52,290 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:40:52,290 ->   berlin0-10,   18546,  30.0,    28,  4,  31.59,    5797,     11594,          675,        211, 10
2018-05-31 01:40:52,985 -> Dropping indices...[0.694s]
2018-05-31 01:40:53,264 -> 1.Set of disks for t_i...                          |  32.60s |    211 disks
2018-05-31 01:41:04,075 -> 2.Distance Join phase...                           |  10.81s |    458 combinations
2018-05-31 01:41:09,930 -> 3.Getting candidates...                            |   5.86s |    197 candidates
2018-05-31 01:41:11,485 -> 4.Found flocks...                                  |   1.56s |    197 flocks
2018-05-31 01:41:20,136 -> 5.Updating times...                                |   1.90s |    197 flocks
2018-05-31 01:41:22,681 -> 6.Filter phase...                                  |   2.54s |    221 flocks
2018-05-31 01:41:22,681 -> 

PFLOCK_SJ	30.0	4	2	2139

2018-05-31 01:41:28,383 -> Running SpatialJoin...                             | 602.62s |   2139 flocks
2018-05-31 01:41:28,383 -> method=SpatialJoin,cores=28,epsilon=30.0,mu=4,delta=2,time=602.62,master=spark://169.235.27.134:7077
2018-05-31 01:41:28,383 -> Closing app...
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack15: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
FLOCKFINDER=SpatialJoin;TIME=Thu May 31 01:41:29 PDT 2018;RUN=1527755469;NODES=4;ESTART=;EEND=;ESTEP=;MU=4;DELTA=;SCRIPT=DeltaBenchmarker;EVENT=End
FLOCKFINDER=MergeLast;TIME=Thu May 31 01:41:29 PDT 2018;RUN=1527756089;NODES=4;ESTART=;EEND=;ESTEP=;MU=4;DELTA=;SCRIPT=DeltaBenchmarker;EVENT=Start
WARNING:root:Setting 4 nodes...
acald013@dblab-rack15: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack14: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack12: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack11: no org.apache.spark.deploy.worker.Worker to stop
no org.apache.spark.deploy.master.Master to stop
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack15: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack15.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
WARNING:root:4 nodes has been set...
2018-05-31 01:41:36,796 -> Starting app...
2018-05-31 01:41:39,622 -> Starting session                                   |   2.83s |      0 
2018-05-31 01:41:39,633 -> Setting paramaters                                 |   0.01s |      0 
2018-05-31 01:41:42,773 -> Reading data                                       |   3.14s | 203106 points
2018-05-31 01:41:45,980 -> Extracting timestamps                              |   3.21s |     11 timestamps
2018-05-31 01:41:45,989 -> === MergeLast Start ===
2018-05-31 01:41:51,358 -> Reporting locations at t=0...                      |   5.15s |  18093 points
2018-05-31 01:41:51,376 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=0,dataset=berlin0-10
2018-05-31 01:41:59,581 -> A.Indexing points... [8.161s] [18093 results]
2018-05-31 01:42:07,070 -> B.Getting pairs... [7.489s] [5511 results]
2018-05-31 01:42:09,313 -> C.Computing centers... [2.243s] [11022 results]
2018-05-31 01:42:10,728 -> D.Indexing centers... [1.415s] [11022 results]
2018-05-31 01:42:16,076 -> E.Getting disks... [5.348s] [11022 results]
2018-05-31 01:42:16,440 -> F.Filtering less-than-mu disks... [0.364s] [1210 results]
2018-05-31 01:42:19,095 -> G.Prunning duplicate candidates... [2.655s] [599 results]
2018-05-31 01:42:19,584 -> H.Indexing candidates... [3.144s] [599 results]
2018-05-31 01:42:19,811 -> I.Getting expansions... [0.227s] [1657 results]
2018-05-31 01:42:20,479 -> J.Finding maximal disks... [0.668s] [206 results]
2018-05-31 01:42:22,858 -> K.Prunning duplicates and subsets... [2.379s] [205 results]
2018-05-31 01:42:22,859 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:42:22,859 ->   berlin0-10,   18093,  30.0,    28,  4,  31.44,    5511,     11022,          599,        205,  0
2018-05-31 01:42:22,933 -> Dropping indices...[0.074s]
2018-05-31 01:42:23,245 -> 1.Set of disks for t_i...                          |  31.89s |    205 disks
2018-05-31 01:42:29,002 -> Reporting locations at t=1...                      |   5.76s |  18245 points
2018-05-31 01:42:29,003 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=1,dataset=berlin0-10
2018-05-31 01:42:34,035 -> A.Indexing points... [5.010s] [18245 results]
2018-05-31 01:42:39,269 -> B.Getting pairs... [5.234s] [5629 results]
2018-05-31 01:42:40,830 -> C.Computing centers... [1.561s] [11258 results]
2018-05-31 01:42:41,858 -> D.Indexing centers... [1.027s] [11258 results]
2018-05-31 01:42:46,629 -> E.Getting disks... [4.771s] [11258 results]
2018-05-31 01:42:46,889 -> F.Filtering less-than-mu disks... [0.260s] [1299 results]
2018-05-31 01:42:48,365 -> G.Prunning duplicate candidates... [1.475s] [640 results]
2018-05-31 01:42:48,695 -> H.Indexing candidates... [1.806s] [640 results]
2018-05-31 01:42:48,859 -> I.Getting expansions... [0.164s] [1703 results]
2018-05-31 01:42:49,050 -> J.Finding maximal disks... [0.191s] [220 results]
2018-05-31 01:42:50,238 -> K.Prunning duplicates and subsets... [1.188s] [216 results]
2018-05-31 01:42:50,238 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:42:50,238 ->   berlin0-10,   18245,  30.0,    28,  4,  21.21,    5629,     11258,          640,        216,  1
2018-05-31 01:42:50,323 -> Dropping indices...[0.085s]
2018-05-31 01:42:50,633 -> 2.Set of disks for t_i+delta...                    |  21.63s |    205 disks
2018-05-31 01:42:58,638 -> 3.Joining timestams                                |   8.01s |    319 candidates
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 16 in stage 1467.0 failed 4 times, most recent failure: Lost task 16.3 in stage 1467.0 (TID 66158, 169.235.27.137, executor 1): java.util.NoSuchElementException: head of empty list
	at scala.collection.immutable.Nil$.head(List.scala:420)
	at scala.collection.immutable.Nil$.head(List.scala:417)
	at scala.collection.generic.TraversableForwarder$class.head(TraversableForwarder.scala:56)
	at scala.collection.mutable.ListBuffer.head(ListBuffer.scala:45)
	at FlockFinderMergeLast$.computeMaximalDisks(FlockFinderMergeLast.scala:277)
	at FlockFinderMergeLast$$anonfun$runMergeLast$1$$anonfun$13.apply(FlockFinderMergeLast.scala:221)
	at FlockFinderMergeLast$$anonfun$runMergeLast$1$$anonfun$13.apply(FlockFinderMergeLast.scala:219)
	at org.apache.spark.sql.execution.MapElementsExec$$anonfun$8$$anonfun$apply$1.apply(objects.scala:237)
	at org.apache.spark.sql.execution.MapElementsExec$$anonfun$8$$anonfun$apply$1.apply(objects.scala:237)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.columnar.InMemoryRelation$$anonfun$1$$anon$1.hasNext(InMemoryRelation.scala:138)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:215)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:957)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:948)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:888)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:948)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:694)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:334)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1958)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:935)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:934)
	at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:275)
	at org.apache.spark.sql.Dataset$$anonfun$org$apache$spark$sql$Dataset$$execute$1$1.apply(Dataset.scala:2371)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:57)
	at org.apache.spark.sql.Dataset.withNewExecutionId(Dataset.scala:2765)
	at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$execute$1(Dataset.scala:2370)
	at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collect(Dataset.scala:2377)
	at org.apache.spark.sql.Dataset$$anonfun$count$1.apply(Dataset.scala:2405)
	at org.apache.spark.sql.Dataset$$anonfun$count$1.apply(Dataset.scala:2404)
	at org.apache.spark.sql.Dataset.withCallback(Dataset.scala:2778)
	at org.apache.spark.sql.Dataset.count(Dataset.scala:2404)
	at FlockFinderMergeLast$$anonfun$runMergeLast$1.apply(FlockFinderMergeLast.scala:228)
	at FlockFinderMergeLast$$anonfun$runMergeLast$1.apply(FlockFinderMergeLast.scala:121)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at FlockFinderMergeLast$.runMergeLast(FlockFinderMergeLast.scala:121)
	at FlockFinderMergeLast$$anonfun$run$1$$anonfun$apply$mcVI$sp$1$$anonfun$apply$mcVI$sp$2.apply$mcVD$sp(FlockFinderMergeLast.scala:91)
	at FlockFinderMergeLast$$anonfun$run$1$$anonfun$apply$mcVI$sp$1$$anonfun$apply$mcVI$sp$2.apply(FlockFinderMergeLast.scala:86)
	at FlockFinderMergeLast$$anonfun$run$1$$anonfun$apply$mcVI$sp$1$$anonfun$apply$mcVI$sp$2.apply(FlockFinderMergeLast.scala:86)
	at scala.collection.immutable.NumericRange.foreach(NumericRange.scala:73)
	at FlockFinderMergeLast$$anonfun$run$1$$anonfun$apply$mcVI$sp$1.apply$mcVI$sp(FlockFinderMergeLast.scala:86)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at FlockFinderMergeLast$$anonfun$run$1.apply$mcVI$sp(FlockFinderMergeLast.scala:86)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at FlockFinderMergeLast$.run(FlockFinderMergeLast.scala:86)
	at FlockFinderMergeLast$.main(FlockFinderMergeLast.scala:585)
	at FlockFinderMergeLast.main(FlockFinderMergeLast.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: java.util.NoSuchElementException: head of empty list
	at scala.collection.immutable.Nil$.head(List.scala:420)
	at scala.collection.immutable.Nil$.head(List.scala:417)
	at scala.collection.generic.TraversableForwarder$class.head(TraversableForwarder.scala:56)
	at scala.collection.mutable.ListBuffer.head(ListBuffer.scala:45)
	at FlockFinderMergeLast$.computeMaximalDisks(FlockFinderMergeLast.scala:277)
	at FlockFinderMergeLast$$anonfun$runMergeLast$1$$anonfun$13.apply(FlockFinderMergeLast.scala:221)
	at FlockFinderMergeLast$$anonfun$runMergeLast$1$$anonfun$13.apply(FlockFinderMergeLast.scala:219)
	at org.apache.spark.sql.execution.MapElementsExec$$anonfun$8$$anonfun$apply$1.apply(objects.scala:237)
	at org.apache.spark.sql.execution.MapElementsExec$$anonfun$8$$anonfun$apply$1.apply(objects.scala:237)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.columnar.InMemoryRelation$$anonfun$1$$anon$1.hasNext(InMemoryRelation.scala:138)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:215)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:957)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:948)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:888)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:948)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:694)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:334)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack15: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
FLOCKFINDER=MergeLast;TIME=Thu May 31 01:43:09 PDT 2018;RUN=1527756089;NODES=4;ESTART=;EEND=;ESTEP=;MU=4;DELTA=;SCRIPT=DeltaBenchmarker;EVENT=End
FLOCKFINDER=SpatialJoin;TIME=Thu May 31 01:43:09 PDT 2018;RUN=1527756189;NODES=4;ESTART=;EEND=;ESTEP=;MU=4;DELTA=;SCRIPT=DeltaBenchmarker;EVENT=Start
WARNING:root:Setting 4 nodes...
acald013@dblab-rack12: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack15: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack11: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack14: no org.apache.spark.deploy.worker.Worker to stop
no org.apache.spark.deploy.master.Master to stop
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack15: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack15.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
WARNING:root:4 nodes has been set...
2018-05-31 01:43:16,798 -> Starting app...
2018-05-31 01:43:19,461 -> Starting session                                   |   2.66s |      0 
2018-05-31 01:43:19,477 -> Setting paramaters                                 |   0.02s |      0 
2018-05-31 01:43:22,752 -> Reading data                                       |   3.28s | 203106 points
2018-05-31 01:43:26,050 -> Extracting timestamps                              |   3.30s |     11 timestamps
2018-05-31 01:43:26,055 -> === SpatialJoin Start ===
2018-05-31 01:43:31,414 -> Reporting locations...                             |   5.17s |  18093 points
2018-05-31 01:43:31,430 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=0,dataset=berlin0-10
2018-05-31 01:43:40,128 -> A.Indexing points... [8.654s] [18093 results]
2018-05-31 01:43:48,072 -> B.Getting pairs... [7.943s] [5511 results]
2018-05-31 01:43:50,102 -> C.Computing centers... [2.030s] [11022 results]
2018-05-31 01:43:51,733 -> D.Indexing centers... [1.631s] [11022 results]
2018-05-31 01:43:57,304 -> E.Getting disks... [5.571s] [11022 results]
2018-05-31 01:43:57,718 -> F.Filtering less-than-mu disks... [0.414s] [1210 results]
2018-05-31 01:44:00,093 -> G.Prunning duplicate candidates... [2.374s] [599 results]
2018-05-31 01:44:00,594 -> H.Indexing candidates... [2.875s] [599 results]
2018-05-31 01:44:00,861 -> I.Getting expansions... [0.267s] [1657 results]
2018-05-31 01:44:01,506 -> J.Finding maximal disks... [0.645s] [206 results]
2018-05-31 01:44:03,366 -> K.Prunning duplicates and subsets... [1.860s] [205 results]
2018-05-31 01:44:03,366 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:44:03,366 ->   berlin0-10,   18093,  30.0,    28,  4,  31.89,    5511,     11022,          599,        205,  0
2018-05-31 01:44:03,445 -> Dropping indices...[0.079s]
2018-05-31 01:44:03,754 -> 1.Set of disks for t_i...                          |  32.34s |    205 disks
2018-05-31 01:44:04,157 -> 4.Found flocks...                                  |   0.40s |      0 flocks
2018-05-31 01:44:04,963 -> 5.Updating times...                                |   0.49s |    205 flocks
2018-05-31 01:44:05,871 -> 6.Filter phase...                                  |   0.91s |    205 flocks
2018-05-31 01:44:11,241 -> Reporting locations...                             |   5.37s |  18245 points
2018-05-31 01:44:11,241 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=1,dataset=berlin0-10
2018-05-31 01:44:16,093 -> A.Indexing points... [4.832s] [18245 results]
2018-05-31 01:44:21,301 -> B.Getting pairs... [5.208s] [5629 results]
2018-05-31 01:44:22,724 -> C.Computing centers... [1.423s] [11258 results]
2018-05-31 01:44:23,744 -> D.Indexing centers... [1.020s] [11258 results]
2018-05-31 01:44:28,397 -> E.Getting disks... [4.653s] [11258 results]
2018-05-31 01:44:28,625 -> F.Filtering less-than-mu disks... [0.228s] [1299 results]
2018-05-31 01:44:29,999 -> G.Prunning duplicate candidates... [1.373s] [640 results]
2018-05-31 01:44:30,312 -> H.Indexing candidates... [1.686s] [640 results]
2018-05-31 01:44:30,466 -> I.Getting expansions... [0.154s] [1703 results]
2018-05-31 01:44:30,624 -> J.Finding maximal disks... [0.158s] [220 results]
2018-05-31 01:44:31,770 -> K.Prunning duplicates and subsets... [1.146s] [216 results]
2018-05-31 01:44:31,770 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:44:31,770 ->   berlin0-10,   18245,  30.0,    28,  4,  20.51,    5629,     11258,          640,        216,  1
2018-05-31 01:44:31,863 -> Dropping indices...[0.093s]
2018-05-31 01:44:32,143 -> 1.Set of disks for t_i...                          |  20.90s |    216 disks
2018-05-31 01:44:35,798 -> 2.Distance Join phase...                           |   3.66s |    645 combinations
2018-05-31 01:44:38,999 -> 3.Getting candidates...                            |   3.20s |    196 candidates
2018-05-31 01:44:39,734 -> 4.Found flocks...                                  |   0.74s |      0 flocks
2018-05-31 01:44:42,097 -> 5.Updating times...                                |   1.40s |    196 flocks
2018-05-31 01:44:44,811 -> 6.Filter phase...                                  |   2.71s |    236 flocks
2018-05-31 01:44:49,790 -> Reporting locations...                             |   4.98s |  18394 points
2018-05-31 01:44:49,791 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=2,dataset=berlin0-10
2018-05-31 01:44:53,969 -> A.Indexing points... [4.159s] [18394 results]
2018-05-31 01:44:58,571 -> B.Getting pairs... [4.602s] [5701 results]
2018-05-31 01:44:59,990 -> C.Computing centers... [1.419s] [11402 results]
2018-05-31 01:45:00,889 -> D.Indexing centers... [0.899s] [11402 results]
2018-05-31 01:45:05,187 -> E.Getting disks... [4.298s] [11402 results]
2018-05-31 01:45:05,425 -> F.Filtering less-than-mu disks... [0.238s] [1336 results]
2018-05-31 01:45:06,769 -> G.Prunning duplicate candidates... [1.344s] [658 results]
2018-05-31 01:45:07,083 -> H.Indexing candidates... [1.658s] [658 results]
2018-05-31 01:45:07,245 -> I.Getting expansions... [0.162s] [1757 results]
2018-05-31 01:45:07,394 -> J.Finding maximal disks... [0.149s] [232 results]
2018-05-31 01:45:08,467 -> K.Prunning duplicates and subsets... [1.073s] [227 results]
2018-05-31 01:45:08,468 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:45:08,468 ->   berlin0-10,   18394,  30.0,    28,  4,  18.66,    5701,     11402,          658,        227,  2
2018-05-31 01:45:08,640 -> Dropping indices...[0.172s]
2018-05-31 01:45:08,920 -> 1.Set of disks for t_i...                          |  19.13s |    227 disks
2018-05-31 01:45:16,301 -> 2.Distance Join phase...                           |   7.38s |    901 combinations
2018-05-31 01:45:21,443 -> 3.Getting candidates...                            |   5.14s |    239 candidates
2018-05-31 01:45:22,174 -> 4.Found flocks...                                  |   0.73s |    199 flocks
2018-05-31 01:45:25,015 -> 5.Updating times...                                |   1.26s |    239 flocks
2018-05-31 01:45:27,037 -> 6.Filter phase...                                  |   2.02s |    268 flocks
2018-05-31 01:45:32,006 -> Reporting locations...                             |   4.97s |  18548 points
2018-05-31 01:45:32,007 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=3,dataset=berlin0-10
2018-05-31 01:45:39,013 -> A.Indexing points... [6.988s] [18548 results]
2018-05-31 01:45:48,912 -> B.Getting pairs... [9.899s] [5768 results]
2018-05-31 01:45:50,266 -> C.Computing centers... [1.354s] [11536 results]
2018-05-31 01:45:51,200 -> D.Indexing centers... [0.934s] [11536 results]
2018-05-31 01:45:57,985 -> E.Getting disks... [6.785s] [11536 results]
2018-05-31 01:45:58,244 -> F.Filtering less-than-mu disks... [0.259s] [1349 results]
2018-05-31 01:46:00,373 -> G.Prunning duplicate candidates... [2.129s] [675 results]
2018-05-31 01:46:00,691 -> H.Indexing candidates... [2.447s] [675 results]
2018-05-31 01:46:00,857 -> I.Getting expansions... [0.166s] [1875 results]
2018-05-31 01:46:01,070 -> J.Finding maximal disks... [0.213s] [230 results]
2018-05-31 01:46:02,854 -> K.Prunning duplicates and subsets... [1.783s] [225 results]
2018-05-31 01:46:02,854 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:46:02,854 ->   berlin0-10,   18548,  30.0,    28,  4,  30.83,    5768,     11536,          675,        225,  3
2018-05-31 01:46:03,064 -> Dropping indices...[0.210s]
2018-05-31 01:46:03,298 -> 1.Set of disks for t_i...                          |  31.29s |    225 disks
2018-05-31 01:46:09,968 -> 2.Distance Join phase...                           |   6.67s |   1012 combinations
2018-05-31 01:46:14,364 -> 3.Getting candidates...                            |   4.40s |    242 candidates
2018-05-31 01:46:15,279 -> 4.Found flocks...                                  |   0.92s |    210 flocks
2018-05-31 01:46:18,802 -> 5.Updating times...                                |   1.33s |    242 flocks
2018-05-31 01:46:21,060 -> 6.Filter phase...                                  |   2.26s |    269 flocks
2018-05-31 01:46:26,007 -> Reporting locations...                             |   4.95s |  18548 points
2018-05-31 01:46:26,008 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=4,dataset=berlin0-10
2018-05-31 01:46:32,801 -> A.Indexing points... [6.775s] [18548 results]
2018-05-31 01:46:42,731 -> B.Getting pairs... [9.930s] [5775 results]
2018-05-31 01:46:44,001 -> C.Computing centers... [1.269s] [11550 results]
2018-05-31 01:46:44,989 -> D.Indexing centers... [0.988s] [11550 results]
2018-05-31 01:46:51,621 -> E.Getting disks... [6.632s] [11550 results]
2018-05-31 01:46:51,887 -> F.Filtering less-than-mu disks... [0.266s] [1369 results]
2018-05-31 01:46:53,987 -> G.Prunning duplicate candidates... [2.100s] [694 results]
2018-05-31 01:46:54,299 -> H.Indexing candidates... [2.412s] [694 results]
2018-05-31 01:46:54,476 -> I.Getting expansions... [0.177s] [1914 results]
2018-05-31 01:46:54,630 -> J.Finding maximal disks... [0.154s] [245 results]
2018-05-31 01:46:56,456 -> K.Prunning duplicates and subsets... [1.826s] [238 results]
2018-05-31 01:46:56,456 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:46:56,456 ->   berlin0-10,   18548,  30.0,    28,  4,  30.43,    5775,     11550,          694,        238,  4
2018-05-31 01:46:56,700 -> Dropping indices...[0.244s]
2018-05-31 01:46:57,000 -> 1.Set of disks for t_i...                          |  30.99s |    238 disks
2018-05-31 01:47:04,581 -> 2.Distance Join phase...                           |   7.58s |   1066 combinations
2018-05-31 01:47:09,676 -> 3.Getting candidates...                            |   5.10s |    250 candidates
2018-05-31 01:47:10,602 -> 4.Found flocks...                                  |   0.93s |    220 flocks
2018-05-31 01:47:14,857 -> 5.Updating times...                                |   1.61s |    250 flocks
2018-05-31 01:47:17,203 -> 6.Filter phase...                                  |   2.35s |    274 flocks
2018-05-31 01:47:22,154 -> Reporting locations...                             |   4.95s |  18548 points
2018-05-31 01:47:22,154 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=5,dataset=berlin0-10
2018-05-31 01:47:29,186 -> A.Indexing points... [7.014s] [18548 results]
2018-05-31 01:47:38,852 -> B.Getting pairs... [9.666s] [5765 results]
2018-05-31 01:47:40,211 -> C.Computing centers... [1.359s] [11530 results]
2018-05-31 01:47:41,111 -> D.Indexing centers... [0.900s] [11530 results]
2018-05-31 01:47:47,617 -> E.Getting disks... [6.506s] [11530 results]
2018-05-31 01:47:48,084 -> F.Filtering less-than-mu disks... [0.467s] [1362 results]
2018-05-31 01:47:49,617 -> G.Prunning duplicate candidates... [1.533s] [686 results]
2018-05-31 01:47:49,930 -> H.Indexing candidates... [1.846s] [686 results]
2018-05-31 01:47:50,078 -> I.Getting expansions... [0.148s] [1917 results]
2018-05-31 01:47:50,214 -> J.Finding maximal disks... [0.135s] [237 results]
2018-05-31 01:47:52,027 -> K.Prunning duplicates and subsets... [1.813s] [234 results]
2018-05-31 01:47:52,028 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:47:52,028 ->   berlin0-10,   18548,  30.0,    28,  4,  29.86,    5765,     11530,          686,        234,  5
2018-05-31 01:47:52,381 -> Dropping indices...[0.353s]
2018-05-31 01:47:52,646 -> 1.Set of disks for t_i...                          |  30.49s |    234 disks
2018-05-31 01:48:00,699 -> 2.Distance Join phase...                           |   8.05s |   1035 combinations
2018-05-31 01:48:05,716 -> 3.Getting candidates...                            |   5.02s |    240 candidates
2018-05-31 01:48:06,768 -> 4.Found flocks...                                  |   1.05s |    213 flocks
2018-05-31 01:48:12,006 -> 5.Updating times...                                |   1.79s |    240 flocks
2018-05-31 01:48:14,564 -> 6.Filter phase...                                  |   2.56s |    267 flocks
2018-05-31 01:48:19,711 -> Reporting locations...                             |   5.15s |  18546 points
2018-05-31 01:48:19,711 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=6,dataset=berlin0-10
2018-05-31 01:48:26,716 -> A.Indexing points... [6.987s] [18546 results]
2018-05-31 01:48:36,766 -> B.Getting pairs... [10.050s] [5758 results]
2018-05-31 01:48:38,092 -> C.Computing centers... [1.326s] [11516 results]
2018-05-31 01:48:39,003 -> D.Indexing centers... [0.911s] [11516 results]
2018-05-31 01:48:45,746 -> E.Getting disks... [6.743s] [11516 results]
2018-05-31 01:48:45,983 -> F.Filtering less-than-mu disks... [0.236s] [1346 results]
2018-05-31 01:48:48,024 -> G.Prunning duplicate candidates... [2.041s] [681 results]
2018-05-31 01:48:48,373 -> H.Indexing candidates... [2.390s] [681 results]
2018-05-31 01:48:48,545 -> I.Getting expansions... [0.172s] [1951 results]
2018-05-31 01:48:48,686 -> J.Finding maximal disks... [0.140s] [225 results]
2018-05-31 01:48:50,929 -> K.Prunning duplicates and subsets... [2.243s] [222 results]
2018-05-31 01:48:50,929 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:48:50,929 ->   berlin0-10,   18546,  30.0,    28,  4,  31.20,    5758,     11516,          681,        222,  6
2018-05-31 01:48:51,363 -> Dropping indices...[0.434s]
2018-05-31 01:48:51,621 -> 1.Set of disks for t_i...                          |  31.91s |    222 disks
2018-05-31 01:49:01,319 -> 2.Distance Join phase...                           |   9.70s |    894 combinations
2018-05-31 01:49:06,448 -> 3.Getting candidates...                            |   5.13s |    252 candidates
2018-05-31 01:49:07,571 -> 4.Found flocks...                                  |   1.12s |    218 flocks
2018-05-31 01:49:13,233 -> 5.Updating times...                                |   1.56s |    252 flocks
2018-05-31 01:49:15,757 -> 6.Filter phase...                                  |   2.52s |    272 flocks
2018-05-31 01:49:20,718 -> Reporting locations...                             |   4.96s |  18546 points
2018-05-31 01:49:20,719 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=7,dataset=berlin0-10
2018-05-31 01:49:27,496 -> A.Indexing points... [6.760s] [18546 results]
2018-05-31 01:49:37,610 -> B.Getting pairs... [10.114s] [5788 results]
2018-05-31 01:49:38,858 -> C.Computing centers... [1.247s] [11576 results]
2018-05-31 01:49:39,770 -> D.Indexing centers... [0.912s] [11576 results]
2018-05-31 01:49:46,478 -> E.Getting disks... [6.708s] [11576 results]
2018-05-31 01:49:46,679 -> F.Filtering less-than-mu disks... [0.201s] [1361 results]
2018-05-31 01:49:48,816 -> G.Prunning duplicate candidates... [2.137s] [688 results]
2018-05-31 01:49:49,121 -> H.Indexing candidates... [2.442s] [688 results]
2018-05-31 01:49:49,271 -> I.Getting expansions... [0.150s] [1882 results]
2018-05-31 01:49:49,410 -> J.Finding maximal disks... [0.139s] [233 results]
2018-05-31 01:49:51,307 -> K.Prunning duplicates and subsets... [1.897s] [231 results]
2018-05-31 01:49:51,308 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:49:51,308 ->   berlin0-10,   18546,  30.0,    28,  4,  30.57,    5788,     11576,          688,        231,  7
2018-05-31 01:49:51,823 -> Dropping indices...[0.515s]
2018-05-31 01:49:52,059 -> 1.Set of disks for t_i...                          |  31.34s |    231 disks
2018-05-31 01:50:00,472 -> 2.Distance Join phase...                           |   8.41s |    934 combinations
2018-05-31 01:50:05,532 -> 3.Getting candidates...                            |   5.06s |    239 candidates
2018-05-31 01:50:06,815 -> 4.Found flocks...                                  |   1.28s |    216 flocks
2018-05-31 01:50:13,672 -> 5.Updating times...                                |   1.88s |    239 flocks
2018-05-31 01:50:16,329 -> 6.Filter phase...                                  |   2.66s |    270 flocks
2018-05-31 01:50:21,224 -> Reporting locations...                             |   4.90s |  18546 points
2018-05-31 01:50:21,224 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=8,dataset=berlin0-10
2018-05-31 01:50:26,206 -> A.Indexing points... [4.965s] [18546 results]
2018-05-31 01:50:32,589 -> B.Getting pairs... [6.383s] [5791 results]
2018-05-31 01:50:34,001 -> C.Computing centers... [1.412s] [11582 results]
2018-05-31 01:50:34,869 -> D.Indexing centers... [0.867s] [11582 results]
2018-05-31 01:50:40,047 -> E.Getting disks... [5.177s] [11582 results]
2018-05-31 01:50:40,266 -> F.Filtering less-than-mu disks... [0.219s] [1316 results]
2018-05-31 01:50:41,731 -> G.Prunning duplicate candidates... [1.465s] [670 results]
2018-05-31 01:50:42,021 -> H.Indexing candidates... [1.755s] [670 results]
2018-05-31 01:50:42,165 -> I.Getting expansions... [0.144s] [1792 results]
2018-05-31 01:50:42,294 -> J.Finding maximal disks... [0.128s] [220 results]
2018-05-31 01:50:43,614 -> K.Prunning duplicates and subsets... [1.320s] [219 results]
2018-05-31 01:50:43,614 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:50:43,614 ->   berlin0-10,   18546,  30.0,    28,  4,  22.37,    5791,     11582,          670,        219,  8
2018-05-31 01:50:44,204 -> Dropping indices...[0.590s]
2018-05-31 01:50:44,472 -> 1.Set of disks for t_i...                          |  23.25s |    219 disks
2018-05-31 01:50:53,869 -> 2.Distance Join phase...                           |   9.40s |    811 combinations
2018-05-31 01:50:59,071 -> 3.Getting candidates...                            |   5.20s |    226 candidates
2018-05-31 01:51:00,413 -> 4.Found flocks...                                  |   1.34s |    197 flocks
2018-05-31 01:51:07,928 -> 5.Updating times...                                |   1.97s |    226 flocks
2018-05-31 01:51:10,548 -> 6.Filter phase...                                  |   2.62s |    247 flocks
2018-05-31 01:51:15,369 -> Reporting locations...                             |   4.82s |  18546 points
2018-05-31 01:51:15,370 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=9,dataset=berlin0-10
2018-05-31 01:51:23,203 -> A.Indexing points... [7.799s] [18546 results]
2018-05-31 01:51:33,969 -> B.Getting pairs... [10.766s] [5802 results]
2018-05-31 01:51:35,371 -> C.Computing centers... [1.402s] [11604 results]
2018-05-31 01:51:36,261 -> D.Indexing centers... [0.890s] [11604 results]
2018-05-31 01:51:43,372 -> E.Getting disks... [7.111s] [11604 results]
2018-05-31 01:51:43,575 -> F.Filtering less-than-mu disks... [0.203s] [1306 results]
2018-05-31 01:51:45,545 -> G.Prunning duplicate candidates... [1.970s] [675 results]
2018-05-31 01:51:45,855 -> H.Indexing candidates... [2.280s] [675 results]
2018-05-31 01:51:46,009 -> I.Getting expansions... [0.154s] [1813 results]
2018-05-31 01:51:46,139 -> J.Finding maximal disks... [0.130s] [212 results]
2018-05-31 01:51:48,061 -> K.Prunning duplicates and subsets... [1.922s] [210 results]
2018-05-31 01:51:48,061 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:51:48,061 ->   berlin0-10,   18546,  30.0,    28,  4,  32.66,    5802,     11604,          675,        210,  9
2018-05-31 01:51:48,722 -> Dropping indices...[0.661s]
2018-05-31 01:51:48,988 -> 1.Set of disks for t_i...                          |  33.62s |    210 disks
2018-05-31 01:51:59,737 -> 2.Distance Join phase...                           |  10.75s |    637 combinations
2018-05-31 01:52:05,738 -> 3.Getting candidates...                            |   6.00s |    219 candidates
2018-05-31 01:52:07,412 -> 4.Found flocks...                                  |   1.67s |    199 flocks
2018-05-31 01:52:16,656 -> 5.Updating times...                                |   2.41s |    219 flocks
2018-05-31 01:52:20,388 -> 6.Filter phase...                                  |   3.73s |    239 flocks
2018-05-31 01:52:25,234 -> Reporting locations...                             |   4.85s |  18546 points
2018-05-31 01:52:25,234 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=10,dataset=berlin0-10
2018-05-31 01:52:33,012 -> A.Indexing points... [7.742s] [18546 results]
2018-05-31 01:52:43,740 -> B.Getting pairs... [10.728s] [5797 results]
2018-05-31 01:52:45,180 -> C.Computing centers... [1.440s] [11594 results]
2018-05-31 01:52:46,052 -> D.Indexing centers... [0.872s] [11594 results]
2018-05-31 01:52:53,254 -> E.Getting disks... [7.202s] [11594 results]
2018-05-31 01:52:53,462 -> F.Filtering less-than-mu disks... [0.208s] [1312 results]
2018-05-31 01:52:55,459 -> G.Prunning duplicate candidates... [1.996s] [675 results]
2018-05-31 01:52:55,736 -> H.Indexing candidates... [2.273s] [675 results]
2018-05-31 01:52:55,884 -> I.Getting expansions... [0.148s] [1804 results]
2018-05-31 01:52:56,012 -> J.Finding maximal disks... [0.128s] [212 results]
2018-05-31 01:52:57,858 -> K.Prunning duplicates and subsets... [1.846s] [211 results]
2018-05-31 01:52:57,859 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:52:57,859 ->   berlin0-10,   18546,  30.0,    28,  4,  32.59,    5797,     11594,          675,        211, 10
2018-05-31 01:52:58,620 -> Dropping indices...[0.761s]
2018-05-31 01:52:58,955 -> 1.Set of disks for t_i...                          |  33.72s |    211 disks
2018-05-31 01:53:10,579 -> 2.Distance Join phase...                           |  11.62s |    598 combinations
2018-05-31 01:53:16,863 -> 3.Getting candidates...                            |   6.28s |    213 candidates
2018-05-31 01:53:18,422 -> 4.Found flocks...                                  |   1.56s |    196 flocks
2018-05-31 01:53:27,847 -> 5.Updating times...                                |   2.03s |    213 flocks
2018-05-31 01:53:30,511 -> 6.Filter phase...                                  |   2.66s |    237 flocks
2018-05-31 01:53:30,511 -> 

PFLOCK_SJ	30.0	4	3	1868

2018-05-31 01:53:36,666 -> Running SpatialJoin...                             | 610.61s |   1868 flocks
2018-05-31 01:53:36,666 -> method=SpatialJoin,cores=28,epsilon=30.0,mu=4,delta=3,time=610.611,master=spark://169.235.27.134:7077
2018-05-31 01:53:36,666 -> Closing app...
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack15: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
FLOCKFINDER=SpatialJoin;TIME=Thu May 31 01:53:43 PDT 2018;RUN=1527756189;NODES=4;ESTART=;EEND=;ESTEP=;MU=4;DELTA=;SCRIPT=DeltaBenchmarker;EVENT=End
FLOCKFINDER=MergeLast;TIME=Thu May 31 01:53:43 PDT 2018;RUN=1527756823;NODES=4;ESTART=;EEND=;ESTEP=;MU=4;DELTA=;SCRIPT=DeltaBenchmarker;EVENT=Start
WARNING:root:Setting 4 nodes...
acald013@dblab-rack12: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack15: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack11: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack14: no org.apache.spark.deploy.worker.Worker to stop
no org.apache.spark.deploy.master.Master to stop
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack15: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack15.out
WARNING:root:4 nodes has been set...
2018-05-31 01:53:50,418 -> Starting app...
2018-05-31 01:53:53,264 -> Starting session                                   |   2.85s |      0 
2018-05-31 01:53:53,281 -> Setting paramaters                                 |   0.02s |      0 
2018-05-31 01:53:56,451 -> Reading data                                       |   3.17s | 203106 points
2018-05-31 01:53:59,693 -> Extracting timestamps                              |   3.24s |     11 timestamps
2018-05-31 01:53:59,702 -> === MergeLast Start ===
2018-05-31 01:54:04,904 -> Reporting locations at t=0...                      |   5.00s |  18093 points
2018-05-31 01:54:04,919 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=0,dataset=berlin0-10
2018-05-31 01:54:13,316 -> A.Indexing points... [8.354s] [18093 results]
2018-05-31 01:54:21,069 -> B.Getting pairs... [7.752s] [5511 results]
2018-05-31 01:54:23,435 -> C.Computing centers... [2.366s] [11022 results]
2018-05-31 01:54:24,759 -> D.Indexing centers... [1.324s] [11022 results]
2018-05-31 01:54:30,803 -> E.Getting disks... [6.044s] [11022 results]
2018-05-31 01:54:31,315 -> F.Filtering less-than-mu disks... [0.511s] [1210 results]
2018-05-31 01:54:33,840 -> G.Prunning duplicate candidates... [2.525s] [599 results]
2018-05-31 01:54:34,356 -> H.Indexing candidates... [3.041s] [599 results]
2018-05-31 01:54:34,626 -> I.Getting expansions... [0.270s] [1657 results]
2018-05-31 01:54:35,101 -> J.Finding maximal disks... [0.475s] [206 results]
2018-05-31 01:54:37,079 -> K.Prunning duplicates and subsets... [1.978s] [205 results]
2018-05-31 01:54:37,079 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:54:37,079 ->   berlin0-10,   18093,  30.0,    28,  4,  32.12,    5511,     11022,          599,        205,  0
2018-05-31 01:54:37,149 -> Dropping indices...[0.070s]
2018-05-31 01:54:37,541 -> 1.Set of disks for t_i...                          |  32.64s |    205 disks
2018-05-31 01:54:43,210 -> Reporting locations at t=2...                      |   5.67s |  18394 points
2018-05-31 01:54:43,211 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=2,dataset=berlin0-10
2018-05-31 01:54:48,014 -> A.Indexing points... [4.780s] [18394 results]
2018-05-31 01:54:53,523 -> B.Getting pairs... [5.509s] [5701 results]
2018-05-31 01:54:54,986 -> C.Computing centers... [1.463s] [11402 results]
2018-05-31 01:54:55,944 -> D.Indexing centers... [0.958s] [11402 results]
2018-05-31 01:55:00,622 -> E.Getting disks... [4.677s] [11402 results]
2018-05-31 01:55:00,926 -> F.Filtering less-than-mu disks... [0.304s] [1336 results]
2018-05-31 01:55:02,438 -> G.Prunning duplicate candidates... [1.512s] [658 results]
2018-05-31 01:55:02,793 -> H.Indexing candidates... [1.867s] [658 results]
2018-05-31 01:55:02,968 -> I.Getting expansions... [0.175s] [1757 results]
2018-05-31 01:55:03,458 -> J.Finding maximal disks... [0.490s] [232 results]
2018-05-31 01:55:04,881 -> K.Prunning duplicates and subsets... [1.423s] [227 results]
2018-05-31 01:55:04,881 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:55:04,881 ->   berlin0-10,   18394,  30.0,    28,  4,  21.65,    5701,     11402,          658,        227,  2
2018-05-31 01:55:04,950 -> Dropping indices...[0.069s]
2018-05-31 01:55:05,254 -> 2.Set of disks for t_i+delta...                    |  22.04s |    205 disks
2018-05-31 01:55:13,779 -> 3.Joining timestams                                |   8.53s |    332 candidates
2018-05-31 01:55:26,060 -> Checking internal timestamps                       |  12.28s |    199 flocks
2018-05-31 01:55:31,255 -> Reporting locations at t=1...                      |   4.80s |  18245 points
2018-05-31 01:55:31,255 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=1,dataset=berlin0-10
2018-05-31 01:55:35,440 -> A.Indexing points... [4.166s] [18245 results]
2018-05-31 01:55:40,145 -> B.Getting pairs... [4.705s] [5629 results]
2018-05-31 01:55:41,630 -> C.Computing centers... [1.485s] [11258 results]
2018-05-31 01:55:42,586 -> D.Indexing centers... [0.956s] [11258 results]
2018-05-31 01:55:46,973 -> E.Getting disks... [4.387s] [11258 results]
2018-05-31 01:55:47,195 -> F.Filtering less-than-mu disks... [0.222s] [1299 results]
2018-05-31 01:55:48,754 -> G.Prunning duplicate candidates... [1.559s] [640 results]
2018-05-31 01:55:49,107 -> H.Indexing candidates... [1.912s] [640 results]
2018-05-31 01:55:49,260 -> I.Getting expansions... [0.153s] [1703 results]
2018-05-31 01:55:49,419 -> J.Finding maximal disks... [0.159s] [220 results]
2018-05-31 01:55:50,671 -> K.Prunning duplicates and subsets... [1.252s] [216 results]
2018-05-31 01:55:50,671 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:55:50,671 ->   berlin0-10,   18245,  30.0,    28,  4,  19.40,    5629,     11258,          640,        216,  1
2018-05-31 01:55:50,809 -> Dropping indices...[0.137s]
2018-05-31 01:55:51,032 -> 1.Set of disks for t_i...                          |  19.78s |    216 disks
2018-05-31 01:55:55,854 -> Reporting locations at t=3...                      |   4.82s |  18548 points
2018-05-31 01:55:55,855 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=3,dataset=berlin0-10
2018-05-31 01:56:02,899 -> A.Indexing points... [7.022s] [18548 results]
2018-05-31 01:56:13,277 -> B.Getting pairs... [10.378s] [5768 results]
2018-05-31 01:56:14,728 -> C.Computing centers... [1.451s] [11536 results]
2018-05-31 01:56:15,674 -> D.Indexing centers... [0.946s] [11536 results]
2018-05-31 01:56:22,716 -> E.Getting disks... [7.042s] [11536 results]
2018-05-31 01:56:23,000 -> F.Filtering less-than-mu disks... [0.284s] [1349 results]
2018-05-31 01:56:25,064 -> G.Prunning duplicate candidates... [2.064s] [675 results]
2018-05-31 01:56:25,408 -> H.Indexing candidates... [2.408s] [675 results]
2018-05-31 01:56:25,574 -> I.Getting expansions... [0.166s] [1875 results]
2018-05-31 01:56:26,305 -> J.Finding maximal disks... [0.731s] [230 results]
2018-05-31 01:56:28,288 -> K.Prunning duplicates and subsets... [1.983s] [225 results]
2018-05-31 01:56:28,288 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:56:28,288 ->   berlin0-10,   18548,  30.0,    28,  4,  32.41,    5768,     11536,          675,        225,  3
2018-05-31 01:56:28,435 -> Dropping indices...[0.147s]
2018-05-31 01:56:28,669 -> 2.Set of disks for t_i+delta...                    |  32.81s |    216 disks
2018-05-31 01:56:35,817 -> 3.Joining timestams                                |   7.15s |    333 candidates
2018-05-31 01:56:45,373 -> Checking internal timestamps                       |   9.56s |    210 flocks
2018-05-31 01:56:51,649 -> Reporting locations at t=2...                      |   5.69s |  18394 points
2018-05-31 01:56:51,896 -> 1.Set of disks for t_i...                          |   0.25s |    227 disks
2018-05-31 01:56:56,659 -> Reporting locations at t=4...                      |   4.76s |  18548 points
2018-05-31 01:56:56,660 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=4,dataset=berlin0-10
2018-05-31 01:57:03,561 -> A.Indexing points... [6.881s] [18548 results]
2018-05-31 01:57:14,271 -> B.Getting pairs... [10.710s] [5775 results]
2018-05-31 01:57:15,507 -> C.Computing centers... [1.236s] [11550 results]
2018-05-31 01:57:16,462 -> D.Indexing centers... [0.955s] [11550 results]
2018-05-31 01:57:23,755 -> E.Getting disks... [7.293s] [11550 results]
2018-05-31 01:57:24,001 -> F.Filtering less-than-mu disks... [0.246s] [1369 results]
2018-05-31 01:57:25,996 -> G.Prunning duplicate candidates... [1.994s] [694 results]
2018-05-31 01:57:26,300 -> H.Indexing candidates... [2.298s] [694 results]
2018-05-31 01:57:26,453 -> I.Getting expansions... [0.153s] [1914 results]
2018-05-31 01:57:26,598 -> J.Finding maximal disks... [0.145s] [245 results]
2018-05-31 01:57:28,526 -> K.Prunning duplicates and subsets... [1.928s] [238 results]
2018-05-31 01:57:28,526 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:57:28,526 ->   berlin0-10,   18548,  30.0,    28,  4,  31.85,    5775,     11550,          694,        238,  4
2018-05-31 01:57:28,705 -> Dropping indices...[0.178s]
2018-05-31 01:57:28,981 -> 2.Set of disks for t_i+delta...                    |  32.32s |    227 disks
2018-05-31 01:57:36,340 -> 3.Joining timestams                                |   7.36s |    360 candidates
2018-05-31 01:57:45,902 -> Checking internal timestamps                       |   9.56s |    220 flocks
2018-05-31 01:57:51,503 -> Reporting locations at t=3...                      |   4.78s |  18548 points
2018-05-31 01:57:51,761 -> 1.Set of disks for t_i...                          |   0.26s |    225 disks
2018-05-31 01:57:56,565 -> Reporting locations at t=5...                      |   4.80s |  18548 points
2018-05-31 01:57:56,565 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=5,dataset=berlin0-10
2018-05-31 01:58:03,389 -> A.Indexing points... [6.804s] [18548 results]
2018-05-31 01:58:13,625 -> B.Getting pairs... [10.236s] [5765 results]
2018-05-31 01:58:14,864 -> C.Computing centers... [1.239s] [11530 results]
2018-05-31 01:58:15,854 -> D.Indexing centers... [0.990s] [11530 results]
2018-05-31 01:58:22,706 -> E.Getting disks... [6.852s] [11530 results]
2018-05-31 01:58:22,958 -> F.Filtering less-than-mu disks... [0.252s] [1362 results]
2018-05-31 01:58:25,133 -> G.Prunning duplicate candidates... [2.175s] [686 results]
2018-05-31 01:58:25,448 -> H.Indexing candidates... [2.490s] [686 results]
2018-05-31 01:58:25,620 -> I.Getting expansions... [0.172s] [1917 results]
2018-05-31 01:58:25,772 -> J.Finding maximal disks... [0.152s] [237 results]
2018-05-31 01:58:27,712 -> K.Prunning duplicates and subsets... [1.940s] [234 results]
2018-05-31 01:58:27,712 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:58:27,712 ->   berlin0-10,   18548,  30.0,    28,  4,  31.13,    5765,     11530,          686,        234,  5
2018-05-31 01:58:27,908 -> Dropping indices...[0.196s]
2018-05-31 01:58:28,271 -> 2.Set of disks for t_i+delta...                    |  31.71s |    225 disks
2018-05-31 01:58:35,588 -> 3.Joining timestams                                |   7.32s |    327 candidates
2018-05-31 01:58:45,176 -> Checking internal timestamps                       |   9.59s |    213 flocks
2018-05-31 01:58:51,070 -> Reporting locations at t=4...                      |   4.79s |  18548 points
2018-05-31 01:58:51,517 -> 1.Set of disks for t_i...                          |   0.45s |    238 disks
2018-05-31 01:58:56,385 -> Reporting locations at t=6...                      |   4.87s |  18546 points
2018-05-31 01:58:56,385 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=6,dataset=berlin0-10
2018-05-31 01:59:03,131 -> A.Indexing points... [6.726s] [18546 results]
2018-05-31 01:59:13,349 -> B.Getting pairs... [10.218s] [5758 results]
2018-05-31 01:59:14,682 -> C.Computing centers... [1.333s] [11516 results]
2018-05-31 01:59:15,566 -> D.Indexing centers... [0.884s] [11516 results]
2018-05-31 01:59:22,393 -> E.Getting disks... [6.826s] [11516 results]
2018-05-31 01:59:22,620 -> F.Filtering less-than-mu disks... [0.227s] [1346 results]
2018-05-31 01:59:25,110 -> G.Prunning duplicate candidates... [2.490s] [681 results]
2018-05-31 01:59:25,446 -> H.Indexing candidates... [2.826s] [681 results]
2018-05-31 01:59:25,624 -> I.Getting expansions... [0.178s] [1951 results]
2018-05-31 01:59:25,763 -> J.Finding maximal disks... [0.139s] [225 results]
2018-05-31 01:59:27,710 -> K.Prunning duplicates and subsets... [1.946s] [222 results]
2018-05-31 01:59:27,710 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 01:59:27,710 ->   berlin0-10,   18546,  30.0,    28,  4,  31.31,    5758,     11516,          681,        222,  6
2018-05-31 01:59:27,965 -> Dropping indices...[0.255s]
2018-05-31 01:59:28,184 -> 2.Set of disks for t_i+delta...                    |  31.80s |    238 disks
2018-05-31 01:59:35,725 -> 3.Joining timestams                                |   7.54s |    324 candidates
2018-05-31 01:59:45,213 -> Checking internal timestamps                       |   9.49s |    218 flocks
2018-05-31 01:59:51,132 -> Reporting locations at t=5...                      |   4.79s |  18548 points
2018-05-31 01:59:51,371 -> 1.Set of disks for t_i...                          |   0.24s |    234 disks
2018-05-31 01:59:56,168 -> Reporting locations at t=7...                      |   4.80s |  18546 points
2018-05-31 01:59:56,168 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=7,dataset=berlin0-10
2018-05-31 02:00:03,067 -> A.Indexing points... [6.880s] [18546 results]
2018-05-31 02:00:13,441 -> B.Getting pairs... [10.373s] [5788 results]
2018-05-31 02:00:14,735 -> C.Computing centers... [1.294s] [11576 results]
2018-05-31 02:00:15,721 -> D.Indexing centers... [0.986s] [11576 results]
2018-05-31 02:00:22,602 -> E.Getting disks... [6.881s] [11576 results]
2018-05-31 02:00:22,837 -> F.Filtering less-than-mu disks... [0.235s] [1361 results]
2018-05-31 02:00:24,945 -> G.Prunning duplicate candidates... [2.108s] [688 results]
2018-05-31 02:00:25,296 -> H.Indexing candidates... [2.459s] [688 results]
2018-05-31 02:00:25,471 -> I.Getting expansions... [0.175s] [1882 results]
2018-05-31 02:00:25,611 -> J.Finding maximal disks... [0.140s] [233 results]
2018-05-31 02:00:27,482 -> K.Prunning duplicates and subsets... [1.871s] [231 results]
2018-05-31 02:00:27,482 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 02:00:27,482 ->   berlin0-10,   18546,  30.0,    28,  4,  31.30,    5788,     11576,          688,        231,  7
2018-05-31 02:00:27,716 -> Dropping indices...[0.234s]
2018-05-31 02:00:27,968 -> 2.Set of disks for t_i+delta...                    |  31.80s |    234 disks
2018-05-31 02:00:35,335 -> 3.Joining timestams                                |   7.37s |    320 candidates
2018-05-31 02:00:44,982 -> Checking internal timestamps                       |   9.65s |    216 flocks
2018-05-31 02:00:51,098 -> Reporting locations at t=6...                      |   4.80s |  18546 points
2018-05-31 02:00:51,346 -> 1.Set of disks for t_i...                          |   0.25s |    222 disks
2018-05-31 02:00:56,049 -> Reporting locations at t=8...                      |   4.70s |  18546 points
2018-05-31 02:00:56,050 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=8,dataset=berlin0-10
2018-05-31 02:01:00,592 -> A.Indexing points... [4.523s] [18546 results]
2018-05-31 02:01:06,559 -> B.Getting pairs... [5.967s] [5791 results]
2018-05-31 02:01:07,907 -> C.Computing centers... [1.348s] [11582 results]
2018-05-31 02:01:08,847 -> D.Indexing centers... [0.940s] [11582 results]
2018-05-31 02:01:14,206 -> E.Getting disks... [5.359s] [11582 results]
2018-05-31 02:01:14,492 -> F.Filtering less-than-mu disks... [0.286s] [1316 results]
2018-05-31 02:01:16,485 -> G.Prunning duplicate candidates... [1.993s] [670 results]
2018-05-31 02:01:16,844 -> H.Indexing candidates... [2.352s] [670 results]
2018-05-31 02:01:17,061 -> I.Getting expansions... [0.216s] [1792 results]
2018-05-31 02:01:17,213 -> J.Finding maximal disks... [0.152s] [220 results]
2018-05-31 02:01:18,822 -> K.Prunning duplicates and subsets... [1.609s] [219 results]
2018-05-31 02:01:18,822 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 02:01:18,822 ->   berlin0-10,   18546,  30.0,    28,  4,  22.75,    5791,     11582,          670,        219,  8
2018-05-31 02:01:19,121 -> Dropping indices...[0.299s]
2018-05-31 02:01:19,359 -> 2.Set of disks for t_i+delta...                    |  23.31s |    222 disks
2018-05-31 02:01:26,907 -> 3.Joining timestams                                |   7.55s |    283 candidates
2018-05-31 02:01:36,307 -> Checking internal timestamps                       |   9.40s |    197 flocks
2018-05-31 02:01:42,752 -> Reporting locations at t=7...                      |   4.82s |  18546 points
2018-05-31 02:01:43,026 -> 1.Set of disks for t_i...                          |   0.27s |    231 disks
2018-05-31 02:01:47,708 -> Reporting locations at t=9...                      |   4.68s |  18546 points
2018-05-31 02:01:47,708 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=9,dataset=berlin0-10
2018-05-31 02:01:55,278 -> A.Indexing points... [7.528s] [18546 results]
2018-05-31 02:02:06,176 -> B.Getting pairs... [10.898s] [5802 results]
2018-05-31 02:02:07,422 -> C.Computing centers... [1.246s] [11604 results]
2018-05-31 02:02:08,367 -> D.Indexing centers... [0.945s] [11604 results]
2018-05-31 02:02:15,612 -> E.Getting disks... [7.245s] [11604 results]
2018-05-31 02:02:15,821 -> F.Filtering less-than-mu disks... [0.209s] [1306 results]
2018-05-31 02:02:17,949 -> G.Prunning duplicate candidates... [2.128s] [675 results]
2018-05-31 02:02:18,284 -> H.Indexing candidates... [2.463s] [675 results]
2018-05-31 02:02:18,450 -> I.Getting expansions... [0.166s] [1813 results]
2018-05-31 02:02:18,578 -> J.Finding maximal disks... [0.128s] [212 results]
2018-05-31 02:02:20,662 -> K.Prunning duplicates and subsets... [2.083s] [210 results]
2018-05-31 02:02:20,662 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 02:02:20,662 ->   berlin0-10,   18546,  30.0,    28,  4,  32.91,    5802,     11604,          675,        210,  9
2018-05-31 02:02:20,980 -> Dropping indices...[0.318s]
2018-05-31 02:02:21,197 -> 2.Set of disks for t_i+delta...                    |  33.49s |    231 disks
2018-05-31 02:02:28,715 -> 3.Joining timestams                                |   7.52s |    277 candidates
2018-05-31 02:02:38,019 -> Checking internal timestamps                       |   9.30s |    199 flocks
2018-05-31 02:02:44,465 -> Reporting locations at t=8...                      |   4.73s |  18546 points
2018-05-31 02:02:44,730 -> 1.Set of disks for t_i...                          |   0.26s |    219 disks
2018-05-31 02:02:49,369 -> Reporting locations at t=10...                     |   4.64s |  18546 points
2018-05-31 02:02:49,369 -> Setting mu=4,epsilon=30.0,cores=28,timestamp=10,dataset=berlin0-10
2018-05-31 02:02:57,012 -> A.Indexing points... [7.601s] [18546 results]
2018-05-31 02:03:07,910 -> B.Getting pairs... [10.897s] [5797 results]
2018-05-31 02:03:09,160 -> C.Computing centers... [1.250s] [11594 results]
2018-05-31 02:03:10,146 -> D.Indexing centers... [0.986s] [11594 results]
2018-05-31 02:03:17,617 -> E.Getting disks... [7.471s] [11594 results]
2018-05-31 02:03:17,835 -> F.Filtering less-than-mu disks... [0.218s] [1312 results]
2018-05-31 02:03:20,197 -> G.Prunning duplicate candidates... [2.362s] [675 results]
2018-05-31 02:03:20,530 -> H.Indexing candidates... [2.695s] [675 results]
2018-05-31 02:03:20,706 -> I.Getting expansions... [0.176s] [1804 results]
2018-05-31 02:03:20,840 -> J.Finding maximal disks... [0.134s] [212 results]
2018-05-31 02:03:23,195 -> K.Prunning duplicates and subsets... [2.355s] [211 results]
2018-05-31 02:03:23,195 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 02:03:23,195 ->   berlin0-10,   18546,  30.0,    28,  4,  33.78,    5797,     11594,          675,        211, 10
2018-05-31 02:03:23,547 -> Dropping indices...[0.352s]
2018-05-31 02:03:23,822 -> 2.Set of disks for t_i+delta...                    |  34.45s |    219 disks
2018-05-31 02:03:31,662 -> 3.Joining timestams                                |   7.84s |    277 candidates
2018-05-31 02:03:41,650 -> Checking internal timestamps                       |   9.99s |    196 flocks
2018-05-31 02:03:43,675 -> 

PFLOCK_ML	30.0	4	3	1868

2018-05-31 02:03:45,452 -> Running MergeLast...                               | 585.75s |   1868 flocks
2018-05-31 02:03:45,452 -> method=MergeLast,cores=28,epsilon=30.0,mu=4,delta=3,time=585.75,master=spark://169.235.27.134:7077
2018-05-31 02:03:45,452 -> Closing app...
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack15: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
FLOCKFINDER=MergeLast;TIME=Thu May 31 02:03:51 PDT 2018;RUN=1527756823;NODES=4;ESTART=;EEND=;ESTEP=;MU=4;DELTA=;SCRIPT=DeltaBenchmarker;EVENT=End
FLOCKFINDER=SpatialJoin;TIME=Thu May 31 02:03:51 PDT 2018;RUN=1527757431;NODES=4;ESTART=;EEND=;ESTEP=;MU=;DELTA=5;SCRIPT=MuBenchmarker;EVENT=Start
WARNING:root:Setting 4 nodes...
acald013@dblab-rack12: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack15: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack11: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack14: no org.apache.spark.deploy.worker.Worker to stop
no org.apache.spark.deploy.master.Master to stop
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack15: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack15.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
WARNING:root:4 nodes has been set...
2018-05-31 02:03:58,949 -> Starting app...
2018-05-31 02:04:01,900 -> Starting session                                   |   2.95s |      0 
2018-05-31 02:04:01,915 -> Setting paramaters                                 |   0.02s |      0 
2018-05-31 02:04:05,127 -> Reading data                                       |   3.21s | 203106 points
2018-05-31 02:04:08,301 -> Extracting timestamps                              |   3.17s |     11 timestamps
2018-05-31 02:04:08,307 -> === SpatialJoin Start ===
2018-05-31 02:04:14,045 -> Reporting locations...                             |   5.47s |  18093 points
2018-05-31 02:04:14,058 -> Setting mu=2,epsilon=30.0,cores=28,timestamp=0,dataset=berlin0-10
2018-05-31 02:04:22,482 -> A.Indexing points... [8.376s] [18093 results]
2018-05-31 02:04:29,951 -> B.Getting pairs... [7.469s] [5511 results]
2018-05-31 02:04:31,978 -> C.Computing centers... [2.027s] [11022 results]
2018-05-31 02:04:33,346 -> D.Indexing centers... [1.367s] [11022 results]
2018-05-31 02:04:39,361 -> E.Getting disks... [6.015s] [11022 results]
2018-05-31 02:04:40,097 -> F.Filtering less-than-mu disks... [0.736s] [11022 results]
2018-05-31 02:04:43,516 -> G.Prunning duplicate candidates... [3.419s] [6157 results]
2018-05-31 02:04:44,096 -> H.Indexing candidates... [3.999s] [6157 results]
2018-05-31 02:04:44,471 -> I.Getting expansions... [0.375s] [6877 results]
2018-05-31 02:04:45,622 -> J.Finding maximal disks... [1.151s] [3432 results]
2018-05-31 02:04:48,020 -> K.Prunning duplicates and subsets... [2.398s] [3427 results]
2018-05-31 02:04:48,020 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 02:04:48,021 ->   berlin0-10,   18093,  30.0,    28,  2,  33.91,    5511,     11022,         6157,       3427,  0
2018-05-31 02:04:48,091 -> Dropping indices...[0.070s]
2018-05-31 02:04:48,510 -> 1.Set of disks for t_i...                          |  34.47s |   3427 disks
2018-05-31 02:04:49,016 -> 4.Found flocks...                                  |   0.51s |      0 flocks
2018-05-31 02:04:49,942 -> 5.Updating times...                                |   0.61s |   3427 flocks
2018-05-31 02:04:51,603 -> 6.Filter phase...                                  |   1.66s |   3427 flocks
2018-05-31 02:04:56,408 -> Reporting locations...                             |   4.81s |  18245 points
2018-05-31 02:04:56,409 -> Setting mu=2,epsilon=30.0,cores=28,timestamp=1,dataset=berlin0-10
2018-05-31 02:05:01,053 -> A.Indexing points... [4.622s] [18245 results]
2018-05-31 02:05:06,397 -> B.Getting pairs... [5.344s] [5629 results]
2018-05-31 02:05:07,925 -> C.Computing centers... [1.528s] [11258 results]
2018-05-31 02:05:08,879 -> D.Indexing centers... [0.954s] [11258 results]
2018-05-31 02:05:14,144 -> E.Getting disks... [5.265s] [11258 results]
2018-05-31 02:05:14,417 -> F.Filtering less-than-mu disks... [0.273s] [11258 results]
2018-05-31 02:05:16,071 -> G.Prunning duplicate candidates... [1.654s] [6297 results]
2018-05-31 02:05:16,624 -> H.Indexing candidates... [2.207s] [6297 results]
2018-05-31 02:05:17,013 -> I.Getting expansions... [0.389s] [6982 results]
2018-05-31 02:05:17,388 -> J.Finding maximal disks... [0.375s] [3482 results]
2018-05-31 02:05:18,935 -> K.Prunning duplicates and subsets... [1.547s] [3478 results]
2018-05-31 02:05:18,935 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 02:05:18,935 ->   berlin0-10,   18245,  30.0,    28,  2,  22.50,    5629,     11258,         6297,       3478,  1
2018-05-31 02:05:19,021 -> Dropping indices...[0.086s]
2018-05-31 02:05:19,369 -> 1.Set of disks for t_i...                          |  22.96s |   3478 disks
2018-05-31 02:05:24,440 -> 2.Distance Join phase...                           |   5.07s |   7060 combinations
2018-05-31 02:14:08,132 -> 3.Getting candidates...                            | 523.69s |   3376 candidates
2018-05-31 02:14:08,923 -> 4.Found flocks...                                  |   0.79s |      0 flocks
2018-05-31 02:14:11,270 -> 5.Updating times...                                |   1.34s |   3376 flocks
2018-05-31 02:14:14,052 -> 6.Filter phase...                                  |   2.78s |   3576 flocks
2018-05-31 02:14:18,624 -> Reporting locations...                             |   4.57s |  18394 points
2018-05-31 02:14:18,624 -> Setting mu=2,epsilon=30.0,cores=28,timestamp=2,dataset=berlin0-10
2018-05-31 02:14:22,898 -> A.Indexing points... [4.254s] [18394 results]
2018-05-31 02:14:27,464 -> B.Getting pairs... [4.566s] [5701 results]
2018-05-31 02:14:28,722 -> C.Computing centers... [1.258s] [11402 results]
2018-05-31 02:14:29,658 -> D.Indexing centers... [0.936s] [11402 results]
2018-05-31 02:14:33,807 -> E.Getting disks... [4.149s] [11402 results]
2018-05-31 02:14:34,078 -> F.Filtering less-than-mu disks... [0.271s] [11402 results]
2018-05-31 02:14:35,886 -> G.Prunning duplicate candidates... [1.808s] [6373 results]
2018-05-31 02:14:36,227 -> H.Indexing candidates... [2.149s] [6373 results]
2018-05-31 02:14:36,435 -> I.Getting expansions... [0.208s] [7107 results]
2018-05-31 02:14:36,624 -> J.Finding maximal disks... [0.189s] [3517 results]
2018-05-31 02:14:38,109 -> K.Prunning duplicates and subsets... [1.485s] [3511 results]
2018-05-31 02:14:38,109 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 02:14:38,109 ->   berlin0-10,   18394,  30.0,    28,  2,  19.47,    5701,     11402,         6373,       3511,  2
2018-05-31 02:14:38,235 -> Dropping indices...[0.125s]
2018-05-31 02:14:38,511 -> 1.Set of disks for t_i...                          |  19.89s |   3511 disks
2018-05-31 02:14:46,719 -> 2.Distance Join phase...                           |   8.21s |   7745 combinations
2018-05-31 02:30:59,330 -> 3.Getting candidates...                            | 972.61s |   3528 candidates
2018-05-31 02:31:00,209 -> 4.Found flocks...                                  |   0.88s |      0 flocks
2018-05-31 02:31:03,221 -> 5.Updating times...                                |   1.43s |   3528 flocks
2018-05-31 02:31:05,607 -> 6.Filter phase...                                  |   2.39s |   3711 flocks
2018-05-31 02:31:10,238 -> Reporting locations...                             |   4.63s |  18548 points
2018-05-31 02:31:10,239 -> Setting mu=2,epsilon=30.0,cores=28,timestamp=3,dataset=berlin0-10
2018-05-31 02:31:17,285 -> A.Indexing points... [7.027s] [18548 results]
2018-05-31 02:31:26,813 -> B.Getting pairs... [9.528s] [5768 results]
2018-05-31 02:31:28,109 -> C.Computing centers... [1.296s] [11536 results]
2018-05-31 02:31:29,008 -> D.Indexing centers... [0.899s] [11536 results]
2018-05-31 02:31:35,608 -> E.Getting disks... [6.600s] [11536 results]
2018-05-31 02:31:35,868 -> F.Filtering less-than-mu disks... [0.260s] [11536 results]
2018-05-31 02:31:38,910 -> G.Prunning duplicate candidates... [3.042s] [6465 results]
2018-05-31 02:31:39,296 -> H.Indexing candidates... [3.428s] [6465 results]
2018-05-31 02:31:39,555 -> I.Getting expansions... [0.259s] [7226 results]
2018-05-31 02:31:40,122 -> J.Finding maximal disks... [0.567s] [3566 results]
2018-05-31 02:31:42,271 -> K.Prunning duplicates and subsets... [2.149s] [3557 results]
2018-05-31 02:31:42,272 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 02:31:42,272 ->   berlin0-10,   18548,  30.0,    28,  2,  32.01,    5768,     11536,         6465,       3557,  3
2018-05-31 02:31:42,483 -> Dropping indices...[0.211s]
2018-05-31 02:31:42,769 -> 1.Set of disks for t_i...                          |  32.53s |   3557 disks
2018-05-31 02:31:51,255 -> 2.Distance Join phase...                           |   8.49s |   8243 combinations
2018-05-31 02:47:49,550 -> 3.Getting candidates...                            | 958.29s |   3681 candidates
2018-05-31 02:47:50,910 -> 4.Found flocks...                                  |   1.36s |      0 flocks
2018-05-31 02:47:56,007 -> 5.Updating times...                                |   2.39s |   3681 flocks
2018-05-31 02:47:59,167 -> 6.Filter phase...                                  |   3.16s |   3843 flocks
2018-05-31 02:48:03,971 -> Reporting locations...                             |   4.80s |  18548 points
2018-05-31 02:48:03,971 -> Setting mu=2,epsilon=30.0,cores=28,timestamp=4,dataset=berlin0-10
2018-05-31 02:48:10,986 -> A.Indexing points... [6.994s] [18548 results]
2018-05-31 02:48:20,624 -> B.Getting pairs... [9.638s] [5775 results]
2018-05-31 02:48:21,873 -> C.Computing centers... [1.249s] [11550 results]
2018-05-31 02:48:22,778 -> D.Indexing centers... [0.905s] [11550 results]
2018-05-31 02:48:29,312 -> E.Getting disks... [6.534s] [11550 results]
2018-05-31 02:48:29,529 -> F.Filtering less-than-mu disks... [0.217s] [11550 results]
2018-05-31 02:48:32,343 -> G.Prunning duplicate candidates... [2.814s] [6486 results]
2018-05-31 02:48:32,688 -> H.Indexing candidates... [3.159s] [6486 results]
2018-05-31 02:48:32,888 -> I.Getting expansions... [0.200s] [7196 results]
2018-05-31 02:48:33,068 -> J.Finding maximal disks... [0.180s] [3554 results]
2018-05-31 02:48:35,350 -> K.Prunning duplicates and subsets... [2.282s] [3546 results]
2018-05-31 02:48:35,350 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 02:48:35,350 ->   berlin0-10,   18548,  30.0,    28,  2,  31.36,    5775,     11550,         6486,       3546,  4
2018-05-31 02:48:35,647 -> Dropping indices...[0.297s]
2018-05-31 02:48:35,984 -> 1.Set of disks for t_i...                          |  32.01s |   3546 disks
2018-05-31 02:48:44,506 -> 2.Distance Join phase...                           |   8.52s |   8754 combinations
2018-05-31 03:02:40,354 -> 3.Getting candidates...                            | 835.85s |   3791 candidates
2018-05-31 03:02:41,876 -> 4.Found flocks...                                  |   1.52s |   3237 flocks
2018-05-31 03:02:48,037 -> 5.Updating times...                                |   2.78s |   3791 flocks
2018-05-31 03:02:51,513 -> 6.Filter phase...                                  |   3.48s |   3916 flocks
2018-05-31 03:02:56,198 -> Reporting locations...                             |   4.69s |  18548 points
2018-05-31 03:02:56,199 -> Setting mu=2,epsilon=30.0,cores=28,timestamp=5,dataset=berlin0-10
2018-05-31 03:03:03,193 -> A.Indexing points... [6.974s] [18548 results]
2018-05-31 03:03:12,560 -> B.Getting pairs... [9.367s] [5765 results]
2018-05-31 03:03:13,875 -> C.Computing centers... [1.315s] [11530 results]
2018-05-31 03:03:14,829 -> D.Indexing centers... [0.954s] [11530 results]
2018-05-31 03:03:21,460 -> E.Getting disks... [6.630s] [11530 results]
2018-05-31 03:03:21,739 -> F.Filtering less-than-mu disks... [0.279s] [11530 results]
2018-05-31 03:03:24,211 -> G.Prunning duplicate candidates... [2.472s] [6453 results]
2018-05-31 03:03:24,535 -> H.Indexing candidates... [2.796s] [6453 results]
2018-05-31 03:03:24,811 -> I.Getting expansions... [0.276s] [7126 results]
2018-05-31 03:03:24,993 -> J.Finding maximal disks... [0.182s] [3550 results]
2018-05-31 03:03:26,918 -> K.Prunning duplicates and subsets... [1.925s] [3540 results]
2018-05-31 03:03:26,919 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 03:03:26,919 ->   berlin0-10,   18548,  30.0,    28,  2,  30.70,    5765,     11530,         6453,       3540,  5
2018-05-31 03:03:27,326 -> Dropping indices...[0.407s]
2018-05-31 03:03:27,677 -> 1.Set of disks for t_i...                          |  31.48s |   3540 disks
2018-05-31 03:03:37,233 -> 2.Distance Join phase...                           |   9.56s |   9309 combinations
2018-05-31 03:20:08,282 -> 3.Getting candidates...                            | 991.05s |   3765 candidates
2018-05-31 03:20:09,927 -> 4.Found flocks...                                  |   1.65s |   3276 flocks
2018-05-31 03:20:18,558 -> 5.Updating times...                                |   2.79s |   3765 flocks
2018-05-31 03:20:22,037 -> 6.Filter phase...                                  |   3.48s |   3886 flocks
2018-05-31 03:20:26,684 -> Reporting locations...                             |   4.65s |  18546 points
2018-05-31 03:20:26,685 -> Setting mu=2,epsilon=30.0,cores=28,timestamp=6,dataset=berlin0-10
2018-05-31 03:20:33,694 -> A.Indexing points... [6.991s] [18546 results]
2018-05-31 03:20:43,315 -> B.Getting pairs... [9.621s] [5758 results]
2018-05-31 03:20:44,547 -> C.Computing centers... [1.232s] [11516 results]
2018-05-31 03:20:45,465 -> D.Indexing centers... [0.918s] [11516 results]
2018-05-31 03:20:51,898 -> E.Getting disks... [6.433s] [11516 results]
2018-05-31 03:20:52,120 -> F.Filtering less-than-mu disks... [0.222s] [11516 results]
2018-05-31 03:20:54,614 -> G.Prunning duplicate candidates... [2.494s] [6441 results]
2018-05-31 03:20:54,959 -> H.Indexing candidates... [2.839s] [6441 results]
2018-05-31 03:20:55,162 -> I.Getting expansions... [0.203s] [7165 results]
2018-05-31 03:20:55,321 -> J.Finding maximal disks... [0.159s] [3539 results]
2018-05-31 03:20:57,179 -> K.Prunning duplicates and subsets... [1.858s] [3533 results]
2018-05-31 03:20:57,179 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 03:20:57,179 ->   berlin0-10,   18546,  30.0,    28,  2,  30.48,    5758,     11516,         6441,       3533,  6
2018-05-31 03:20:57,649 -> Dropping indices...[0.470s]
2018-05-31 03:20:57,919 -> 1.Set of disks for t_i...                          |  31.24s |   3533 disks
2018-05-31 03:21:07,602 -> 2.Distance Join phase...                           |   9.68s |   9006 combinations
2018-05-31 03:34:39,344 -> 3.Getting candidates...                            | 811.74s |   3734 candidates
2018-05-31 03:34:41,315 -> 4.Found flocks...                                  |   1.94s |   3298 flocks
2018-05-31 03:34:50,069 -> 5.Updating times...                                |   3.11s |   3734 flocks
2018-05-31 03:34:54,021 -> 6.Filter phase...                                  |   3.95s |   3860 flocks
2018-05-31 03:34:58,633 -> Reporting locations...                             |   4.61s |  18546 points
2018-05-31 03:34:58,633 -> Setting mu=2,epsilon=30.0,cores=28,timestamp=7,dataset=berlin0-10
2018-05-31 03:35:05,702 -> A.Indexing points... [7.048s] [18546 results]
2018-05-31 03:35:15,203 -> B.Getting pairs... [9.501s] [5788 results]
2018-05-31 03:35:16,461 -> C.Computing centers... [1.258s] [11576 results]
2018-05-31 03:35:17,364 -> D.Indexing centers... [0.903s] [11576 results]
2018-05-31 03:35:23,909 -> E.Getting disks... [6.545s] [11576 results]
2018-05-31 03:35:24,212 -> F.Filtering less-than-mu disks... [0.303s] [11576 results]
2018-05-31 03:35:26,747 -> G.Prunning duplicate candidates... [2.535s] [6471 results]
2018-05-31 03:35:27,104 -> H.Indexing candidates... [2.892s] [6471 results]
2018-05-31 03:35:27,330 -> I.Getting expansions... [0.225s] [7215 results]
2018-05-31 03:35:27,583 -> J.Finding maximal disks... [0.253s] [3560 results]
2018-05-31 03:35:29,446 -> K.Prunning duplicates and subsets... [1.863s] [3552 results]
2018-05-31 03:35:29,446 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 03:35:29,446 ->   berlin0-10,   18546,  30.0,    28,  2,  30.79,    5788,     11576,         6471,       3552,  7
2018-05-31 03:35:29,984 -> Dropping indices...[0.538s]
2018-05-31 03:35:30,300 -> 1.Set of disks for t_i...                          |  31.67s |   3552 disks
2018-05-31 03:35:40,480 -> 2.Distance Join phase...                           |  10.18s |   8876 combinations
2018-05-31 03:48:40,145 -> 3.Getting candidates...                            | 779.67s |   3743 candidates
2018-05-31 03:48:41,941 -> 4.Found flocks...                                  |   1.75s |   3338 flocks
2018-05-31 03:48:51,903 -> 5.Updating times...                                |   1.83s |   3743 flocks
2018-05-31 03:48:54,951 -> 6.Filter phase...                                  |   3.05s |   3896 flocks
2018-05-31 03:48:59,494 -> Reporting locations...                             |   4.54s |  18546 points
2018-05-31 03:48:59,495 -> Setting mu=2,epsilon=30.0,cores=28,timestamp=8,dataset=berlin0-10
2018-05-31 03:49:04,458 -> A.Indexing points... [4.934s] [18546 results]
2018-05-31 03:49:10,906 -> B.Getting pairs... [6.448s] [5791 results]
2018-05-31 03:49:12,377 -> C.Computing centers... [1.471s] [11582 results]
2018-05-31 03:49:13,281 -> D.Indexing centers... [0.904s] [11582 results]
2018-05-31 03:49:18,690 -> E.Getting disks... [5.409s] [11582 results]
2018-05-31 03:49:19,040 -> F.Filtering less-than-mu disks... [0.350s] [11582 results]
2018-05-31 03:49:21,283 -> G.Prunning duplicate candidates... [2.243s] [6477 results]
2018-05-31 03:49:21,596 -> H.Indexing candidates... [2.556s] [6477 results]
2018-05-31 03:49:21,903 -> I.Getting expansions... [0.307s] [7307 results]
2018-05-31 03:49:22,150 -> J.Finding maximal disks... [0.247s] [3569 results]
2018-05-31 03:49:24,404 -> K.Prunning duplicates and subsets... [2.254s] [3561 results]
2018-05-31 03:49:24,404 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 03:49:24,404 ->   berlin0-10,   18546,  30.0,    28,  2,  24.88,    5791,     11582,         6477,       3561,  8
2018-05-31 03:49:24,978 -> Dropping indices...[0.574s]
2018-05-31 03:49:25,300 -> 1.Set of disks for t_i...                          |  25.81s |   3561 disks
2018-05-31 03:49:36,633 -> 2.Distance Join phase...                           |  11.33s |   8735 combinations
2018-05-31 04:03:36,796 -> 3.Getting candidates...                            | 840.16s |   3759 candidates
2018-05-31 04:03:38,994 -> 4.Found flocks...                                  |   2.15s |   3326 flocks
2018-05-31 04:03:49,189 -> 5.Updating times...                                |   3.12s |   3759 flocks
2018-05-31 04:03:52,940 -> 6.Filter phase...                                  |   3.75s |   3891 flocks
2018-05-31 04:03:57,414 -> Reporting locations...                             |   4.47s |  18546 points
2018-05-31 04:03:57,414 -> Setting mu=2,epsilon=30.0,cores=28,timestamp=9,dataset=berlin0-10
2018-05-31 04:04:06,776 -> A.Indexing points... [9.333s] [18546 results]
2018-05-31 04:04:17,625 -> B.Getting pairs... [10.849s] [5802 results]
2018-05-31 04:04:18,882 -> C.Computing centers... [1.256s] [11604 results]
2018-05-31 04:04:19,778 -> D.Indexing centers... [0.896s] [11604 results]
2018-05-31 04:04:26,871 -> E.Getting disks... [7.069s] [11604 results]
2018-05-31 04:04:27,147 -> F.Filtering less-than-mu disks... [0.276s] [11604 results]
2018-05-31 04:04:29,942 -> G.Prunning duplicate candidates... [2.795s] [6488 results]
2018-05-31 04:04:30,252 -> H.Indexing candidates... [3.105s] [6488 results]
2018-05-31 04:04:30,486 -> I.Getting expansions... [0.234s] [7309 results]
2018-05-31 04:04:30,719 -> J.Finding maximal disks... [0.233s] [3566 results]
2018-05-31 04:04:32,932 -> K.Prunning duplicates and subsets... [2.212s] [3559 results]
2018-05-31 04:04:32,932 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 04:04:32,932 ->   berlin0-10,   18546,  30.0,    28,  2,  35.49,    5802,     11604,         6488,       3559,  9
2018-05-31 04:04:33,581 -> Dropping indices...[0.648s]
2018-05-31 04:04:33,866 -> 1.Set of disks for t_i...                          |  36.45s |   3559 disks
2018-05-31 04:04:44,741 -> 2.Distance Join phase...                           |  10.87s |   8579 combinations
2018-05-31 04:17:41,160 -> 3.Getting candidates...                            | 776.42s |   3773 candidates
2018-05-31 04:17:43,537 -> 4.Found flocks...                                  |   2.34s |   3335 flocks
2018-05-31 04:17:55,607 -> 5.Updating times...                                |   3.43s |   3773 flocks
2018-05-31 04:17:59,868 -> 6.Filter phase...                                  |   4.26s |   3909 flocks
2018-05-31 04:18:04,339 -> Reporting locations...                             |   4.47s |  18546 points
2018-05-31 04:18:04,340 -> Setting mu=2,epsilon=30.0,cores=28,timestamp=10,dataset=berlin0-10
2018-05-31 04:18:11,948 -> A.Indexing points... [7.536s] [18546 results]
2018-05-31 04:18:22,971 -> B.Getting pairs... [11.023s] [5797 results]
2018-05-31 04:18:24,336 -> C.Computing centers... [1.365s] [11594 results]
2018-05-31 04:18:25,230 -> D.Indexing centers... [0.894s] [11594 results]
2018-05-31 04:18:32,378 -> E.Getting disks... [7.148s] [11594 results]
2018-05-31 04:18:32,602 -> F.Filtering less-than-mu disks... [0.224s] [11594 results]
2018-05-31 04:18:35,183 -> G.Prunning duplicate candidates... [2.581s] [6486 results]
2018-05-31 04:18:35,489 -> H.Indexing candidates... [2.887s] [6486 results]
2018-05-31 04:18:35,697 -> I.Getting expansions... [0.208s] [7322 results]
2018-05-31 04:18:35,927 -> J.Finding maximal disks... [0.230s] [3565 results]
2018-05-31 04:18:37,859 -> K.Prunning duplicates and subsets... [1.932s] [3557 results]
2018-05-31 04:18:37,933 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 04:18:37,933 ->   berlin0-10,   18546,  30.0,    28,  2,  33.52,    5797,     11594,         6486,       3557, 10
2018-05-31 04:18:38,724 -> Dropping indices...[0.791s]
2018-05-31 04:18:39,055 -> 1.Set of disks for t_i...                          |  34.72s |   3557 disks
2018-05-31 04:18:50,476 -> 2.Distance Join phase...                           |  11.42s |   8482 combinations
2018-05-31 04:31:10,979 -> 3.Getting candidates...                            | 740.50s |   3764 candidates
2018-05-31 04:31:13,830 -> 4.Found flocks...                                  |   2.80s |   3319 flocks
2018-05-31 04:31:27,831 -> 5.Updating times...                                |   3.75s |   3764 flocks
2018-05-31 04:31:32,233 -> 6.Filter phase...                                  |   4.40s |   3884 flocks
2018-05-31 04:31:32,233 -> 

PFLOCK_SJ	30.0	2	5	23129

2018-05-31 04:31:40,512 -> Running SpatialJoin...                             | 8852.21s |  23129 flocks
2018-05-31 04:31:40,512 -> method=SpatialJoin,cores=28,epsilon=30.0,mu=2,delta=5,time=8852.205,master=spark://169.235.27.134:7077
2018-05-31 04:31:40,512 -> Closing app...
acald013@dblab-rack15: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
FLOCKFINDER=SpatialJoin;TIME=Thu May 31 04:31:49 PDT 2018;RUN=1527757431;NODES=4;ESTART=;EEND=;ESTEP=;MU=;DELTA=5;SCRIPT=MuBenchmarker;EVENT=End
FLOCKFINDER=MergeLast;TIME=Thu May 31 04:31:49 PDT 2018;RUN=1527766309;NODES=4;ESTART=;EEND=;ESTEP=;MU=;DELTA=5;SCRIPT=MuBenchmarker;EVENT=Start
WARNING:root:Setting 4 nodes...
acald013@dblab-rack12: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack15: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack14: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack11: no org.apache.spark.deploy.worker.Worker to stop
no org.apache.spark.deploy.master.Master to stop
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack15: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack15.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
WARNING:root:4 nodes has been set...
2018-05-31 04:32:03,158 -> Starting app...
2018-05-31 04:32:06,524 -> Starting session                                   |   3.37s |      0 
2018-05-31 04:32:06,537 -> Setting paramaters                                 |   0.01s |      0 
2018-05-31 04:32:10,384 -> Reading data                                       |   3.85s | 203106 points
2018-05-31 04:32:12,904 -> Extracting timestamps                              |   2.52s |     11 timestamps
2018-05-31 04:32:12,909 -> === MergeLast Start ===
2018-05-31 04:32:18,160 -> Reporting locations at t=0...                      |   5.07s |  18093 points
2018-05-31 04:32:18,176 -> Setting mu=2,epsilon=30.0,cores=28,timestamp=0,dataset=berlin0-10
2018-05-31 04:32:27,258 -> A.Indexing points... [9.036s] [18093 results]
2018-05-31 04:32:34,920 -> B.Getting pairs... [7.661s] [5511 results]
2018-05-31 04:32:37,040 -> C.Computing centers... [2.120s] [11022 results]
2018-05-31 04:32:38,470 -> D.Indexing centers... [1.429s] [11022 results]
2018-05-31 04:32:44,667 -> E.Getting disks... [6.197s] [11022 results]
2018-05-31 04:32:45,022 -> F.Filtering less-than-mu disks... [0.355s] [11022 results]
2018-05-31 04:32:49,071 -> G.Prunning duplicate candidates... [4.049s] [6157 results]
2018-05-31 04:32:49,657 -> H.Indexing candidates... [4.635s] [6157 results]
2018-05-31 04:32:49,987 -> I.Getting expansions... [0.330s] [6877 results]
2018-05-31 04:32:50,653 -> J.Finding maximal disks... [0.666s] [3432 results]
2018-05-31 04:32:52,849 -> K.Prunning duplicates and subsets... [2.196s] [3427 results]
2018-05-31 04:32:52,849 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 04:32:52,849 ->   berlin0-10,   18093,  30.0,    28,  2,  34.63,    5511,     11022,         6157,       3427,  0
2018-05-31 04:32:52,928 -> Dropping indices...[0.079s]
2018-05-31 04:32:53,428 -> 1.Set of disks for t_i...                          |  35.27s |   3427 disks
2018-05-31 04:32:58,099 -> Reporting locations at t=4...                      |   4.67s |  18548 points
2018-05-31 04:32:58,100 -> Setting mu=2,epsilon=30.0,cores=28,timestamp=4,dataset=berlin0-10
2018-05-31 04:33:05,662 -> A.Indexing points... [7.539s] [18548 results]
2018-05-31 04:33:15,967 -> B.Getting pairs... [10.305s] [5775 results]
2018-05-31 04:33:17,487 -> C.Computing centers... [1.520s] [11550 results]
2018-05-31 04:33:18,537 -> D.Indexing centers... [1.050s] [11550 results]
2018-05-31 04:33:25,814 -> E.Getting disks... [7.277s] [11550 results]
2018-05-31 04:33:26,066 -> F.Filtering less-than-mu disks... [0.252s] [11550 results]
2018-05-31 04:33:28,380 -> G.Prunning duplicate candidates... [2.314s] [6486 results]
2018-05-31 04:33:28,749 -> H.Indexing candidates... [2.683s] [6486 results]
2018-05-31 04:33:29,095 -> I.Getting expansions... [0.346s] [7196 results]
2018-05-31 04:33:29,304 -> J.Finding maximal disks... [0.209s] [3554 results]
2018-05-31 04:33:32,225 -> K.Prunning duplicates and subsets... [2.921s] [3546 results]
2018-05-31 04:33:32,225 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 04:33:32,225 ->   berlin0-10,   18548,  30.0,    28,  2,  34.10,    5775,     11550,         6486,       3546,  4
2018-05-31 04:33:32,324 -> Dropping indices...[0.099s]
2018-05-31 04:33:32,608 -> 2.Set of disks for t_i+delta...                    |  34.51s |   3427 disks
2018-05-31 04:33:54,376 -> 3.Joining timestams                                |  21.77s |   3866 candidates
2018-05-31 04:45:32,983 -> Checking internal timestamps                       | 698.61s |   3237 flocks
2018-05-31 04:45:37,860 -> Reporting locations at t=1...                      |   4.43s |  18245 points
2018-05-31 04:45:37,860 -> Setting mu=2,epsilon=30.0,cores=28,timestamp=1,dataset=berlin0-10
2018-05-31 04:45:42,285 -> A.Indexing points... [4.405s] [18245 results]
2018-05-31 04:45:47,250 -> B.Getting pairs... [4.965s] [5629 results]
2018-05-31 04:45:48,606 -> C.Computing centers... [1.356s] [11258 results]
2018-05-31 04:45:49,619 -> D.Indexing centers... [1.013s] [11258 results]
2018-05-31 04:45:54,330 -> E.Getting disks... [4.711s] [11258 results]
2018-05-31 04:45:54,588 -> F.Filtering less-than-mu disks... [0.258s] [11258 results]
2018-05-31 04:45:56,769 -> G.Prunning duplicate candidates... [2.181s] [6297 results]
2018-05-31 04:45:57,121 -> H.Indexing candidates... [2.533s] [6297 results]
2018-05-31 04:45:57,331 -> I.Getting expansions... [0.210s] [6982 results]
2018-05-31 04:45:57,506 -> J.Finding maximal disks... [0.174s] [3482 results]
2018-05-31 04:45:58,954 -> K.Prunning duplicates and subsets... [1.448s] [3478 results]
2018-05-31 04:45:58,954 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 04:45:58,965 ->   berlin0-10,   18245,  30.0,    28,  2,  21.07,    5629,     11258,         6297,       3478,  1
2018-05-31 04:45:59,062 -> Dropping indices...[0.097s]
2018-05-31 04:45:59,303 -> 1.Set of disks for t_i...                          |  21.44s |   3478 disks
2018-05-31 04:46:03,657 -> Reporting locations at t=5...                      |   4.35s |  18548 points
2018-05-31 04:46:03,658 -> Setting mu=2,epsilon=30.0,cores=28,timestamp=5,dataset=berlin0-10
2018-05-31 04:46:10,693 -> A.Indexing points... [7.013s] [18548 results]
2018-05-31 04:46:20,736 -> B.Getting pairs... [10.043s] [5765 results]
2018-05-31 04:46:22,076 -> C.Computing centers... [1.340s] [11530 results]
2018-05-31 04:46:22,985 -> D.Indexing centers... [0.909s] [11530 results]
2018-05-31 04:46:30,001 -> E.Getting disks... [7.016s] [11530 results]
2018-05-31 04:46:30,269 -> F.Filtering less-than-mu disks... [0.268s] [11530 results]
2018-05-31 04:46:32,763 -> G.Prunning duplicate candidates... [2.493s] [6453 results]
2018-05-31 04:46:33,138 -> H.Indexing candidates... [2.868s] [6453 results]
2018-05-31 04:46:33,461 -> I.Getting expansions... [0.322s] [7126 results]
2018-05-31 04:46:33,658 -> J.Finding maximal disks... [0.197s] [3550 results]
2018-05-31 04:46:36,400 -> K.Prunning duplicates and subsets... [2.742s] [3540 results]
2018-05-31 04:46:36,401 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 04:46:36,401 ->   berlin0-10,   18548,  30.0,    28,  2,  32.72,    5765,     11530,         6453,       3540,  5
2018-05-31 04:46:36,519 -> Dropping indices...[0.118s]
2018-05-31 04:46:36,793 -> 2.Set of disks for t_i+delta...                    |  33.14s |   3478 disks
2018-05-31 04:47:00,252 -> 3.Joining timestams                                |  23.46s |   3941 candidates
2018-05-31 04:59:58,367 -> Checking internal timestamps                       | 778.11s |   3276 flocks
2018-05-31 05:00:03,766 -> Reporting locations at t=2...                      |   4.45s |  18394 points
2018-05-31 05:00:03,767 -> Setting mu=2,epsilon=30.0,cores=28,timestamp=2,dataset=berlin0-10
2018-05-31 05:00:08,431 -> A.Indexing points... [4.622s] [18394 results]
2018-05-31 05:00:13,358 -> B.Getting pairs... [4.927s] [5701 results]
2018-05-31 05:00:14,753 -> C.Computing centers... [1.395s] [11402 results]
2018-05-31 05:00:15,671 -> D.Indexing centers... [0.918s] [11402 results]
2018-05-31 05:00:20,102 -> E.Getting disks... [4.430s] [11402 results]
2018-05-31 05:00:20,326 -> F.Filtering less-than-mu disks... [0.224s] [11402 results]
2018-05-31 05:00:22,170 -> G.Prunning duplicate candidates... [1.844s] [6373 results]
2018-05-31 05:00:22,510 -> H.Indexing candidates... [2.184s] [6373 results]
2018-05-31 05:00:22,771 -> I.Getting expansions... [0.260s] [7107 results]
2018-05-31 05:00:22,980 -> J.Finding maximal disks... [0.209s] [3517 results]
2018-05-31 05:00:24,386 -> K.Prunning duplicates and subsets... [1.406s] [3511 results]
2018-05-31 05:00:24,386 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 05:00:24,386 ->   berlin0-10,   18394,  30.0,    28,  2,  20.58,    5701,     11402,         6373,       3511,  2
2018-05-31 05:00:24,546 -> Dropping indices...[0.159s]
2018-05-31 05:00:24,864 -> 1.Set of disks for t_i...                          |  21.10s |   3511 disks
2018-05-31 05:00:29,222 -> Reporting locations at t=6...                      |   4.36s |  18546 points
2018-05-31 05:00:29,222 -> Setting mu=2,epsilon=30.0,cores=28,timestamp=6,dataset=berlin0-10
2018-05-31 05:00:36,228 -> A.Indexing points... [6.983s] [18546 results]
2018-05-31 05:00:46,258 -> B.Getting pairs... [10.029s] [5758 results]
2018-05-31 05:00:47,573 -> C.Computing centers... [1.315s] [11516 results]
2018-05-31 05:00:48,684 -> D.Indexing centers... [1.110s] [11516 results]
2018-05-31 05:00:55,633 -> E.Getting disks... [6.949s] [11516 results]
2018-05-31 05:00:55,907 -> F.Filtering less-than-mu disks... [0.274s] [11516 results]
2018-05-31 05:00:58,409 -> G.Prunning duplicate candidates... [2.502s] [6441 results]
2018-05-31 05:00:58,751 -> H.Indexing candidates... [2.844s] [6441 results]
2018-05-31 05:00:59,034 -> I.Getting expansions... [0.283s] [7165 results]
2018-05-31 05:00:59,829 -> J.Finding maximal disks... [0.795s] [3539 results]
2018-05-31 05:01:02,265 -> K.Prunning duplicates and subsets... [2.436s] [3533 results]
2018-05-31 05:01:02,265 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 05:01:02,266 ->   berlin0-10,   18546,  30.0,    28,  2,  33.02,    5758,     11516,         6441,       3533,  6
2018-05-31 05:01:02,482 -> Dropping indices...[0.195s]
2018-05-31 05:01:02,794 -> 2.Set of disks for t_i+delta...                    |  33.57s |   3511 disks
2018-05-31 05:01:25,185 -> 3.Joining timestams                                |  22.39s |   3948 candidates
2018-05-31 05:15:43,220 -> Checking internal timestamps                       | 858.04s |   3298 flocks
2018-05-31 05:15:49,784 -> Reporting locations at t=3...                      |   4.49s |  18548 points
2018-05-31 05:15:49,784 -> Setting mu=2,epsilon=30.0,cores=28,timestamp=3,dataset=berlin0-10
2018-05-31 05:15:56,702 -> A.Indexing points... [6.899s] [18548 results]
2018-05-31 05:16:06,764 -> B.Getting pairs... [10.062s] [5768 results]
2018-05-31 05:16:08,057 -> C.Computing centers... [1.293s] [11536 results]
2018-05-31 05:16:09,085 -> D.Indexing centers... [1.028s] [11536 results]
2018-05-31 05:16:15,653 -> E.Getting disks... [6.568s] [11536 results]
2018-05-31 05:16:15,893 -> F.Filtering less-than-mu disks... [0.240s] [11536 results]
2018-05-31 05:16:18,151 -> G.Prunning duplicate candidates... [2.258s] [6465 results]
2018-05-31 05:16:18,479 -> H.Indexing candidates... [2.586s] [6465 results]
2018-05-31 05:16:18,685 -> I.Getting expansions... [0.206s] [7226 results]
2018-05-31 05:16:18,891 -> J.Finding maximal disks... [0.206s] [3566 results]
2018-05-31 05:16:21,026 -> K.Prunning duplicates and subsets... [2.135s] [3557 results]
2018-05-31 05:16:21,026 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 05:16:21,026 ->   berlin0-10,   18548,  30.0,    28,  2,  31.22,    5768,     11536,         6465,       3557,  3
2018-05-31 05:16:21,246 -> Dropping indices...[0.220s]
2018-05-31 05:16:21,518 -> 1.Set of disks for t_i...                          |  31.73s |   3557 disks
2018-05-31 05:16:25,845 -> Reporting locations at t=7...                      |   4.33s |  18546 points
2018-05-31 05:16:25,846 -> Setting mu=2,epsilon=30.0,cores=28,timestamp=7,dataset=berlin0-10
2018-05-31 05:16:32,656 -> A.Indexing points... [6.790s] [18546 results]
2018-05-31 05:16:42,898 -> B.Getting pairs... [10.241s] [5788 results]
2018-05-31 05:16:44,236 -> C.Computing centers... [1.338s] [11576 results]
2018-05-31 05:16:45,165 -> D.Indexing centers... [0.929s] [11576 results]
2018-05-31 05:16:52,244 -> E.Getting disks... [7.079s] [11576 results]
2018-05-31 05:16:52,489 -> F.Filtering less-than-mu disks... [0.245s] [11576 results]
2018-05-31 05:16:55,052 -> G.Prunning duplicate candidates... [2.562s] [6471 results]
2018-05-31 05:16:55,412 -> H.Indexing candidates... [2.922s] [6471 results]
2018-05-31 05:16:55,649 -> I.Getting expansions... [0.237s] [7215 results]
2018-05-31 05:16:55,841 -> J.Finding maximal disks... [0.192s] [3560 results]
2018-05-31 05:16:57,977 -> K.Prunning duplicates and subsets... [2.136s] [3552 results]
2018-05-31 05:16:57,977 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 05:16:57,977 ->   berlin0-10,   18546,  30.0,    28,  2,  32.11,    5788,     11576,         6471,       3552,  7
2018-05-31 05:16:58,218 -> Dropping indices...[0.241s]
2018-05-31 05:16:58,487 -> 2.Set of disks for t_i+delta...                    |  32.64s |   3557 disks
2018-05-31 05:17:21,629 -> 3.Joining timestams                                |  23.14s |   3989 candidates
2018-05-31 05:34:21,999 -> Checking internal timestamps                       | 1020.37s |   3338 flocks
2018-05-31 05:34:27,932 -> Reporting locations at t=4...                      |   4.38s |  18548 points
2018-05-31 05:34:28,437 -> 1.Set of disks for t_i...                          |   0.51s |   3546 disks
2018-05-31 05:34:32,691 -> Reporting locations at t=8...                      |   4.25s |  18546 points
2018-05-31 05:34:32,692 -> Setting mu=2,epsilon=30.0,cores=28,timestamp=8,dataset=berlin0-10
2018-05-31 05:34:37,784 -> A.Indexing points... [5.049s] [18546 results]
2018-05-31 05:34:44,605 -> B.Getting pairs... [6.821s] [5791 results]
2018-05-31 05:34:45,895 -> C.Computing centers... [1.290s] [11582 results]
2018-05-31 05:34:46,850 -> D.Indexing centers... [0.955s] [11582 results]
2018-05-31 05:34:52,697 -> E.Getting disks... [5.847s] [11582 results]
2018-05-31 05:34:52,965 -> F.Filtering less-than-mu disks... [0.268s] [11582 results]
2018-05-31 05:34:55,368 -> G.Prunning duplicate candidates... [2.403s] [6477 results]
2018-05-31 05:34:55,754 -> H.Indexing candidates... [2.789s] [6477 results]
2018-05-31 05:34:56,183 -> I.Getting expansions... [0.429s] [7307 results]
2018-05-31 05:34:56,444 -> J.Finding maximal disks... [0.261s] [3569 results]
2018-05-31 05:34:58,275 -> K.Prunning duplicates and subsets... [1.831s] [3561 results]
2018-05-31 05:34:58,275 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 05:34:58,275 ->   berlin0-10,   18546,  30.0,    28,  2,  25.54,    5791,     11582,         6477,       3561,  8
2018-05-31 05:34:58,572 -> Dropping indices...[0.297s]
2018-05-31 05:34:58,896 -> 2.Set of disks for t_i+delta...                    |  26.21s |   3546 disks
2018-05-31 05:35:24,800 -> 3.Joining timestams                                |  25.90s |   3972 candidates
2018-05-31 05:51:00,792 -> Checking internal timestamps                       | 935.99s |   3326 flocks
2018-05-31 05:51:06,734 -> Reporting locations at t=5...                      |   4.37s |  18548 points
2018-05-31 05:51:07,235 -> 1.Set of disks for t_i...                          |   0.50s |   3540 disks
2018-05-31 05:51:11,453 -> Reporting locations at t=9...                      |   4.22s |  18546 points
2018-05-31 05:51:11,453 -> Setting mu=2,epsilon=30.0,cores=28,timestamp=9,dataset=berlin0-10
2018-05-31 05:51:19,379 -> A.Indexing points... [7.875s] [18546 results]
2018-05-31 05:51:31,355 -> B.Getting pairs... [11.976s] [5802 results]
2018-05-31 05:51:32,624 -> C.Computing centers... [1.269s] [11604 results]
2018-05-31 05:51:33,556 -> D.Indexing centers... [0.932s] [11604 results]
2018-05-31 05:51:41,317 -> E.Getting disks... [7.761s] [11604 results]
2018-05-31 05:51:41,538 -> F.Filtering less-than-mu disks... [0.220s] [11604 results]
2018-05-31 05:51:44,519 -> G.Prunning duplicate candidates... [2.981s] [6488 results]
2018-05-31 05:51:44,918 -> H.Indexing candidates... [3.380s] [6488 results]
2018-05-31 05:51:45,124 -> I.Getting expansions... [0.205s] [7309 results]
2018-05-31 05:51:45,288 -> J.Finding maximal disks... [0.163s] [3566 results]
2018-05-31 05:51:47,892 -> K.Prunning duplicates and subsets... [2.603s] [3559 results]
2018-05-31 05:51:47,892 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 05:51:47,892 ->   berlin0-10,   18546,  30.0,    28,  2,  36.39,    5802,     11604,         6488,       3559,  9
2018-05-31 05:51:48,343 -> Dropping indices...[0.450s]
2018-05-31 05:51:48,711 -> 2.Set of disks for t_i+delta...                    |  37.26s |   3540 disks
2018-05-31 05:52:12,125 -> 3.Joining timestams                                |  23.41s |   3952 candidates
2018-05-31 06:07:57,679 -> Checking internal timestamps                       | 945.55s |   3335 flocks
2018-05-31 06:08:03,863 -> Reporting locations at t=6...                      |   4.41s |  18546 points
2018-05-31 06:08:04,472 -> 1.Set of disks for t_i...                          |   0.61s |   3533 disks
2018-05-31 06:08:08,717 -> Reporting locations at t=10...                     |   4.25s |  18546 points
2018-05-31 06:08:08,717 -> Setting mu=2,epsilon=30.0,cores=28,timestamp=10,dataset=berlin0-10
2018-05-31 06:08:16,722 -> A.Indexing points... [7.962s] [18546 results]
2018-05-31 06:08:28,259 -> B.Getting pairs... [11.537s] [5797 results]
2018-05-31 06:08:29,553 -> C.Computing centers... [1.294s] [11594 results]
2018-05-31 06:08:30,568 -> D.Indexing centers... [1.015s] [11594 results]
2018-05-31 06:08:38,024 -> E.Getting disks... [7.456s] [11594 results]
2018-05-31 06:08:38,257 -> F.Filtering less-than-mu disks... [0.233s] [11594 results]
2018-05-31 06:08:40,687 -> G.Prunning duplicate candidates... [2.430s] [6486 results]
2018-05-31 06:08:41,046 -> H.Indexing candidates... [2.789s] [6486 results]
2018-05-31 06:08:41,398 -> I.Getting expansions... [0.352s] [7322 results]
2018-05-31 06:08:41,605 -> J.Finding maximal disks... [0.207s] [3565 results]
2018-05-31 06:08:43,746 -> K.Prunning duplicates and subsets... [2.141s] [3557 results]
2018-05-31 06:08:43,746 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 06:08:43,746 ->   berlin0-10,   18546,  30.0,    28,  2,  34.99,    5797,     11594,         6486,       3557, 10
2018-05-31 06:08:44,204 -> Dropping indices...[0.458s]
2018-05-31 06:08:44,531 -> 2.Set of disks for t_i+delta...                    |  35.81s |   3533 disks
2018-05-31 06:09:07,149 -> 3.Joining timestams                                |  22.62s |   3905 candidates
2018-05-31 06:25:21,983 -> Checking internal timestamps                       | 974.83s |   3319 flocks
2018-05-31 06:25:23,977 -> 

PFLOCK_ML	30.0	2	5	23129

2018-05-31 06:25:25,842 -> Running MergeLast...                               | 6792.93s |  23129 flocks
2018-05-31 06:25:25,842 -> method=MergeLast,cores=28,epsilon=30.0,mu=2,delta=5,time=6792.933,master=spark://169.235.27.134:7077
2018-05-31 06:25:25,842 -> Closing app...
acald013@dblab-rack15: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
FLOCKFINDER=MergeLast;TIME=Thu May 31 06:25:33 PDT 2018;RUN=1527766309;NODES=4;ESTART=;EEND=;ESTEP=;MU=;DELTA=5;SCRIPT=MuBenchmarker;EVENT=End
FLOCKFINDER=SpatialJoin;TIME=Thu May 31 06:25:33 PDT 2018;RUN=1527773133;NODES=4;ESTART=;EEND=;ESTEP=;MU=;DELTA=5;SCRIPT=MuBenchmarker;EVENT=Start
WARNING:root:Setting 4 nodes...
acald013@dblab-rack12: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack15: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack11: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack14: no org.apache.spark.deploy.worker.Worker to stop
no org.apache.spark.deploy.master.Master to stop
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack15: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack15.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
WARNING:root:4 nodes has been set...
2018-05-31 06:25:49,529 -> Starting app...
2018-05-31 06:25:52,574 -> Starting session                                   |   3.05s |      0 
2018-05-31 06:25:52,587 -> Setting paramaters                                 |   0.01s |      0 
2018-05-31 06:25:58,081 -> Reading data                                       |   5.49s | 203106 points
2018-05-31 06:26:00,978 -> Extracting timestamps                              |   2.90s |     11 timestamps
2018-05-31 06:26:00,984 -> === SpatialJoin Start ===
2018-05-31 06:26:15,318 -> Reporting locations...                             |  14.07s |  18093 points
2018-05-31 06:26:15,332 -> Setting mu=3,epsilon=30.0,cores=28,timestamp=0,dataset=berlin0-10
2018-05-31 06:26:25,891 -> A.Indexing points... [10.506s] [18093 results]
2018-05-31 06:26:34,013 -> B.Getting pairs... [8.122s] [5511 results]
2018-05-31 06:26:36,242 -> C.Computing centers... [2.228s] [11022 results]
2018-05-31 06:26:37,645 -> D.Indexing centers... [1.403s] [11022 results]
2018-05-31 06:26:43,545 -> E.Getting disks... [5.900s] [11022 results]
2018-05-31 06:26:43,934 -> F.Filtering less-than-mu disks... [0.388s] [3372 results]
2018-05-31 06:26:46,763 -> G.Prunning duplicate candidates... [2.829s] [1700 results]
2018-05-31 06:26:47,281 -> H.Indexing candidates... [3.347s] [1700 results]
2018-05-31 06:26:47,519 -> I.Getting expansions... [0.238s] [2699 results]
2018-05-31 06:26:48,395 -> J.Finding maximal disks... [0.876s] [752 results]
2018-05-31 06:26:50,306 -> K.Prunning duplicates and subsets... [1.910s] [749 results]
2018-05-31 06:26:50,306 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 06:26:50,307 ->   berlin0-10,   18093,  30.0,    28,  3,  34.92,    5511,     11022,         1700,        749,  0
2018-05-31 06:26:50,384 -> Dropping indices...[0.077s]
2018-05-31 06:26:50,734 -> 1.Set of disks for t_i...                          |  35.42s |    749 disks
2018-05-31 06:26:51,161 -> 4.Found flocks...                                  |   0.43s |      0 flocks
2018-05-31 06:26:52,043 -> 5.Updating times...                                |   0.58s |    749 flocks
2018-05-31 06:26:53,064 -> 6.Filter phase...                                  |   1.02s |    749 flocks
2018-05-31 06:27:06,626 -> Reporting locations...                             |  13.56s |  18245 points
2018-05-31 06:27:06,626 -> Setting mu=3,epsilon=30.0,cores=28,timestamp=1,dataset=berlin0-10
2018-05-31 06:27:12,609 -> A.Indexing points... [5.961s] [18245 results]
2018-05-31 06:27:18,185 -> B.Getting pairs... [5.576s] [5629 results]
2018-05-31 06:27:19,650 -> C.Computing centers... [1.465s] [11258 results]
2018-05-31 06:27:20,749 -> D.Indexing centers... [1.099s] [11258 results]
2018-05-31 06:27:25,971 -> E.Getting disks... [5.222s] [11258 results]
2018-05-31 06:27:26,227 -> F.Filtering less-than-mu disks... [0.255s] [3500 results]
2018-05-31 06:27:28,007 -> G.Prunning duplicate candidates... [1.780s] [1778 results]
2018-05-31 06:27:28,407 -> H.Indexing candidates... [2.180s] [1778 results]
2018-05-31 06:27:28,588 -> I.Getting expansions... [0.181s] [2890 results]
2018-05-31 06:27:28,766 -> J.Finding maximal disks... [0.178s] [770 results]
2018-05-31 06:27:30,194 -> K.Prunning duplicates and subsets... [1.428s] [767 results]
2018-05-31 06:27:30,194 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 06:27:30,194 ->   berlin0-10,   18245,  30.0,    28,  3,  23.55,    5629,     11258,         1778,        767,  1
2018-05-31 06:27:30,283 -> Dropping indices...[0.089s]
2018-05-31 06:27:30,564 -> 1.Set of disks for t_i...                          |  23.94s |    767 disks
2018-05-31 06:27:34,825 -> 2.Distance Join phase...                           |   4.26s |   2154 combinations
2018-05-31 06:27:43,042 -> 3.Getting candidates...                            |   8.22s |    725 candidates
2018-05-31 06:27:43,785 -> 4.Found flocks...                                  |   0.74s |      0 flocks
2018-05-31 06:27:46,297 -> 5.Updating times...                                |   1.48s |    725 flocks
2018-05-31 06:27:48,962 -> 6.Filter phase...                                  |   2.67s |    810 flocks
2018-05-31 06:28:02,906 -> Reporting locations...                             |  13.94s |  18394 points
2018-05-31 06:28:02,907 -> Setting mu=3,epsilon=30.0,cores=28,timestamp=2,dataset=berlin0-10
2018-05-31 06:28:08,655 -> A.Indexing points... [5.728s] [18394 results]
2018-05-31 06:28:13,834 -> B.Getting pairs... [5.179s] [5701 results]
2018-05-31 06:28:15,229 -> C.Computing centers... [1.395s] [11402 results]
2018-05-31 06:28:16,323 -> D.Indexing centers... [1.094s] [11402 results]
2018-05-31 06:28:21,333 -> E.Getting disks... [5.010s] [11402 results]
2018-05-31 06:28:21,675 -> F.Filtering less-than-mu disks... [0.342s] [3535 results]
2018-05-31 06:28:23,592 -> G.Prunning duplicate candidates... [1.917s] [1807 results]
2018-05-31 06:28:23,966 -> H.Indexing candidates... [2.291s] [1807 results]
2018-05-31 06:28:24,144 -> I.Getting expansions... [0.178s] [2902 results]
2018-05-31 06:28:24,316 -> J.Finding maximal disks... [0.172s] [776 results]
2018-05-31 06:28:25,647 -> K.Prunning duplicates and subsets... [1.331s] [774 results]
2018-05-31 06:28:25,647 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 06:28:25,647 ->   berlin0-10,   18394,  30.0,    28,  3,  22.72,    5701,     11402,         1807,        774,  2
2018-05-31 06:28:25,788 -> Dropping indices...[0.141s]
2018-05-31 06:28:26,071 -> 1.Set of disks for t_i...                          |  23.17s |    774 disks
2018-05-31 06:28:34,788 -> 2.Distance Join phase...                           |   8.72s |   2614 combinations
2018-05-31 06:28:49,662 -> 3.Getting candidates...                            |  14.87s |    791 candidates
2018-05-31 06:28:50,580 -> 4.Found flocks...                                  |   0.92s |      0 flocks
2018-05-31 06:28:53,973 -> 5.Updating times...                                |   1.63s |    791 flocks
2018-05-31 06:28:56,914 -> 6.Filter phase...                                  |   2.94s |    858 flocks
2018-05-31 06:29:10,514 -> Reporting locations...                             |  13.60s |  18548 points
2018-05-31 06:29:10,514 -> Setting mu=3,epsilon=30.0,cores=28,timestamp=3,dataset=berlin0-10
2018-05-31 06:29:18,145 -> A.Indexing points... [7.611s] [18548 results]
2018-05-31 06:29:27,946 -> B.Getting pairs... [9.801s] [5768 results]
2018-05-31 06:29:29,313 -> C.Computing centers... [1.367s] [11536 results]
2018-05-31 06:29:30,408 -> D.Indexing centers... [1.094s] [11536 results]
2018-05-31 06:29:37,179 -> E.Getting disks... [6.770s] [11536 results]
2018-05-31 06:29:37,450 -> F.Filtering less-than-mu disks... [0.271s] [3584 results]
2018-05-31 06:29:39,886 -> G.Prunning duplicate candidates... [2.435s] [1848 results]
2018-05-31 06:29:40,237 -> H.Indexing candidates... [2.786s] [1848 results]
2018-05-31 06:29:40,455 -> I.Getting expansions... [0.218s] [3000 results]
2018-05-31 06:29:40,612 -> J.Finding maximal disks... [0.156s] [787 results]
2018-05-31 06:29:42,592 -> K.Prunning duplicates and subsets... [1.980s] [785 results]
2018-05-31 06:29:42,592 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 06:29:42,592 ->   berlin0-10,   18548,  30.0,    28,  3,  32.06,    5768,     11536,         1848,        785,  3
2018-05-31 06:29:42,805 -> Dropping indices...[0.213s]
2018-05-31 06:29:43,094 -> 1.Set of disks for t_i...                          |  32.58s |    785 disks
2018-05-31 06:29:52,545 -> 2.Distance Join phase...                           |   9.45s |   2894 combinations
2018-05-31 06:30:09,821 -> 3.Getting candidates...                            |  17.28s |    844 candidates
2018-05-31 06:30:10,830 -> 4.Found flocks...                                  |   1.01s |      0 flocks
2018-05-31 06:30:15,048 -> 5.Updating times...                                |   1.74s |    844 flocks
2018-05-31 06:30:17,785 -> 6.Filter phase...                                  |   2.74s |    908 flocks
2018-05-31 06:30:31,460 -> Reporting locations...                             |  13.68s |  18548 points
2018-05-31 06:30:31,460 -> Setting mu=3,epsilon=30.0,cores=28,timestamp=4,dataset=berlin0-10
2018-05-31 06:30:39,192 -> A.Indexing points... [7.712s] [18548 results]
2018-05-31 06:30:48,775 -> B.Getting pairs... [9.583s] [5775 results]
2018-05-31 06:30:50,176 -> C.Computing centers... [1.401s] [11550 results]
2018-05-31 06:30:51,193 -> D.Indexing centers... [1.017s] [11550 results]
2018-05-31 06:30:58,136 -> E.Getting disks... [6.943s] [11550 results]
2018-05-31 06:30:58,410 -> F.Filtering less-than-mu disks... [0.274s] [3606 results]
2018-05-31 06:31:00,381 -> G.Prunning duplicate candidates... [1.970s] [1867 results]
2018-05-31 06:31:00,762 -> H.Indexing candidates... [2.351s] [1867 results]
2018-05-31 06:31:01,001 -> I.Getting expansions... [0.239s] [3005 results]
2018-05-31 06:31:01,162 -> J.Finding maximal disks... [0.161s] [795 results]
2018-05-31 06:31:02,933 -> K.Prunning duplicates and subsets... [1.771s] [788 results]
2018-05-31 06:31:02,934 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 06:31:02,934 ->   berlin0-10,   18548,  30.0,    28,  3,  31.45,    5775,     11550,         1867,        788,  4
2018-05-31 06:31:03,281 -> Dropping indices...[0.347s]
2018-05-31 06:31:03,598 -> 1.Set of disks for t_i...                          |  32.14s |    788 disks
2018-05-31 06:31:13,380 -> 2.Distance Join phase...                           |   9.78s |   3225 combinations
2018-05-31 06:31:32,175 -> 3.Getting candidates...                            |  18.80s |    888 candidates
2018-05-31 06:31:33,234 -> 4.Found flocks...                                  |   1.06s |    661 flocks
2018-05-31 06:31:38,415 -> 5.Updating times...                                |   1.75s |    888 flocks
2018-05-31 06:31:42,079 -> 6.Filter phase...                                  |   3.66s |    941 flocks
2018-05-31 06:31:55,962 -> Reporting locations...                             |  13.88s |  18548 points
2018-05-31 06:31:55,962 -> Setting mu=3,epsilon=30.0,cores=28,timestamp=5,dataset=berlin0-10
2018-05-31 06:32:03,636 -> A.Indexing points... [7.655s] [18548 results]
2018-05-31 06:32:13,329 -> B.Getting pairs... [9.692s] [5765 results]
2018-05-31 06:32:14,808 -> C.Computing centers... [1.479s] [11530 results]
2018-05-31 06:32:15,947 -> D.Indexing centers... [1.139s] [11530 results]
2018-05-31 06:32:22,768 -> E.Getting disks... [6.821s] [11530 results]
2018-05-31 06:32:23,032 -> F.Filtering less-than-mu disks... [0.263s] [3620 results]
2018-05-31 06:32:25,275 -> G.Prunning duplicate candidates... [2.243s] [1858 results]
2018-05-31 06:32:25,666 -> H.Indexing candidates... [2.634s] [1858 results]
2018-05-31 06:32:25,905 -> I.Getting expansions... [0.239s] [2980 results]
2018-05-31 06:32:26,071 -> J.Finding maximal disks... [0.165s] [788 results]
2018-05-31 06:32:27,837 -> K.Prunning duplicates and subsets... [1.765s] [785 results]
2018-05-31 06:32:27,838 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 06:32:27,838 ->   berlin0-10,   18548,  30.0,    28,  3,  31.86,    5765,     11530,         1858,        785,  5
2018-05-31 06:32:28,195 -> Dropping indices...[0.357s]
2018-05-31 06:32:28,561 -> 1.Set of disks for t_i...                          |  32.60s |    785 disks
2018-05-31 06:32:39,014 -> 2.Distance Join phase...                           |  10.45s |   3578 combinations
2018-05-31 06:33:04,472 -> 3.Getting candidates...                            |  25.46s |    881 candidates
2018-05-31 06:33:05,792 -> 4.Found flocks...                                  |   1.32s |    687 flocks
2018-05-31 06:33:12,177 -> 5.Updating times...                                |   1.91s |    881 flocks
2018-05-31 06:33:15,196 -> 6.Filter phase...                                  |   3.02s |    936 flocks
2018-05-31 06:33:28,880 -> Reporting locations...                             |  13.68s |  18546 points
2018-05-31 06:33:28,881 -> Setting mu=3,epsilon=30.0,cores=28,timestamp=6,dataset=berlin0-10
2018-05-31 06:33:36,459 -> A.Indexing points... [7.560s] [18546 results]
2018-05-31 06:33:46,641 -> B.Getting pairs... [10.182s] [5758 results]
2018-05-31 06:33:48,200 -> C.Computing centers... [1.559s] [11516 results]
2018-05-31 06:33:49,190 -> D.Indexing centers... [0.990s] [11516 results]
2018-05-31 06:33:55,745 -> E.Getting disks... [6.555s] [11516 results]
2018-05-31 06:33:55,965 -> F.Filtering less-than-mu disks... [0.219s] [3615 results]
2018-05-31 06:33:58,534 -> G.Prunning duplicate candidates... [2.569s] [1861 results]
2018-05-31 06:33:58,873 -> H.Indexing candidates... [2.908s] [1861 results]
2018-05-31 06:33:59,048 -> I.Getting expansions... [0.175s] [3020 results]
2018-05-31 06:33:59,204 -> J.Finding maximal disks... [0.156s] [782 results]
2018-05-31 06:34:01,234 -> K.Prunning duplicates and subsets... [2.030s] [776 results]
2018-05-31 06:34:01,235 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 06:34:01,235 ->   berlin0-10,   18546,  30.0,    28,  3,  32.34,    5758,     11516,         1861,        776,  6
2018-05-31 06:34:01,775 -> Dropping indices...[0.540s]
2018-05-31 06:34:02,105 -> 1.Set of disks for t_i...                          |  33.23s |    776 disks
2018-05-31 06:34:12,560 -> 2.Distance Join phase...                           |  10.45s |   3312 combinations
2018-05-31 06:34:28,398 -> 3.Getting candidates...                            |  15.84s |    866 candidates
2018-05-31 06:34:29,705 -> 4.Found flocks...                                  |   1.31s |    676 flocks
2018-05-31 06:34:36,983 -> 5.Updating times...                                |   2.03s |    866 flocks
2018-05-31 06:34:40,056 -> 6.Filter phase...                                  |   3.07s |    917 flocks
2018-05-31 06:34:53,539 -> Reporting locations...                             |  13.48s |  18546 points
2018-05-31 06:34:53,539 -> Setting mu=3,epsilon=30.0,cores=28,timestamp=7,dataset=berlin0-10
2018-05-31 06:35:01,553 -> A.Indexing points... [7.995s] [18546 results]
2018-05-31 06:35:11,333 -> B.Getting pairs... [9.780s] [5788 results]
2018-05-31 06:35:12,714 -> C.Computing centers... [1.381s] [11576 results]
2018-05-31 06:35:13,792 -> D.Indexing centers... [1.078s] [11576 results]
2018-05-31 06:35:21,871 -> E.Getting disks... [8.079s] [11576 results]
2018-05-31 06:35:22,100 -> F.Filtering less-than-mu disks... [0.229s] [3654 results]
2018-05-31 06:35:24,018 -> G.Prunning duplicate candidates... [1.918s] [1872 results]
2018-05-31 06:35:24,441 -> H.Indexing candidates... [2.341s] [1872 results]
2018-05-31 06:35:24,618 -> I.Getting expansions... [0.177s] [2960 results]
2018-05-31 06:35:24,768 -> J.Finding maximal disks... [0.150s] [786 results]
2018-05-31 06:35:26,495 -> K.Prunning duplicates and subsets... [1.727s] [782 results]
2018-05-31 06:35:26,495 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 06:35:26,495 ->   berlin0-10,   18546,  30.0,    28,  3,  32.94,    5788,     11576,         1872,        782,  7
2018-05-31 06:35:27,134 -> Dropping indices...[0.638s]
2018-05-31 06:35:27,451 -> 1.Set of disks for t_i...                          |  33.91s |    782 disks
2018-05-31 06:35:38,413 -> 2.Distance Join phase...                           |  10.96s |   3284 combinations
2018-05-31 06:36:00,209 -> 3.Getting candidates...                            |  21.80s |    864 candidates
2018-05-31 06:36:01,756 -> 4.Found flocks...                                  |   1.55s |    685 flocks
2018-05-31 06:36:10,009 -> 5.Updating times...                                |   2.07s |    864 flocks
2018-05-31 06:36:13,437 -> 6.Filter phase...                                  |   3.43s |    928 flocks
2018-05-31 06:36:27,227 -> Reporting locations...                             |  13.79s |  18546 points
2018-05-31 06:36:27,228 -> Setting mu=3,epsilon=30.0,cores=28,timestamp=8,dataset=berlin0-10
2018-05-31 06:36:34,957 -> A.Indexing points... [7.711s] [18546 results]
2018-05-31 06:36:45,173 -> B.Getting pairs... [10.216s] [5791 results]
2018-05-31 06:36:46,606 -> C.Computing centers... [1.433s] [11582 results]
2018-05-31 06:36:47,818 -> D.Indexing centers... [1.212s] [11582 results]
2018-05-31 06:36:54,474 -> E.Getting disks... [6.656s] [11582 results]
2018-05-31 06:36:54,721 -> F.Filtering less-than-mu disks... [0.247s] [3639 results]
2018-05-31 06:36:57,006 -> G.Prunning duplicate candidates... [2.285s] [1848 results]
2018-05-31 06:36:57,310 -> H.Indexing candidates... [2.589s] [1848 results]
2018-05-31 06:36:57,486 -> I.Getting expansions... [0.176s] [2887 results]
2018-05-31 06:36:57,642 -> J.Finding maximal disks... [0.156s] [790 results]
2018-05-31 06:36:59,389 -> K.Prunning duplicates and subsets... [1.746s] [785 results]
2018-05-31 06:36:59,389 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 06:36:59,389 ->   berlin0-10,   18546,  30.0,    28,  3,  32.14,    5791,     11582,         1848,        785,  8
2018-05-31 06:37:00,088 -> Dropping indices...[0.699s]
2018-05-31 06:37:00,399 -> 1.Set of disks for t_i...                          |  33.17s |    785 disks
2018-05-31 06:37:12,454 -> 2.Distance Join phase...                           |  12.06s |   3170 combinations
2018-05-31 06:37:34,426 -> 3.Getting candidates...                            |  21.97s |    880 candidates
2018-05-31 06:37:35,948 -> 4.Found flocks...                                  |   1.52s |    696 flocks
2018-05-31 06:37:45,343 -> 5.Updating times...                                |   2.16s |    880 flocks
2018-05-31 06:37:48,655 -> 6.Filter phase...                                  |   3.31s |    932 flocks
2018-05-31 06:38:02,040 -> Reporting locations...                             |  13.39s |  18546 points
2018-05-31 06:38:02,041 -> Setting mu=3,epsilon=30.0,cores=28,timestamp=9,dataset=berlin0-10
2018-05-31 06:38:09,077 -> A.Indexing points... [7.018s] [18546 results]
2018-05-31 06:38:19,351 -> B.Getting pairs... [10.274s] [5802 results]
2018-05-31 06:38:21,019 -> C.Computing centers... [1.668s] [11604 results]
2018-05-31 06:38:22,061 -> D.Indexing centers... [1.042s] [11604 results]
2018-05-31 06:38:28,757 -> E.Getting disks... [6.696s] [11604 results]
2018-05-31 06:38:29,037 -> F.Filtering less-than-mu disks... [0.280s] [3660 results]
2018-05-31 06:38:31,376 -> G.Prunning duplicate candidates... [2.338s] [1856 results]
2018-05-31 06:38:31,700 -> H.Indexing candidates... [2.662s] [1856 results]
2018-05-31 06:38:31,886 -> I.Getting expansions... [0.186s] [2942 results]
2018-05-31 06:38:32,023 -> J.Finding maximal disks... [0.137s] [796 results]
2018-05-31 06:38:33,729 -> K.Prunning duplicates and subsets... [1.684s] [789 results]
2018-05-31 06:38:33,729 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 06:38:33,730 ->   berlin0-10,   18546,  30.0,    28,  3,  31.67,    5802,     11604,         1856,        789,  9
2018-05-31 06:38:34,472 -> Dropping indices...[0.742s]
2018-05-31 06:38:34,828 -> 1.Set of disks for t_i...                          |  32.79s |    789 disks
2018-05-31 06:38:47,180 -> 2.Distance Join phase...                           |  12.35s |   3072 combinations
2018-05-31 06:39:08,419 -> 3.Getting candidates...                            |  21.24s |    868 candidates
2018-05-31 06:39:10,259 -> 4.Found flocks...                                  |   1.84s |    688 flocks
2018-05-31 06:39:21,070 -> 5.Updating times...                                |   2.44s |    868 flocks
2018-05-31 06:39:24,488 -> 6.Filter phase...                                  |   3.42s |    927 flocks
2018-05-31 06:39:37,777 -> Reporting locations...                             |  13.29s |  18546 points
2018-05-31 06:39:37,778 -> Setting mu=3,epsilon=30.0,cores=28,timestamp=10,dataset=berlin0-10
2018-05-31 06:39:46,226 -> A.Indexing points... [8.413s] [18546 results]
2018-05-31 06:39:56,017 -> B.Getting pairs... [9.791s] [5797 results]
2018-05-31 06:39:57,408 -> C.Computing centers... [1.391s] [11594 results]
2018-05-31 06:39:58,414 -> D.Indexing centers... [1.006s] [11594 results]
2018-05-31 06:40:05,463 -> E.Getting disks... [7.048s] [11594 results]
2018-05-31 06:40:05,685 -> F.Filtering less-than-mu disks... [0.222s] [3645 results]
2018-05-31 06:40:08,176 -> G.Prunning duplicate candidates... [2.491s] [1845 results]
2018-05-31 06:40:08,528 -> H.Indexing candidates... [2.843s] [1845 results]
2018-05-31 06:40:08,704 -> I.Getting expansions... [0.175s] [2902 results]
2018-05-31 06:40:08,848 -> J.Finding maximal disks... [0.144s] [781 results]
2018-05-31 06:40:11,206 -> K.Prunning duplicates and subsets... [2.358s] [776 results]
2018-05-31 06:40:11,209 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 06:40:11,209 ->   berlin0-10,   18546,  30.0,    28,  3,  33.40,    5797,     11594,         1845,        776, 10
2018-05-31 06:40:12,185 -> Dropping indices...[0.976s]
2018-05-31 06:40:12,455 -> 1.Set of disks for t_i...                          |  34.68s |    776 disks
2018-05-31 06:40:25,220 -> 2.Distance Join phase...                           |  12.76s |   2865 combinations
2018-05-31 06:40:43,728 -> 3.Getting candidates...                            |  18.51s |    857 candidates
2018-05-31 06:40:45,409 -> 4.Found flocks...                                  |   1.68s |    675 flocks
2018-05-31 06:40:57,175 -> 5.Updating times...                                |   2.26s |    857 flocks
2018-05-31 06:41:00,845 -> 6.Filter phase...                                  |   3.67s |    903 flocks
2018-05-31 06:41:00,845 -> 

PFLOCK_SJ	30.0	3	5	4768

2018-05-31 06:41:08,585 -> Running SpatialJoin...                             | 907.60s |   4768 flocks
2018-05-31 06:41:08,585 -> method=SpatialJoin,cores=28,epsilon=30.0,mu=3,delta=5,time=907.601,master=spark://169.235.27.134:7077
2018-05-31 06:41:08,585 -> Closing app...
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack15: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
FLOCKFINDER=SpatialJoin;TIME=Thu May 31 06:41:09 PDT 2018;RUN=1527773133;NODES=4;ESTART=;EEND=;ESTEP=;MU=;DELTA=5;SCRIPT=MuBenchmarker;EVENT=End
FLOCKFINDER=MergeLast;TIME=Thu May 31 06:41:09 PDT 2018;RUN=1527774069;NODES=4;ESTART=;EEND=;ESTEP=;MU=;DELTA=5;SCRIPT=MuBenchmarker;EVENT=Start
WARNING:root:Setting 4 nodes...
acald013@dblab-rack12: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack15: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack14: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack11: no org.apache.spark.deploy.worker.Worker to stop
no org.apache.spark.deploy.master.Master to stop
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack15: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack15.out
WARNING:root:4 nodes has been set...
2018-05-31 06:41:17,503 -> Starting app...
2018-05-31 06:41:20,598 -> Starting session                                   |   3.10s |      0 
2018-05-31 06:41:20,617 -> Setting paramaters                                 |   0.02s |      0 
2018-05-31 06:41:23,780 -> Reading data                                       |   3.16s | 203106 points
2018-05-31 06:41:27,081 -> Extracting timestamps                              |   3.30s |     11 timestamps
2018-05-31 06:41:27,090 -> === MergeLast Start ===
2018-05-31 06:41:32,760 -> Reporting locations at t=0...                      |   5.45s |  18093 points
2018-05-31 06:41:32,769 -> Setting mu=3,epsilon=30.0,cores=28,timestamp=0,dataset=berlin0-10
2018-05-31 06:41:41,498 -> A.Indexing points... [8.697s] [18093 results]
2018-05-31 06:41:48,618 -> B.Getting pairs... [7.119s] [5511 results]
2018-05-31 06:41:50,893 -> C.Computing centers... [2.275s] [11022 results]
2018-05-31 06:41:52,177 -> D.Indexing centers... [1.284s] [11022 results]
2018-05-31 06:41:58,316 -> E.Getting disks... [6.139s] [11022 results]
2018-05-31 06:41:58,706 -> F.Filtering less-than-mu disks... [0.390s] [3372 results]
2018-05-31 06:42:01,618 -> G.Prunning duplicate candidates... [2.912s] [1700 results]
2018-05-31 06:42:02,110 -> H.Indexing candidates... [3.404s] [1700 results]
2018-05-31 06:42:02,368 -> I.Getting expansions... [0.258s] [2699 results]
2018-05-31 06:42:03,049 -> J.Finding maximal disks... [0.681s] [752 results]
2018-05-31 06:42:05,127 -> K.Prunning duplicates and subsets... [2.078s] [749 results]
2018-05-31 06:42:05,127 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 06:42:05,127 ->   berlin0-10,   18093,  30.0,    28,  3,  32.33,    5511,     11022,         1700,        749,  0
2018-05-31 06:42:05,200 -> Dropping indices...[0.073s]
2018-05-31 06:42:05,523 -> 1.Set of disks for t_i...                          |  32.76s |    749 disks
2018-05-31 06:42:10,701 -> Reporting locations at t=4...                      |   5.18s |  18548 points
2018-05-31 06:42:10,702 -> Setting mu=3,epsilon=30.0,cores=28,timestamp=4,dataset=berlin0-10
2018-05-31 06:42:19,158 -> A.Indexing points... [8.434s] [18548 results]
2018-05-31 06:42:31,030 -> B.Getting pairs... [11.872s] [5775 results]
2018-05-31 06:42:32,567 -> C.Computing centers... [1.537s] [11550 results]
2018-05-31 06:42:33,555 -> D.Indexing centers... [0.987s] [11550 results]
2018-05-31 06:42:41,317 -> E.Getting disks... [7.762s] [11550 results]
2018-05-31 06:42:41,581 -> F.Filtering less-than-mu disks... [0.264s] [3606 results]
2018-05-31 06:42:44,138 -> G.Prunning duplicate candidates... [2.557s] [1867 results]
2018-05-31 06:42:44,467 -> H.Indexing candidates... [2.886s] [1867 results]
2018-05-31 06:42:44,680 -> I.Getting expansions... [0.213s] [3005 results]
2018-05-31 06:42:45,018 -> J.Finding maximal disks... [0.338s] [795 results]
2018-05-31 06:42:47,161 -> K.Prunning duplicates and subsets... [2.143s] [788 results]
2018-05-31 06:42:47,161 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 06:42:47,161 ->   berlin0-10,   18548,  30.0,    28,  3,  36.44,    5775,     11550,         1867,        788,  4
2018-05-31 06:42:47,234 -> Dropping indices...[0.073s]
2018-05-31 06:42:47,494 -> 2.Set of disks for t_i+delta...                    |  36.79s |    749 disks
2018-05-31 06:43:05,992 -> 3.Joining timestams                                |  18.50s |    916 candidates
2018-05-31 06:43:27,401 -> Checking internal timestamps                       |  21.41s |    661 flocks
2018-05-31 06:43:33,049 -> Reporting locations at t=1...                      |   5.20s |  18245 points
2018-05-31 06:43:33,050 -> Setting mu=3,epsilon=30.0,cores=28,timestamp=1,dataset=berlin0-10
2018-05-31 06:43:37,304 -> A.Indexing points... [4.235s] [18245 results]
2018-05-31 06:43:42,531 -> B.Getting pairs... [5.226s] [5629 results]
2018-05-31 06:43:43,865 -> C.Computing centers... [1.333s] [11258 results]
2018-05-31 06:43:45,084 -> D.Indexing centers... [1.219s] [11258 results]
2018-05-31 06:43:49,593 -> E.Getting disks... [4.509s] [11258 results]
2018-05-31 06:43:49,863 -> F.Filtering less-than-mu disks... [0.270s] [3500 results]
2018-05-31 06:43:51,228 -> G.Prunning duplicate candidates... [1.365s] [1778 results]
2018-05-31 06:43:51,568 -> H.Indexing candidates... [1.705s] [1778 results]
2018-05-31 06:43:51,734 -> I.Getting expansions... [0.166s] [2890 results]
2018-05-31 06:43:51,901 -> J.Finding maximal disks... [0.167s] [770 results]
2018-05-31 06:43:53,186 -> K.Prunning duplicates and subsets... [1.285s] [767 results]
2018-05-31 06:43:53,186 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 06:43:53,186 ->   berlin0-10,   18245,  30.0,    28,  3,  20.12,    5629,     11258,         1778,        767,  1
2018-05-31 06:43:53,360 -> Dropping indices...[0.174s]
2018-05-31 06:43:53,622 -> 1.Set of disks for t_i...                          |  20.57s |    767 disks
2018-05-31 06:43:58,737 -> Reporting locations at t=5...                      |   5.12s |  18548 points
2018-05-31 06:43:58,737 -> Setting mu=3,epsilon=30.0,cores=28,timestamp=5,dataset=berlin0-10
2018-05-31 06:44:06,508 -> A.Indexing points... [7.754s] [18548 results]
2018-05-31 06:44:17,944 -> B.Getting pairs... [11.436s] [5765 results]
2018-05-31 06:44:19,341 -> C.Computing centers... [1.397s] [11530 results]
2018-05-31 06:44:20,384 -> D.Indexing centers... [1.043s] [11530 results]
2018-05-31 06:44:28,191 -> E.Getting disks... [7.807s] [11530 results]
2018-05-31 06:44:28,422 -> F.Filtering less-than-mu disks... [0.230s] [3620 results]
2018-05-31 06:44:30,807 -> G.Prunning duplicate candidates... [2.385s] [1858 results]
2018-05-31 06:44:31,121 -> H.Indexing candidates... [2.699s] [1858 results]
2018-05-31 06:44:31,323 -> I.Getting expansions... [0.191s] [2980 results]
2018-05-31 06:44:31,488 -> J.Finding maximal disks... [0.165s] [788 results]
2018-05-31 06:44:33,662 -> K.Prunning duplicates and subsets... [2.174s] [785 results]
2018-05-31 06:44:33,662 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 06:44:33,662 ->   berlin0-10,   18548,  30.0,    28,  3,  34.91,    5765,     11530,         1858,        785,  5
2018-05-31 06:44:33,775 -> Dropping indices...[0.113s]
2018-05-31 06:44:34,023 -> 2.Set of disks for t_i+delta...                    |  35.29s |    767 disks
2018-05-31 06:44:51,894 -> 3.Joining timestams                                |  17.87s |    947 candidates
2018-05-31 06:45:12,531 -> Checking internal timestamps                       |  20.64s |    687 flocks
2018-05-31 06:45:18,454 -> Reporting locations at t=2...                      |   5.21s |  18394 points
2018-05-31 06:45:18,455 -> Setting mu=3,epsilon=30.0,cores=28,timestamp=2,dataset=berlin0-10
2018-05-31 06:45:22,583 -> A.Indexing points... [4.111s] [18394 results]
2018-05-31 06:45:27,152 -> B.Getting pairs... [4.569s] [5701 results]
2018-05-31 06:45:28,446 -> C.Computing centers... [1.294s] [11402 results]
2018-05-31 06:45:29,347 -> D.Indexing centers... [0.901s] [11402 results]
2018-05-31 06:45:33,515 -> E.Getting disks... [4.168s] [11402 results]
2018-05-31 06:45:33,736 -> F.Filtering less-than-mu disks... [0.221s] [3535 results]
2018-05-31 06:45:35,017 -> G.Prunning duplicate candidates... [1.281s] [1807 results]
2018-05-31 06:45:35,338 -> H.Indexing candidates... [1.602s] [1807 results]
2018-05-31 06:45:35,501 -> I.Getting expansions... [0.163s] [2902 results]
2018-05-31 06:45:35,722 -> J.Finding maximal disks... [0.221s] [776 results]
2018-05-31 06:45:37,326 -> K.Prunning duplicates and subsets... [1.604s] [774 results]
2018-05-31 06:45:37,326 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 06:45:37,326 ->   berlin0-10,   18394,  30.0,    28,  3,  18.85,    5701,     11402,         1807,        774,  2
2018-05-31 06:45:37,527 -> Dropping indices...[0.201s]
2018-05-31 06:45:37,800 -> 1.Set of disks for t_i...                          |  19.35s |    774 disks
2018-05-31 06:45:42,950 -> Reporting locations at t=6...                      |   5.15s |  18546 points
2018-05-31 06:45:42,950 -> Setting mu=3,epsilon=30.0,cores=28,timestamp=6,dataset=berlin0-10
2018-05-31 06:45:50,726 -> A.Indexing points... [7.753s] [18546 results]
2018-05-31 06:46:02,171 -> B.Getting pairs... [11.445s] [5758 results]
2018-05-31 06:46:03,492 -> C.Computing centers... [1.320s] [11516 results]
2018-05-31 06:46:04,455 -> D.Indexing centers... [0.962s] [11516 results]
2018-05-31 06:46:11,864 -> E.Getting disks... [7.409s] [11516 results]
2018-05-31 06:46:12,091 -> F.Filtering less-than-mu disks... [0.227s] [3615 results]
2018-05-31 06:46:14,500 -> G.Prunning duplicate candidates... [2.409s] [1861 results]
2018-05-31 06:46:14,826 -> H.Indexing candidates... [2.735s] [1861 results]
2018-05-31 06:46:15,008 -> I.Getting expansions... [0.182s] [3020 results]
2018-05-31 06:46:15,212 -> J.Finding maximal disks... [0.204s] [782 results]
2018-05-31 06:46:17,354 -> K.Prunning duplicates and subsets... [2.142s] [776 results]
2018-05-31 06:46:17,354 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 06:46:17,354 ->   berlin0-10,   18546,  30.0,    28,  3,  34.38,    5758,     11516,         1861,        776,  6
2018-05-31 06:46:17,548 -> Dropping indices...[0.194s]
2018-05-31 06:46:17,780 -> 2.Set of disks for t_i+delta...                    |  34.83s |    774 disks
2018-05-31 06:46:36,258 -> 3.Joining timestams                                |  18.48s |    928 candidates
2018-05-31 06:46:56,052 -> Checking internal timestamps                       |  19.79s |    676 flocks
2018-05-31 06:47:02,242 -> Reporting locations at t=3...                      |   5.11s |  18548 points
2018-05-31 06:47:02,243 -> Setting mu=3,epsilon=30.0,cores=28,timestamp=3,dataset=berlin0-10
2018-05-31 06:47:09,883 -> A.Indexing points... [7.626s] [18548 results]
2018-05-31 06:47:20,808 -> B.Getting pairs... [10.925s] [5768 results]
2018-05-31 06:47:22,074 -> C.Computing centers... [1.266s] [11536 results]
2018-05-31 06:47:23,009 -> D.Indexing centers... [0.935s] [11536 results]
2018-05-31 06:47:30,092 -> E.Getting disks... [7.083s] [11536 results]
2018-05-31 06:47:30,303 -> F.Filtering less-than-mu disks... [0.211s] [3584 results]
2018-05-31 06:47:32,643 -> G.Prunning duplicate candidates... [2.340s] [1848 results]
2018-05-31 06:47:32,988 -> H.Indexing candidates... [2.685s] [1848 results]
2018-05-31 06:47:33,154 -> I.Getting expansions... [0.166s] [3000 results]
2018-05-31 06:47:33,295 -> J.Finding maximal disks... [0.141s] [787 results]
2018-05-31 06:47:35,274 -> K.Prunning duplicates and subsets... [1.979s] [785 results]
2018-05-31 06:47:35,274 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 06:47:35,274 ->   berlin0-10,   18548,  30.0,    28,  3,  33.02,    5768,     11536,         1848,        785,  3
2018-05-31 06:47:35,512 -> Dropping indices...[0.238s]
2018-05-31 06:47:35,821 -> 1.Set of disks for t_i...                          |  33.58s |    785 disks
2018-05-31 06:47:41,040 -> Reporting locations at t=7...                      |   5.22s |  18546 points
2018-05-31 06:47:41,040 -> Setting mu=3,epsilon=30.0,cores=28,timestamp=7,dataset=berlin0-10
2018-05-31 06:47:48,857 -> A.Indexing points... [7.799s] [18546 results]
2018-05-31 06:48:00,721 -> B.Getting pairs... [11.864s] [5788 results]
2018-05-31 06:48:02,087 -> C.Computing centers... [1.366s] [11576 results]
2018-05-31 06:48:03,001 -> D.Indexing centers... [0.914s] [11576 results]
2018-05-31 06:48:10,418 -> E.Getting disks... [7.416s] [11576 results]
2018-05-31 06:48:10,623 -> F.Filtering less-than-mu disks... [0.205s] [3654 results]
2018-05-31 06:48:12,783 -> G.Prunning duplicate candidates... [2.160s] [1872 results]
2018-05-31 06:48:13,095 -> H.Indexing candidates... [2.472s] [1872 results]
2018-05-31 06:48:13,295 -> I.Getting expansions... [0.200s] [2960 results]
2018-05-31 06:48:13,525 -> J.Finding maximal disks... [0.230s] [786 results]
2018-05-31 06:48:15,882 -> K.Prunning duplicates and subsets... [2.357s] [782 results]
2018-05-31 06:48:15,882 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 06:48:15,882 ->   berlin0-10,   18546,  30.0,    28,  3,  34.82,    5788,     11576,         1872,        782,  7
2018-05-31 06:48:16,133 -> Dropping indices...[0.251s]
2018-05-31 06:48:16,355 -> 2.Set of disks for t_i+delta...                    |  35.32s |    785 disks
2018-05-31 06:48:33,557 -> 3.Joining timestams                                |  17.20s |    925 candidates
2018-05-31 06:48:51,091 -> Checking internal timestamps                       |  17.53s |    685 flocks
2018-05-31 06:48:57,754 -> Reporting locations at t=4...                      |   5.32s |  18548 points
2018-05-31 06:48:58,026 -> 1.Set of disks for t_i...                          |   0.27s |    788 disks
2018-05-31 06:49:03,114 -> Reporting locations at t=8...                      |   5.09s |  18546 points
2018-05-31 06:49:03,115 -> Setting mu=3,epsilon=30.0,cores=28,timestamp=8,dataset=berlin0-10
2018-05-31 06:49:08,503 -> A.Indexing points... [5.368s] [18546 results]
2018-05-31 06:49:15,319 -> B.Getting pairs... [6.815s] [5791 results]
2018-05-31 06:49:16,619 -> C.Computing centers... [1.300s] [11582 results]
2018-05-31 06:49:17,530 -> D.Indexing centers... [0.911s] [11582 results]
2018-05-31 06:49:23,221 -> E.Getting disks... [5.690s] [11582 results]
2018-05-31 06:49:23,490 -> F.Filtering less-than-mu disks... [0.269s] [3639 results]
2018-05-31 06:49:26,117 -> G.Prunning duplicate candidates... [2.626s] [1848 results]
2018-05-31 06:49:26,478 -> H.Indexing candidates... [2.987s] [1848 results]
2018-05-31 06:49:26,716 -> I.Getting expansions... [0.238s] [2887 results]
2018-05-31 06:49:26,876 -> J.Finding maximal disks... [0.160s] [790 results]
2018-05-31 06:49:28,542 -> K.Prunning duplicates and subsets... [1.666s] [785 results]
2018-05-31 06:49:28,542 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 06:49:28,542 ->   berlin0-10,   18546,  30.0,    28,  3,  25.41,    5791,     11582,         1848,        785,  8
2018-05-31 06:49:28,851 -> Dropping indices...[0.309s]
2018-05-31 06:49:29,074 -> 2.Set of disks for t_i+delta...                    |  25.96s |    788 disks
2018-05-31 06:49:49,833 -> 3.Joining timestams                                |  20.76s |    921 candidates
2018-05-31 06:50:08,296 -> Checking internal timestamps                       |  18.46s |    696 flocks
2018-05-31 06:50:15,103 -> Reporting locations at t=5...                      |   5.26s |  18548 points
2018-05-31 06:50:15,350 -> 1.Set of disks for t_i...                          |   0.25s |    785 disks
2018-05-31 06:50:20,397 -> Reporting locations at t=9...                      |   5.05s |  18546 points
2018-05-31 06:50:20,397 -> Setting mu=3,epsilon=30.0,cores=28,timestamp=9,dataset=berlin0-10
2018-05-31 06:50:27,640 -> A.Indexing points... [7.208s] [18546 results]
2018-05-31 06:50:37,817 -> B.Getting pairs... [10.177s] [5802 results]
2018-05-31 06:50:39,100 -> C.Computing centers... [1.283s] [11604 results]
2018-05-31 06:50:40,049 -> D.Indexing centers... [0.949s] [11604 results]
2018-05-31 06:50:46,935 -> E.Getting disks... [6.885s] [11604 results]
2018-05-31 06:50:47,139 -> F.Filtering less-than-mu disks... [0.204s] [3660 results]
2018-05-31 06:50:49,200 -> G.Prunning duplicate candidates... [2.061s] [1856 results]
2018-05-31 06:50:49,511 -> H.Indexing candidates... [2.372s] [1856 results]
2018-05-31 06:50:49,700 -> I.Getting expansions... [0.189s] [2942 results]
2018-05-31 06:50:49,841 -> J.Finding maximal disks... [0.141s] [796 results]
2018-05-31 06:50:51,867 -> K.Prunning duplicates and subsets... [2.026s] [789 results]
2018-05-31 06:50:51,868 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 06:50:51,868 ->   berlin0-10,   18546,  30.0,    28,  3,  31.44,    5802,     11604,         1856,        789,  9
2018-05-31 06:50:52,239 -> Dropping indices...[0.371s]
2018-05-31 06:50:52,543 -> 2.Set of disks for t_i+delta...                    |  32.15s |    785 disks
2018-05-31 06:51:09,950 -> 3.Joining timestams                                |  17.41s |    886 candidates
2018-05-31 06:51:30,273 -> Checking internal timestamps                       |  20.32s |    688 flocks
2018-05-31 06:51:37,244 -> Reporting locations at t=6...                      |   5.20s |  18546 points
2018-05-31 06:51:37,481 -> 1.Set of disks for t_i...                          |   0.24s |    776 disks
2018-05-31 06:51:42,505 -> Reporting locations at t=10...                     |   5.02s |  18546 points
2018-05-31 06:51:42,505 -> Setting mu=3,epsilon=30.0,cores=28,timestamp=10,dataset=berlin0-10
2018-05-31 06:51:49,814 -> A.Indexing points... [7.274s] [18546 results]
2018-05-31 06:51:59,855 -> B.Getting pairs... [10.041s] [5797 results]
2018-05-31 06:52:01,256 -> C.Computing centers... [1.401s] [11594 results]
2018-05-31 06:52:02,225 -> D.Indexing centers... [0.969s] [11594 results]
2018-05-31 06:52:09,352 -> E.Getting disks... [7.127s] [11594 results]
2018-05-31 06:52:09,585 -> F.Filtering less-than-mu disks... [0.233s] [3645 results]
2018-05-31 06:52:11,954 -> G.Prunning duplicate candidates... [2.369s] [1845 results]
2018-05-31 06:52:12,314 -> H.Indexing candidates... [2.729s] [1845 results]
2018-05-31 06:52:12,501 -> I.Getting expansions... [0.187s] [2902 results]
2018-05-31 06:52:12,649 -> J.Finding maximal disks... [0.148s] [781 results]
2018-05-31 06:52:14,583 -> K.Prunning duplicates and subsets... [1.933s] [776 results]
2018-05-31 06:52:14,583 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 06:52:14,584 ->   berlin0-10,   18546,  30.0,    28,  3,  32.04,    5797,     11594,         1845,        776, 10
2018-05-31 06:52:14,978 -> Dropping indices...[0.394s]
2018-05-31 06:52:15,233 -> 2.Set of disks for t_i+delta...                    |  32.73s |    776 disks
2018-05-31 06:52:34,435 -> 3.Joining timestams                                |  19.20s |    878 candidates
2018-05-31 06:52:52,825 -> Checking internal timestamps                       |  18.39s |    675 flocks
2018-05-31 06:52:54,725 -> 

PFLOCK_ML	30.0	3	5	4768

2018-05-31 06:52:56,413 -> Running MergeLast...                               | 689.32s |   4768 flocks
2018-05-31 06:52:56,413 -> method=MergeLast,cores=28,epsilon=30.0,mu=3,delta=5,time=689.323,master=spark://169.235.27.134:7077
2018-05-31 06:52:56,414 -> Closing app...
acald013@dblab-rack15: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
FLOCKFINDER=MergeLast;TIME=Thu May 31 06:53:02 PDT 2018;RUN=1527774069;NODES=4;ESTART=;EEND=;ESTEP=;MU=;DELTA=5;SCRIPT=MuBenchmarker;EVENT=End
FLOCKFINDER=SpatialJoin;TIME=Thu May 31 06:53:02 PDT 2018;RUN=1527774782;NODES=4;ESTART=;EEND=;ESTEP=;MU=;DELTA=5;SCRIPT=MuBenchmarker;EVENT=Start
WARNING:root:Setting 4 nodes...
acald013@dblab-rack12: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack15: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack14: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack11: no org.apache.spark.deploy.worker.Worker to stop
no org.apache.spark.deploy.master.Master to stop
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack15: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack15.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
WARNING:root:4 nodes has been set...
2018-05-31 06:53:10,107 -> Starting app...
2018-05-31 06:53:13,323 -> Starting session                                   |   3.22s |      0 
2018-05-31 06:53:13,336 -> Setting paramaters                                 |   0.01s |      0 
2018-05-31 06:53:16,500 -> Reading data                                       |   3.16s | 203106 points
2018-05-31 06:53:19,814 -> Extracting timestamps                              |   3.31s |     11 timestamps
2018-05-31 06:53:19,819 -> === SpatialJoin Start ===
2018-05-31 06:53:25,528 -> Reporting locations...                             |   5.52s |  18093 points
2018-05-31 06:53:25,537 -> Setting mu=2,epsilon=30.0,cores=28,timestamp=0,dataset=berlin0-10
2018-05-31 06:53:34,054 -> A.Indexing points... [8.484s] [18093 results]
2018-05-31 06:53:41,335 -> B.Getting pairs... [7.281s] [5511 results]
2018-05-31 06:53:43,527 -> C.Computing centers... [2.192s] [11022 results]
2018-05-31 06:53:44,895 -> D.Indexing centers... [1.368s] [11022 results]
2018-05-31 06:53:50,620 -> E.Getting disks... [5.725s] [11022 results]
2018-05-31 06:53:51,105 -> F.Filtering less-than-mu disks... [0.485s] [11022 results]
2018-05-31 06:53:53,980 -> G.Prunning duplicate candidates... [2.875s] [6157 results]
2018-05-31 06:53:54,518 -> H.Indexing candidates... [3.413s] [6157 results]
2018-05-31 06:53:54,824 -> I.Getting expansions... [0.306s] [6877 results]
2018-05-31 06:53:55,539 -> J.Finding maximal disks... [0.715s] [3432 results]
2018-05-31 06:53:57,854 -> K.Prunning duplicates and subsets... [2.315s] [3427 results]
2018-05-31 06:53:57,854 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 06:53:57,854 ->   berlin0-10,   18093,  30.0,    28,  2,  32.28,    5511,     11022,         6157,       3427,  0
2018-05-31 06:53:57,938 -> Dropping indices...[0.084s]
2018-05-31 06:53:58,407 -> 1.Set of disks for t_i...                          |  32.88s |   3427 disks
2018-05-31 06:53:58,882 -> 4.Found flocks...                                  |   0.48s |      0 flocks
2018-05-31 06:53:59,717 -> 5.Updating times...                                |   0.53s |   3427 flocks
2018-05-31 06:54:00,913 -> 6.Filter phase...                                  |   1.20s |   3427 flocks
2018-05-31 06:54:05,485 -> Reporting locations...                             |   4.57s |  18245 points
2018-05-31 06:54:05,486 -> Setting mu=2,epsilon=30.0,cores=28,timestamp=1,dataset=berlin0-10
2018-05-31 06:54:10,013 -> A.Indexing points... [4.509s] [18245 results]
2018-05-31 06:54:15,259 -> B.Getting pairs... [5.246s] [5629 results]
2018-05-31 06:54:16,643 -> C.Computing centers... [1.384s] [11258 results]
2018-05-31 06:54:17,670 -> D.Indexing centers... [1.027s] [11258 results]
2018-05-31 06:54:22,429 -> E.Getting disks... [4.759s] [11258 results]
2018-05-31 06:54:22,705 -> F.Filtering less-than-mu disks... [0.276s] [11258 results]
2018-05-31 06:54:24,798 -> G.Prunning duplicate candidates... [2.093s] [6297 results]
2018-05-31 06:54:25,149 -> H.Indexing candidates... [2.444s] [6297 results]
2018-05-31 06:54:25,364 -> I.Getting expansions... [0.215s] [6982 results]
2018-05-31 06:54:25,767 -> J.Finding maximal disks... [0.403s] [3482 results]
2018-05-31 06:54:27,439 -> K.Prunning duplicates and subsets... [1.672s] [3478 results]
2018-05-31 06:54:27,439 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 06:54:27,439 ->   berlin0-10,   18245,  30.0,    28,  2,  21.94,    5629,     11258,         6297,       3478,  1
2018-05-31 06:54:27,531 -> Dropping indices...[0.092s]
2018-05-31 06:54:27,849 -> 1.Set of disks for t_i...                          |  22.36s |   3478 disks
2018-05-31 06:54:32,669 -> 2.Distance Join phase...                           |   4.82s |   7060 combinations
2018-05-31 07:08:51,729 -> 3.Getting candidates...                            | 859.06s |   3376 candidates
2018-05-31 07:08:52,572 -> 4.Found flocks...                                  |   0.84s |      0 flocks
2018-05-31 07:08:54,917 -> 5.Updating times...                                |   1.43s |   3376 flocks
2018-05-31 07:08:57,814 -> 6.Filter phase...                                  |   2.90s |   3576 flocks
2018-05-31 07:09:02,432 -> Reporting locations...                             |   4.62s |  18394 points
2018-05-31 07:09:02,432 -> Setting mu=2,epsilon=30.0,cores=28,timestamp=2,dataset=berlin0-10
2018-05-31 07:09:06,545 -> A.Indexing points... [4.096s] [18394 results]
2018-05-31 07:09:11,186 -> B.Getting pairs... [4.641s] [5701 results]
2018-05-31 07:09:12,455 -> C.Computing centers... [1.269s] [11402 results]
2018-05-31 07:09:13,508 -> D.Indexing centers... [1.053s] [11402 results]
2018-05-31 07:09:18,365 -> E.Getting disks... [4.857s] [11402 results]
2018-05-31 07:09:18,609 -> F.Filtering less-than-mu disks... [0.244s] [11402 results]
2018-05-31 07:09:20,588 -> G.Prunning duplicate candidates... [1.979s] [6373 results]
2018-05-31 07:09:20,894 -> H.Indexing candidates... [2.285s] [6373 results]
2018-05-31 07:09:21,177 -> I.Getting expansions... [0.283s] [7107 results]
2018-05-31 07:09:21,469 -> J.Finding maximal disks... [0.292s] [3517 results]
2018-05-31 07:09:23,283 -> K.Prunning duplicates and subsets... [1.814s] [3511 results]
2018-05-31 07:09:23,283 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 07:09:23,283 ->   berlin0-10,   18394,  30.0,    28,  2,  20.83,    5701,     11402,         6373,       3511,  2
2018-05-31 07:09:23,420 -> Dropping indices...[0.137s]
2018-05-31 07:09:23,669 -> 1.Set of disks for t_i...                          |  21.24s |   3511 disks
2018-05-31 07:09:32,003 -> 2.Distance Join phase...                           |   8.33s |   7745 combinations
2018-05-31 07:18:56,910 -> 3.Getting candidates...                            | 564.91s |   3528 candidates
2018-05-31 07:18:57,892 -> 4.Found flocks...                                  |   0.98s |      0 flocks
2018-05-31 07:19:01,075 -> 5.Updating times...                                |   1.51s |   3528 flocks
2018-05-31 07:19:03,583 -> 6.Filter phase...                                  |   2.51s |   3711 flocks
2018-05-31 07:19:08,200 -> Reporting locations...                             |   4.62s |  18548 points
2018-05-31 07:19:08,200 -> Setting mu=2,epsilon=30.0,cores=28,timestamp=3,dataset=berlin0-10
2018-05-31 07:19:16,277 -> A.Indexing points... [8.065s] [18548 results]
2018-05-31 07:19:27,691 -> B.Getting pairs... [11.414s] [5768 results]
2018-05-31 07:19:29,104 -> C.Computing centers... [1.413s] [11536 results]
2018-05-31 07:19:30,055 -> D.Indexing centers... [0.950s] [11536 results]
2018-05-31 07:19:37,593 -> E.Getting disks... [7.538s] [11536 results]
2018-05-31 07:19:37,873 -> F.Filtering less-than-mu disks... [0.280s] [11536 results]
2018-05-31 07:19:40,355 -> G.Prunning duplicate candidates... [2.481s] [6465 results]
2018-05-31 07:19:40,675 -> H.Indexing candidates... [2.800s] [6465 results]
2018-05-31 07:19:41,024 -> I.Getting expansions... [0.349s] [7226 results]
2018-05-31 07:19:41,282 -> J.Finding maximal disks... [0.258s] [3566 results]
2018-05-31 07:19:43,513 -> K.Prunning duplicates and subsets... [2.231s] [3557 results]
2018-05-31 07:19:43,513 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 07:19:43,513 ->   berlin0-10,   18548,  30.0,    28,  2,  35.30,    5768,     11536,         6465,       3557,  3
2018-05-31 07:19:43,754 -> Dropping indices...[0.241s]
2018-05-31 07:19:44,031 -> 1.Set of disks for t_i...                          |  35.83s |   3557 disks
2018-05-31 07:19:52,565 -> 2.Distance Join phase...                           |   8.53s |   8243 combinations
2018-05-31 07:32:48,712 -> 3.Getting candidates...                            | 776.15s |   3681 candidates
2018-05-31 07:32:50,136 -> 4.Found flocks...                                  |   1.42s |      0 flocks
2018-05-31 07:32:55,211 -> 5.Updating times...                                |   2.40s |   3681 flocks
2018-05-31 07:32:58,469 -> 6.Filter phase...                                  |   3.26s |   3843 flocks
2018-05-31 07:33:03,193 -> Reporting locations...                             |   4.72s |  18548 points
2018-05-31 07:33:03,193 -> Setting mu=2,epsilon=30.0,cores=28,timestamp=4,dataset=berlin0-10
2018-05-31 07:33:11,192 -> A.Indexing points... [7.984s] [18548 results]
2018-05-31 07:33:22,596 -> B.Getting pairs... [11.404s] [5775 results]
2018-05-31 07:33:23,871 -> C.Computing centers... [1.275s] [11550 results]
2018-05-31 07:33:24,865 -> D.Indexing centers... [0.994s] [11550 results]
2018-05-31 07:33:32,109 -> E.Getting disks... [7.244s] [11550 results]
2018-05-31 07:33:32,368 -> F.Filtering less-than-mu disks... [0.259s] [11550 results]
2018-05-31 07:33:34,838 -> G.Prunning duplicate candidates... [2.470s] [6486 results]
2018-05-31 07:33:35,186 -> H.Indexing candidates... [2.818s] [6486 results]
2018-05-31 07:33:35,455 -> I.Getting expansions... [0.269s] [7196 results]
2018-05-31 07:33:35,627 -> J.Finding maximal disks... [0.171s] [3554 results]
2018-05-31 07:33:38,060 -> K.Prunning duplicates and subsets... [2.433s] [3546 results]
2018-05-31 07:33:38,060 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 07:33:38,060 ->   berlin0-10,   18548,  30.0,    28,  2,  34.85,    5775,     11550,         6486,       3546,  4
2018-05-31 07:33:38,327 -> Dropping indices...[0.267s]
2018-05-31 07:33:38,617 -> 1.Set of disks for t_i...                          |  35.42s |   3546 disks
2018-05-31 07:33:47,510 -> 2.Distance Join phase...                           |   8.89s |   8754 combinations
2018-05-31 07:47:59,470 -> 3.Getting candidates...                            | 851.96s |   3791 candidates
2018-05-31 07:48:01,060 -> 4.Found flocks...                                  |   1.59s |   3237 flocks
2018-05-31 07:48:06,579 -> 5.Updating times...                                |   2.50s |   3791 flocks
2018-05-31 07:48:09,793 -> 6.Filter phase...                                  |   3.21s |   3916 flocks
2018-05-31 07:48:14,393 -> Reporting locations...                             |   4.60s |  18548 points
2018-05-31 07:48:14,394 -> Setting mu=2,epsilon=30.0,cores=28,timestamp=5,dataset=berlin0-10
2018-05-31 07:48:22,220 -> A.Indexing points... [7.811s] [18548 results]
2018-05-31 07:48:33,582 -> B.Getting pairs... [11.362s] [5765 results]
2018-05-31 07:48:34,915 -> C.Computing centers... [1.333s] [11530 results]
2018-05-31 07:48:35,906 -> D.Indexing centers... [0.990s] [11530 results]
2018-05-31 07:48:43,068 -> E.Getting disks... [7.162s] [11530 results]
2018-05-31 07:48:43,289 -> F.Filtering less-than-mu disks... [0.221s] [11530 results]
2018-05-31 07:48:45,880 -> G.Prunning duplicate candidates... [2.591s] [6453 results]
2018-05-31 07:48:46,201 -> H.Indexing candidates... [2.912s] [6453 results]
2018-05-31 07:48:46,389 -> I.Getting expansions... [0.188s] [7126 results]
2018-05-31 07:48:46,558 -> J.Finding maximal disks... [0.169s] [3550 results]
2018-05-31 07:48:48,870 -> K.Prunning duplicates and subsets... [2.312s] [3540 results]
2018-05-31 07:48:48,870 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 07:48:48,870 ->   berlin0-10,   18548,  30.0,    28,  2,  34.46,    5765,     11530,         6453,       3540,  5
2018-05-31 07:48:49,271 -> Dropping indices...[0.401s]
2018-05-31 07:48:49,519 -> 1.Set of disks for t_i...                          |  35.13s |   3540 disks
2018-05-31 07:48:59,008 -> 2.Distance Join phase...                           |   9.49s |   9309 combinations
2018-05-31 08:03:28,359 -> 3.Getting candidates...                            | 869.35s |   3765 candidates
2018-05-31 08:03:30,114 -> 4.Found flocks...                                  |   1.76s |   3276 flocks
2018-05-31 08:03:38,316 -> 5.Updating times...                                |   3.12s |   3765 flocks
2018-05-31 08:03:42,266 -> 6.Filter phase...                                  |   3.95s |   3886 flocks
2018-05-31 08:03:46,915 -> Reporting locations...                             |   4.65s |  18546 points
2018-05-31 08:03:46,916 -> Setting mu=2,epsilon=30.0,cores=28,timestamp=6,dataset=berlin0-10
2018-05-31 08:03:55,008 -> A.Indexing points... [8.078s] [18546 results]
2018-05-31 08:04:06,392 -> B.Getting pairs... [11.384s] [5758 results]
2018-05-31 08:04:07,645 -> C.Computing centers... [1.253s] [11516 results]
2018-05-31 08:04:08,513 -> D.Indexing centers... [0.868s] [11516 results]
2018-05-31 08:04:15,809 -> E.Getting disks... [7.296s] [11516 results]
2018-05-31 08:04:16,046 -> F.Filtering less-than-mu disks... [0.237s] [11516 results]
2018-05-31 08:04:18,673 -> G.Prunning duplicate candidates... [2.626s] [6441 results]
2018-05-31 08:04:19,028 -> H.Indexing candidates... [2.981s] [6441 results]
2018-05-31 08:04:19,295 -> I.Getting expansions... [0.267s] [7165 results]
2018-05-31 08:04:19,535 -> J.Finding maximal disks... [0.240s] [3539 results]
2018-05-31 08:04:21,650 -> K.Prunning duplicates and subsets... [2.115s] [3533 results]
2018-05-31 08:04:21,650 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 08:04:21,650 ->   berlin0-10,   18546,  30.0,    28,  2,  34.72,    5758,     11516,         6441,       3533,  6
2018-05-31 08:04:22,110 -> Dropping indices...[0.460s]
2018-05-31 08:04:22,529 -> 1.Set of disks for t_i...                          |  35.61s |   3533 disks
2018-05-31 08:04:32,598 -> 2.Distance Join phase...                           |  10.07s |   9006 combinations
2018-05-31 08:16:18,335 -> 3.Getting candidates...                            | 705.74s |   3734 candidates
2018-05-31 08:16:20,178 -> 4.Found flocks...                                  |   1.84s |   3298 flocks
2018-05-31 08:16:29,151 -> 5.Updating times...                                |   3.24s |   3734 flocks
2018-05-31 08:16:33,153 -> 6.Filter phase...                                  |   4.00s |   3860 flocks
2018-05-31 08:16:37,795 -> Reporting locations...                             |   4.64s |  18546 points
2018-05-31 08:16:37,796 -> Setting mu=2,epsilon=30.0,cores=28,timestamp=7,dataset=berlin0-10
2018-05-31 08:16:45,969 -> A.Indexing points... [8.157s] [18546 results]
2018-05-31 08:16:57,242 -> B.Getting pairs... [11.273s] [5788 results]
2018-05-31 08:16:58,723 -> C.Computing centers... [1.481s] [11576 results]
2018-05-31 08:16:59,689 -> D.Indexing centers... [0.966s] [11576 results]
2018-05-31 08:17:07,020 -> E.Getting disks... [7.331s] [11576 results]
2018-05-31 08:17:07,249 -> F.Filtering less-than-mu disks... [0.229s] [11576 results]
2018-05-31 08:17:09,969 -> G.Prunning duplicate candidates... [2.720s] [6471 results]
2018-05-31 08:17:10,321 -> H.Indexing candidates... [3.072s] [6471 results]
2018-05-31 08:17:10,514 -> I.Getting expansions... [0.193s] [7215 results]
2018-05-31 08:17:10,688 -> J.Finding maximal disks... [0.173s] [3560 results]
2018-05-31 08:17:12,734 -> K.Prunning duplicates and subsets... [2.046s] [3552 results]
2018-05-31 08:17:12,743 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 08:17:12,743 ->   berlin0-10,   18546,  30.0,    28,  2,  34.93,    5788,     11576,         6471,       3552,  7
2018-05-31 08:17:13,255 -> Dropping indices...[0.512s]
2018-05-31 08:17:13,586 -> 1.Set of disks for t_i...                          |  35.79s |   3552 disks
2018-05-31 08:17:24,071 -> 2.Distance Join phase...                           |  10.48s |   8876 combinations
2018-05-31 08:37:28,789 -> 3.Getting candidates...                            | 1204.72s |   3743 candidates
2018-05-31 08:37:30,170 -> 4.Found flocks...                                  |   1.38s |   3338 flocks
2018-05-31 08:37:39,533 -> 5.Updating times...                                |   1.97s |   3743 flocks
2018-05-31 08:37:42,686 -> 6.Filter phase...                                  |   3.15s |   3896 flocks
2018-05-31 08:37:47,172 -> Reporting locations...                             |   4.49s |  18546 points
2018-05-31 08:37:47,172 -> Setting mu=2,epsilon=30.0,cores=28,timestamp=8,dataset=berlin0-10
2018-05-31 08:37:52,002 -> A.Indexing points... [4.814s] [18546 results]
2018-05-31 08:37:58,760 -> B.Getting pairs... [6.758s] [5791 results]
2018-05-31 08:38:00,029 -> C.Computing centers... [1.269s] [11582 results]
2018-05-31 08:38:00,998 -> D.Indexing centers... [0.969s] [11582 results]
2018-05-31 08:38:06,342 -> E.Getting disks... [5.344s] [11582 results]
2018-05-31 08:38:06,659 -> F.Filtering less-than-mu disks... [0.317s] [11582 results]
2018-05-31 08:38:09,330 -> G.Prunning duplicate candidates... [2.671s] [6477 results]
2018-05-31 08:38:09,662 -> H.Indexing candidates... [3.003s] [6477 results]
2018-05-31 08:38:09,992 -> I.Getting expansions... [0.330s] [7307 results]
2018-05-31 08:38:10,256 -> J.Finding maximal disks... [0.264s] [3569 results]
2018-05-31 08:38:11,967 -> K.Prunning duplicates and subsets... [1.711s] [3561 results]
2018-05-31 08:38:11,967 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 08:38:11,967 ->   berlin0-10,   18546,  30.0,    28,  2,  24.78,    5791,     11582,         6477,       3561,  8
2018-05-31 08:38:12,664 -> Dropping indices...[0.697s]
2018-05-31 08:38:12,996 -> 1.Set of disks for t_i...                          |  25.82s |   3561 disks
2018-05-31 08:38:24,643 -> 2.Distance Join phase...                           |  11.65s |   8735 combinations
2018-05-31 08:52:09,440 -> 3.Getting candidates...                            | 824.80s |   3759 candidates
2018-05-31 08:52:11,571 -> 4.Found flocks...                                  |   2.13s |   3326 flocks
2018-05-31 08:52:23,323 -> 5.Updating times...                                |   3.29s |   3759 flocks
2018-05-31 08:52:27,563 -> 6.Filter phase...                                  |   4.24s |   3891 flocks
2018-05-31 08:52:32,020 -> Reporting locations...                             |   4.46s |  18546 points
2018-05-31 08:52:32,020 -> Setting mu=2,epsilon=30.0,cores=28,timestamp=9,dataset=berlin0-10
2018-05-31 08:52:39,000 -> A.Indexing points... [6.955s] [18546 results]
2018-05-31 08:52:48,945 -> B.Getting pairs... [9.945s] [5802 results]
2018-05-31 08:52:50,225 -> C.Computing centers... [1.280s] [11604 results]
2018-05-31 08:52:51,116 -> D.Indexing centers... [0.891s] [11604 results]
2018-05-31 08:52:57,897 -> E.Getting disks... [6.781s] [11604 results]
2018-05-31 08:52:58,159 -> F.Filtering less-than-mu disks... [0.262s] [11604 results]
2018-05-31 08:53:00,750 -> G.Prunning duplicate candidates... [2.591s] [6488 results]
2018-05-31 08:53:01,114 -> H.Indexing candidates... [2.955s] [6488 results]
2018-05-31 08:53:01,359 -> I.Getting expansions... [0.245s] [7309 results]
2018-05-31 08:53:01,664 -> J.Finding maximal disks... [0.305s] [3566 results]
2018-05-31 08:53:03,705 -> K.Prunning duplicates and subsets... [2.041s] [3559 results]
2018-05-31 08:53:03,705 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 08:53:03,705 ->   berlin0-10,   18546,  30.0,    28,  2,  31.66,    5802,     11604,         6488,       3559,  9
2018-05-31 08:53:04,468 -> Dropping indices...[0.763s]
2018-05-31 08:53:04,837 -> 1.Set of disks for t_i...                          |  32.82s |   3559 disks
2018-05-31 08:53:17,112 -> 2.Distance Join phase...                           |  12.27s |   8579 combinations
2018-05-31 09:07:14,441 -> 3.Getting candidates...                            | 837.33s |   3773 candidates
2018-05-31 09:07:16,625 -> 4.Found flocks...                                  |   2.18s |   3335 flocks
2018-05-31 09:07:28,742 -> 5.Updating times...                                |   3.04s |   3773 flocks
2018-05-31 09:07:32,776 -> 6.Filter phase...                                  |   4.03s |   3909 flocks
2018-05-31 09:07:37,184 -> Reporting locations...                             |   4.41s |  18546 points
2018-05-31 09:07:37,184 -> Setting mu=2,epsilon=30.0,cores=28,timestamp=10,dataset=berlin0-10
2018-05-31 09:07:44,028 -> A.Indexing points... [6.811s] [18546 results]
2018-05-31 09:07:54,044 -> B.Getting pairs... [10.015s] [5797 results]
2018-05-31 09:07:55,314 -> C.Computing centers... [1.269s] [11594 results]
2018-05-31 09:07:56,295 -> D.Indexing centers... [0.981s] [11594 results]
2018-05-31 09:08:03,014 -> E.Getting disks... [6.719s] [11594 results]
2018-05-31 09:08:03,309 -> F.Filtering less-than-mu disks... [0.295s] [11594 results]
2018-05-31 09:08:05,822 -> G.Prunning duplicate candidates... [2.513s] [6486 results]
2018-05-31 09:08:06,142 -> H.Indexing candidates... [2.833s] [6486 results]
2018-05-31 09:08:06,340 -> I.Getting expansions... [0.197s] [7322 results]
2018-05-31 09:08:06,496 -> J.Finding maximal disks... [0.156s] [3565 results]
2018-05-31 09:08:08,429 -> K.Prunning duplicates and subsets... [1.933s] [3557 results]
2018-05-31 09:08:08,429 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 09:08:08,429 ->   berlin0-10,   18546,  30.0,    28,  2,  31.21,    5797,     11594,         6486,       3557, 10
2018-05-31 09:08:09,309 -> Dropping indices...[0.880s]
2018-05-31 09:08:09,805 -> 1.Set of disks for t_i...                          |  32.62s |   3557 disks
2018-05-31 09:08:21,484 -> 2.Distance Join phase...                           |  11.68s |   8482 combinations
2018-05-31 09:21:30,647 -> 3.Getting candidates...                            | 789.16s |   3764 candidates
2018-05-31 09:21:32,851 -> 4.Found flocks...                                  |   2.20s |   3319 flocks
2018-05-31 09:21:45,780 -> 5.Updating times...                                |   3.27s |   3764 flocks
2018-05-31 09:21:50,166 -> 6.Filter phase...                                  |   4.39s |   3884 flocks
2018-05-31 09:21:50,166 -> 

PFLOCK_SJ	30.0	2	5	23129

2018-05-31 09:21:59,408 -> Running SpatialJoin...                             | 8919.59s |  23129 flocks
2018-05-31 09:21:59,408 -> method=SpatialJoin,cores=28,epsilon=30.0,mu=2,delta=5,time=8919.589,master=spark://169.235.27.134:7077
2018-05-31 09:21:59,408 -> Closing app...
acald013@dblab-rack15: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
FLOCKFINDER=SpatialJoin;TIME=Thu May 31 09:22:02 PDT 2018;RUN=1527774782;NODES=4;ESTART=;EEND=;ESTEP=;MU=;DELTA=5;SCRIPT=MuBenchmarker;EVENT=End
FLOCKFINDER=MergeLast;TIME=Thu May 31 09:22:02 PDT 2018;RUN=1527783722;NODES=4;ESTART=;EEND=;ESTEP=;MU=;DELTA=5;SCRIPT=MuBenchmarker;EVENT=Start
WARNING:root:Setting 4 nodes...
acald013@dblab-rack15: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack14: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack11: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack12: no org.apache.spark.deploy.worker.Worker to stop
no org.apache.spark.deploy.master.Master to stop
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
acald013@dblab-rack15: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack15.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
WARNING:root:4 nodes has been set...
2018-05-31 09:22:13,135 -> Starting app...
2018-05-31 09:22:16,655 -> Starting session                                   |   3.52s |      0 
2018-05-31 09:22:16,672 -> Setting paramaters                                 |   0.02s |      0 
2018-05-31 09:22:21,681 -> Reading data                                       |   5.01s | 203106 points
2018-05-31 09:22:24,114 -> Extracting timestamps                              |   2.43s |     11 timestamps
2018-05-31 09:22:24,121 -> === MergeLast Start ===
2018-05-31 09:22:29,677 -> Reporting locations at t=0...                      |   5.37s |  18093 points
2018-05-31 09:22:29,686 -> Setting mu=2,epsilon=30.0,cores=28,timestamp=0,dataset=berlin0-10
2018-05-31 09:22:37,942 -> A.Indexing points... [8.220s] [18093 results]
2018-05-31 09:22:45,464 -> B.Getting pairs... [7.521s] [5511 results]
2018-05-31 09:22:47,519 -> C.Computing centers... [2.054s] [11022 results]
2018-05-31 09:22:48,906 -> D.Indexing centers... [1.387s] [11022 results]
2018-05-31 09:22:54,900 -> E.Getting disks... [5.994s] [11022 results]
2018-05-31 09:22:55,288 -> F.Filtering less-than-mu disks... [0.388s] [11022 results]
2018-05-31 09:22:58,237 -> G.Prunning duplicate candidates... [2.948s] [6157 results]
2018-05-31 09:22:58,706 -> H.Indexing candidates... [3.417s] [6157 results]
2018-05-31 09:22:58,994 -> I.Getting expansions... [0.287s] [6877 results]
2018-05-31 09:22:59,880 -> J.Finding maximal disks... [0.886s] [3432 results]
2018-05-31 09:23:02,044 -> K.Prunning duplicates and subsets... [2.164s] [3427 results]
2018-05-31 09:23:02,044 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 09:23:02,045 ->   berlin0-10,   18093,  30.0,    28,  2,  32.32,    5511,     11022,         6157,       3427,  0
2018-05-31 09:23:02,129 -> Dropping indices...[0.084s]
2018-05-31 09:23:02,452 -> 1.Set of disks for t_i...                          |  32.78s |   3427 disks
2018-05-31 09:23:07,518 -> Reporting locations at t=4...                      |   5.07s |  18548 points
2018-05-31 09:23:07,519 -> Setting mu=2,epsilon=30.0,cores=28,timestamp=4,dataset=berlin0-10
2018-05-31 09:23:15,745 -> A.Indexing points... [8.205s] [18548 results]
2018-05-31 09:23:26,738 -> B.Getting pairs... [10.993s] [5775 results]
2018-05-31 09:23:28,217 -> C.Computing centers... [1.478s] [11550 results]
2018-05-31 09:23:29,306 -> D.Indexing centers... [1.089s] [11550 results]
2018-05-31 09:23:36,725 -> E.Getting disks... [7.419s] [11550 results]
2018-05-31 09:23:36,979 -> F.Filtering less-than-mu disks... [0.254s] [11550 results]
2018-05-31 09:23:39,938 -> G.Prunning duplicate candidates... [2.958s] [6486 results]
2018-05-31 09:23:40,269 -> H.Indexing candidates... [3.289s] [6486 results]
2018-05-31 09:23:40,537 -> I.Getting expansions... [0.268s] [7196 results]
2018-05-31 09:23:40,748 -> J.Finding maximal disks... [0.211s] [3554 results]
2018-05-31 09:23:43,430 -> K.Prunning duplicates and subsets... [2.682s] [3546 results]
2018-05-31 09:23:43,431 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 09:23:43,431 ->   berlin0-10,   18548,  30.0,    28,  2,  35.89,    5775,     11550,         6486,       3546,  4
2018-05-31 09:23:43,516 -> Dropping indices...[0.085s]
2018-05-31 09:23:43,806 -> 2.Set of disks for t_i+delta...                    |  36.29s |   3427 disks
2018-05-31 09:24:04,776 -> 3.Joining timestams                                |  20.97s |   3866 candidates
2018-05-31 09:36:22,018 -> Checking internal timestamps                       | 737.24s |   3237 flocks
2018-05-31 09:36:27,267 -> Reporting locations at t=1...                      |   4.83s |  18245 points
2018-05-31 09:36:27,267 -> Setting mu=2,epsilon=30.0,cores=28,timestamp=1,dataset=berlin0-10
2018-05-31 09:36:31,475 -> A.Indexing points... [4.191s] [18245 results]
2018-05-31 09:36:36,882 -> B.Getting pairs... [5.407s] [5629 results]
2018-05-31 09:36:38,269 -> C.Computing centers... [1.387s] [11258 results]
2018-05-31 09:36:39,307 -> D.Indexing centers... [1.038s] [11258 results]
2018-05-31 09:36:44,110 -> E.Getting disks... [4.803s] [11258 results]
2018-05-31 09:36:44,381 -> F.Filtering less-than-mu disks... [0.271s] [11258 results]
2018-05-31 09:36:46,852 -> G.Prunning duplicate candidates... [2.471s] [6297 results]
2018-05-31 09:36:47,260 -> H.Indexing candidates... [2.879s] [6297 results]
2018-05-31 09:36:47,502 -> I.Getting expansions... [0.242s] [6982 results]
2018-05-31 09:36:47,685 -> J.Finding maximal disks... [0.183s] [3482 results]
2018-05-31 09:36:49,105 -> K.Prunning duplicates and subsets... [1.420s] [3478 results]
2018-05-31 09:36:49,105 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 09:36:49,105 ->   berlin0-10,   18245,  30.0,    28,  2,  21.82,    5629,     11258,         6297,       3478,  1
2018-05-31 09:36:49,215 -> Dropping indices...[0.110s]
2018-05-31 09:36:49,482 -> 1.Set of disks for t_i...                          |  22.22s |   3478 disks
2018-05-31 09:36:54,362 -> Reporting locations at t=5...                      |   4.88s |  18548 points
2018-05-31 09:36:54,363 -> Setting mu=2,epsilon=30.0,cores=28,timestamp=5,dataset=berlin0-10
2018-05-31 09:37:01,172 -> A.Indexing points... [6.791s] [18548 results]
2018-05-31 09:37:11,897 -> B.Getting pairs... [10.725s] [5765 results]
2018-05-31 09:37:13,277 -> C.Computing centers... [1.380s] [11530 results]
2018-05-31 09:37:14,304 -> D.Indexing centers... [1.027s] [11530 results]
2018-05-31 09:37:21,701 -> E.Getting disks... [7.397s] [11530 results]
2018-05-31 09:37:21,929 -> F.Filtering less-than-mu disks... [0.228s] [11530 results]
2018-05-31 09:37:24,549 -> G.Prunning duplicate candidates... [2.620s] [6453 results]
2018-05-31 09:37:24,870 -> H.Indexing candidates... [2.941s] [6453 results]
2018-05-31 09:37:25,095 -> I.Getting expansions... [0.224s] [7126 results]
2018-05-31 09:37:25,285 -> J.Finding maximal disks... [0.190s] [3550 results]
2018-05-31 09:37:27,802 -> K.Prunning duplicates and subsets... [2.517s] [3540 results]
2018-05-31 09:37:27,802 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 09:37:27,802 ->   berlin0-10,   18548,  30.0,    28,  2,  33.42,    5765,     11530,         6453,       3540,  5
2018-05-31 09:37:27,963 -> Dropping indices...[0.161s]
2018-05-31 09:37:28,234 -> 2.Set of disks for t_i+delta...                    |  33.87s |   3478 disks
2018-05-31 09:37:48,922 -> 3.Joining timestams                                |  20.69s |   3941 candidates
2018-05-31 09:52:11,520 -> Checking internal timestamps                       | 862.60s |   3276 flocks
2018-05-31 09:52:17,352 -> Reporting locations at t=2...                      |   5.07s |  18394 points
2018-05-31 09:52:17,352 -> Setting mu=2,epsilon=30.0,cores=28,timestamp=2,dataset=berlin0-10
2018-05-31 09:52:21,659 -> A.Indexing points... [4.286s] [18394 results]
2018-05-31 09:52:26,742 -> B.Getting pairs... [5.083s] [5701 results]
2018-05-31 09:52:28,107 -> C.Computing centers... [1.365s] [11402 results]
2018-05-31 09:52:29,142 -> D.Indexing centers... [1.035s] [11402 results]
2018-05-31 09:52:33,792 -> E.Getting disks... [4.650s] [11402 results]
2018-05-31 09:52:34,031 -> F.Filtering less-than-mu disks... [0.239s] [11402 results]
2018-05-31 09:52:35,867 -> G.Prunning duplicate candidates... [1.836s] [6373 results]
2018-05-31 09:52:36,230 -> H.Indexing candidates... [2.199s] [6373 results]
2018-05-31 09:52:36,471 -> I.Getting expansions... [0.241s] [7107 results]
2018-05-31 09:52:36,661 -> J.Finding maximal disks... [0.190s] [3517 results]
2018-05-31 09:52:38,392 -> K.Prunning duplicates and subsets... [1.731s] [3511 results]
2018-05-31 09:52:38,392 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 09:52:38,392 ->   berlin0-10,   18394,  30.0,    28,  2,  21.02,    5701,     11402,         6373,       3511,  2
2018-05-31 09:52:38,554 -> Dropping indices...[0.162s]
2018-05-31 09:52:38,830 -> 1.Set of disks for t_i...                          |  21.48s |   3511 disks
2018-05-31 09:52:43,671 -> Reporting locations at t=6...                      |   4.84s |  18546 points
2018-05-31 09:52:43,671 -> Setting mu=2,epsilon=30.0,cores=28,timestamp=6,dataset=berlin0-10
2018-05-31 09:52:50,993 -> A.Indexing points... [7.300s] [18546 results]
2018-05-31 09:53:01,854 -> B.Getting pairs... [10.860s] [5758 results]
2018-05-31 09:53:03,463 -> C.Computing centers... [1.609s] [11516 results]
2018-05-31 09:53:04,423 -> D.Indexing centers... [0.960s] [11516 results]
2018-05-31 09:53:12,007 -> E.Getting disks... [7.584s] [11516 results]
2018-05-31 09:53:12,243 -> F.Filtering less-than-mu disks... [0.235s] [11516 results]
2018-05-31 09:53:14,820 -> G.Prunning duplicate candidates... [2.577s] [6441 results]
2018-05-31 09:53:15,220 -> H.Indexing candidates... [2.977s] [6441 results]
2018-05-31 09:53:15,437 -> I.Getting expansions... [0.217s] [7165 results]
2018-05-31 09:53:15,604 -> J.Finding maximal disks... [0.167s] [3539 results]
2018-05-31 09:53:17,878 -> K.Prunning duplicates and subsets... [2.274s] [3533 results]
2018-05-31 09:53:17,878 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 09:53:17,878 ->   berlin0-10,   18546,  30.0,    28,  2,  34.19,    5758,     11516,         6441,       3533,  6
2018-05-31 09:53:18,095 -> Dropping indices...[0.217s]
2018-05-31 09:53:18,434 -> 2.Set of disks for t_i+delta...                    |  34.76s |   3511 disks
2018-05-31 09:53:39,813 -> 3.Joining timestams                                |  21.38s |   3948 candidates
2018-05-31 10:06:59,877 -> Checking internal timestamps                       | 800.06s |   3298 flocks
2018-05-31 10:07:05,735 -> Reporting locations at t=3...                      |   4.82s |  18548 points
2018-05-31 10:07:05,735 -> Setting mu=2,epsilon=30.0,cores=28,timestamp=3,dataset=berlin0-10
2018-05-31 10:07:12,963 -> A.Indexing points... [7.211s] [18548 results]
2018-05-31 10:07:23,385 -> B.Getting pairs... [10.421s] [5768 results]
2018-05-31 10:07:24,860 -> C.Computing centers... [1.475s] [11536 results]
2018-05-31 10:07:25,894 -> D.Indexing centers... [1.034s] [11536 results]
2018-05-31 10:07:32,915 -> E.Getting disks... [7.021s] [11536 results]
2018-05-31 10:07:33,163 -> F.Filtering less-than-mu disks... [0.247s] [11536 results]
2018-05-31 10:07:35,932 -> G.Prunning duplicate candidates... [2.769s] [6465 results]
2018-05-31 10:07:36,266 -> H.Indexing candidates... [3.103s] [6465 results]
2018-05-31 10:07:36,496 -> I.Getting expansions... [0.230s] [7226 results]
2018-05-31 10:07:36,703 -> J.Finding maximal disks... [0.207s] [3566 results]
2018-05-31 10:07:38,930 -> K.Prunning duplicates and subsets... [2.227s] [3557 results]
2018-05-31 10:07:38,931 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 10:07:38,931 ->   berlin0-10,   18548,  30.0,    28,  2,  33.18,    5768,     11536,         6465,       3557,  3
2018-05-31 10:07:39,149 -> Dropping indices...[0.218s]
2018-05-31 10:07:39,441 -> 1.Set of disks for t_i...                          |  33.71s |   3557 disks
2018-05-31 10:07:44,245 -> Reporting locations at t=7...                      |   4.80s |  18546 points
2018-05-31 10:07:44,246 -> Setting mu=2,epsilon=30.0,cores=28,timestamp=7,dataset=berlin0-10
2018-05-31 10:07:51,778 -> A.Indexing points... [7.512s] [18546 results]
2018-05-31 10:08:02,665 -> B.Getting pairs... [10.887s] [5788 results]
2018-05-31 10:08:04,058 -> C.Computing centers... [1.393s] [11576 results]
2018-05-31 10:08:04,996 -> D.Indexing centers... [0.938s] [11576 results]
2018-05-31 10:08:12,563 -> E.Getting disks... [7.567s] [11576 results]
2018-05-31 10:08:12,868 -> F.Filtering less-than-mu disks... [0.305s] [11576 results]
2018-05-31 10:08:16,226 -> G.Prunning duplicate candidates... [3.358s] [6471 results]
2018-05-31 10:08:16,586 -> H.Indexing candidates... [3.718s] [6471 results]
2018-05-31 10:08:16,888 -> I.Getting expansions... [0.302s] [7215 results]
2018-05-31 10:08:17,092 -> J.Finding maximal disks... [0.204s] [3560 results]
2018-05-31 10:08:19,285 -> K.Prunning duplicates and subsets... [2.192s] [3552 results]
2018-05-31 10:08:19,285 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 10:08:19,285 ->   berlin0-10,   18546,  30.0,    28,  2,  35.02,    5788,     11576,         6471,       3552,  7
2018-05-31 10:08:19,542 -> Dropping indices...[0.257s]
2018-05-31 10:08:20,202 -> 2.Set of disks for t_i+delta...                    |  35.96s |   3557 disks
2018-05-31 10:08:42,472 -> 3.Joining timestams                                |  22.27s |   3989 candidates
2018-05-31 10:22:40,496 -> Checking internal timestamps                       | 838.02s |   3338 flocks
2018-05-31 10:22:46,662 -> Reporting locations at t=4...                      |   4.84s |  18548 points
2018-05-31 10:22:46,888 -> 1.Set of disks for t_i...                          |   0.23s |   3546 disks
2018-05-31 10:22:51,629 -> Reporting locations at t=8...                      |   4.74s |  18546 points
2018-05-31 10:22:51,629 -> Setting mu=2,epsilon=30.0,cores=28,timestamp=8,dataset=berlin0-10
2018-05-31 10:22:57,241 -> A.Indexing points... [5.592s] [18546 results]
2018-05-31 10:23:04,797 -> B.Getting pairs... [7.556s] [5791 results]
2018-05-31 10:23:06,154 -> C.Computing centers... [1.357s] [11582 results]
2018-05-31 10:23:07,196 -> D.Indexing centers... [1.042s] [11582 results]
2018-05-31 10:23:12,533 -> E.Getting disks... [5.337s] [11582 results]
2018-05-31 10:23:12,791 -> F.Filtering less-than-mu disks... [0.257s] [11582 results]
2018-05-31 10:23:14,937 -> G.Prunning duplicate candidates... [2.146s] [6477 results]
2018-05-31 10:23:15,306 -> H.Indexing candidates... [2.515s] [6477 results]
2018-05-31 10:23:15,572 -> I.Getting expansions... [0.266s] [7307 results]
2018-05-31 10:23:15,743 -> J.Finding maximal disks... [0.171s] [3569 results]
2018-05-31 10:23:17,502 -> K.Prunning duplicates and subsets... [1.759s] [3561 results]
2018-05-31 10:23:17,502 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 10:23:17,502 ->   berlin0-10,   18546,  30.0,    28,  2,  25.85,    5791,     11582,         6477,       3561,  8
2018-05-31 10:23:17,797 -> Dropping indices...[0.295s]
2018-05-31 10:23:18,107 -> 2.Set of disks for t_i+delta...                    |  26.48s |   3546 disks
2018-05-31 10:23:38,797 -> 3.Joining timestams                                |  20.69s |   3972 candidates
2018-05-31 10:46:35,389 -> Checking internal timestamps                       | 1376.59s |   3326 flocks
2018-05-31 10:46:41,813 -> Reporting locations at t=5...                      |   4.88s |  18548 points
2018-05-31 10:46:42,044 -> 1.Set of disks for t_i...                          |   0.23s |   3540 disks
2018-05-31 10:46:46,659 -> Reporting locations at t=9...                      |   4.62s |  18546 points
2018-05-31 10:46:46,660 -> Setting mu=2,epsilon=30.0,cores=28,timestamp=9,dataset=berlin0-10
2018-05-31 10:46:54,388 -> A.Indexing points... [7.688s] [18546 results]
2018-05-31 10:47:05,127 -> B.Getting pairs... [10.738s] [5802 results]
2018-05-31 10:47:06,450 -> C.Computing centers... [1.323s] [11604 results]
2018-05-31 10:47:07,634 -> D.Indexing centers... [1.184s] [11604 results]
2018-05-31 10:47:14,678 -> E.Getting disks... [7.044s] [11604 results]
2018-05-31 10:47:14,930 -> F.Filtering less-than-mu disks... [0.252s] [11604 results]
2018-05-31 10:47:17,181 -> G.Prunning duplicate candidates... [2.251s] [6488 results]
2018-05-31 10:47:17,615 -> H.Indexing candidates... [2.685s] [6488 results]
2018-05-31 10:47:17,856 -> I.Getting expansions... [0.241s] [7309 results]
2018-05-31 10:47:18,037 -> J.Finding maximal disks... [0.181s] [3566 results]
2018-05-31 10:47:20,045 -> K.Prunning duplicates and subsets... [2.008s] [3559 results]
2018-05-31 10:47:20,045 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-05-31 10:47:20,045 ->   berlin0-10,   18546,  30.0,    28,  2,  33.35,    5802,     11604,         6488,       3559,  9
2018-05-31 10:47:20,397 -> Dropping indices...[0.352s]
2018-05-31 10:47:20,687 -> 2.Set of disks for t_i+delta...                    |  34.03s |   3540 disks
2018-05-31 10:47:41,708 -> 3.Joining timestams                                |  21.02s |   3952 candidates
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 8490.0 failed 4 times, most recent failure: Lost task 1.3 in stage 8490.0 (TID 439824, 169.235.27.138, executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1958)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:935)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:934)
	at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:275)
	at org.apache.spark.sql.Dataset$$anonfun$org$apache$spark$sql$Dataset$$execute$1$1.apply(Dataset.scala:2371)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:57)
	at org.apache.spark.sql.Dataset.withNewExecutionId(Dataset.scala:2765)
	at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$execute$1(Dataset.scala:2370)
	at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collect(Dataset.scala:2377)
	at org.apache.spark.sql.Dataset$$anonfun$count$1.apply(Dataset.scala:2405)
	at org.apache.spark.sql.Dataset$$anonfun$count$1.apply(Dataset.scala:2404)
	at org.apache.spark.sql.Dataset.withCallback(Dataset.scala:2778)
	at org.apache.spark.sql.Dataset.count(Dataset.scala:2404)
	at FlockFinderMergeLast$$anonfun$runMergeLast$1.apply(FlockFinderMergeLast.scala:235)
	at FlockFinderMergeLast$$anonfun$runMergeLast$1.apply(FlockFinderMergeLast.scala:121)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at FlockFinderMergeLast$.runMergeLast(FlockFinderMergeLast.scala:121)
	at FlockFinderMergeLast$$anonfun$run$1$$anonfun$apply$mcVI$sp$1$$anonfun$apply$mcVI$sp$2.apply$mcVD$sp(FlockFinderMergeLast.scala:91)
	at FlockFinderMergeLast$$anonfun$run$1$$anonfun$apply$mcVI$sp$1$$anonfun$apply$mcVI$sp$2.apply(FlockFinderMergeLast.scala:86)
	at FlockFinderMergeLast$$anonfun$run$1$$anonfun$apply$mcVI$sp$1$$anonfun$apply$mcVI$sp$2.apply(FlockFinderMergeLast.scala:86)
	at scala.collection.immutable.NumericRange.foreach(NumericRange.scala:73)
	at FlockFinderMergeLast$$anonfun$run$1$$anonfun$apply$mcVI$sp$1.apply$mcVI$sp(FlockFinderMergeLast.scala:86)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at FlockFinderMergeLast$$anonfun$run$1.apply$mcVI$sp(FlockFinderMergeLast.scala:86)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at FlockFinderMergeLast$.run(FlockFinderMergeLast.scala:86)
	at FlockFinderMergeLast$.main(FlockFinderMergeLast.scala:585)
	at FlockFinderMergeLast.main(FlockFinderMergeLast.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
