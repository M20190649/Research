FLOCKFINDER=MergeLast;TIME=Mon Jun  4 09:53:07 PDT 2018;RUN=1528131187;NODES=4;ESTART=100;EEND=100;ESTEP=5;MU=4;DELTA=5;SCRIPT=EpsilonBenchmarker;EVENT=Start
WARNING:root:Setting 4 nodes...
acald013@dblab-rack15: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack14: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack11: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack12: no org.apache.spark.deploy.worker.Worker to stop
no org.apache.spark.deploy.master.Master to stop
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack15: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack15.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
WARNING:root:4 nodes has been set...
2018-06-04 09:53:25,166 -> Starting app...
2018-06-04 09:53:28,648 -> Starting session                                   |   3.48s |      0 
2018-06-04 09:53:28,660 -> Setting paramaters                                 |   0.01s |      0 
2018-06-04 09:53:33,593 -> Reading data                                       |   4.93s | 203106 points
2018-06-04 09:53:37,397 -> Extracting timestamps                              |   3.80s |     11 timestamps
2018-06-04 09:53:37,404 -> === MergeLast Start ===
2018-06-04 09:53:44,338 -> Reporting locations at t=0...                      |   6.72s |  18093 points
2018-06-04 09:53:44,357 -> Setting mu=4,epsilon=100.0,cores=28,timestamp=0,dataset=berlin0-10
2018-06-04 09:53:53,492 -> A.Indexing points... [9.092s] [18093 results]
2018-06-04 09:54:01,804 -> B.Getting pairs... [8.312s] [33957 results]
2018-06-04 09:54:04,454 -> C.Computing centers... [2.650s] [67914 results]
2018-06-04 09:54:06,603 -> D.Indexing centers... [2.148s] [67914 results]
2018-06-04 09:54:14,284 -> E.Getting disks... [7.681s] [67914 results]
2018-06-04 09:54:15,357 -> F.Filtering less-than-mu disks... [1.073s] [32499 results]
2018-06-04 09:54:19,207 -> G.Prunning duplicate candidates... [3.850s] [19046 results]
2018-06-04 09:54:19,939 -> H.Indexing candidates... [4.582s] [19046 results]
2018-06-04 09:54:20,544 -> I.Getting expansions... [0.605s] [38041 results]
2018-06-04 09:54:40,933 -> J.Finding maximal disks... [20.389s] [3357 results]
2018-06-04 09:54:43,080 -> K.Prunning duplicates and subsets... [2.147s] [3329 results]
2018-06-04 09:54:43,081 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-06-04 09:54:43,081 ->   berlin0-10,   18093, 100.0,    28,  4,  58.68,   33957,     67914,        19046,       3329,  0
2018-06-04 09:54:43,162 -> Dropping indices...[0.081s]
2018-06-04 09:54:43,490 -> 1.Set of disks for t_i...                          |  59.15s |   3329 disks
2018-06-04 09:54:49,217 -> Reporting locations at t=4...                      |   5.73s |  18548 points
2018-06-04 09:54:49,217 -> Setting mu=4,epsilon=100.0,cores=28,timestamp=4,dataset=berlin0-10
2018-06-04 09:54:56,654 -> A.Indexing points... [7.414s] [18548 results]
2018-06-04 09:55:07,146 -> B.Getting pairs... [10.492s] [35479 results]
2018-06-04 09:55:08,950 -> C.Computing centers... [1.804s] [70958 results]
2018-06-04 09:55:10,490 -> D.Indexing centers... [1.540s] [70958 results]
2018-06-04 09:55:19,608 -> E.Getting disks... [9.118s] [70958 results]
2018-06-04 09:55:20,916 -> F.Filtering less-than-mu disks... [1.308s] [34262 results]
2018-06-04 09:55:25,747 -> G.Prunning duplicate candidates... [4.831s] [19944 results]
2018-06-04 09:55:26,251 -> H.Indexing candidates... [5.335s] [19944 results]
2018-06-04 09:55:26,640 -> I.Getting expansions... [0.389s] [38693 results]
2018-06-04 09:55:52,051 -> J.Finding maximal disks... [25.411s] [3630 results]
2018-06-04 09:55:54,403 -> K.Prunning duplicates and subsets... [2.352s] [3602 results]
2018-06-04 09:55:54,403 ->      Dataset,# Points,   Eps, Cores, Mu,   Time, # Pairs,   # Disks, # Candidates, # Maximals,  t
2018-06-04 09:55:54,403 ->   berlin0-10,   18548, 100.0,    28,  4,  65.16,   35479,     70958,        19944,       3602,  4
2018-06-04 09:55:54,480 -> Dropping indices...[0.077s]
2018-06-04 09:55:54,822 -> 2.Set of disks for t_i+delta...                    |  65.61s |   3329 disks
2018-06-04 09:56:19,457 -> 3.Joining timestams                                |  24.64s |  19345 candidates
